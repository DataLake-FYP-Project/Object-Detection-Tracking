{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11956593,"sourceType":"datasetVersion","datasetId":7517556}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:04:04.493381Z","iopub.execute_input":"2025-05-26T10:04:04.493815Z","iopub.status.idle":"2025-05-26T10:04:04.624643Z","shell.execute_reply.started":"2025-05-26T10:04:04.493774Z","shell.execute_reply":"2025-05-26T10:04:04.622179Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: nvidia-smi: command not found\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:04:06.749299Z","iopub.execute_input":"2025-05-26T10:04:06.749828Z","iopub.status.idle":"2025-05-26T10:04:13.142484Z","shell.execute_reply.started":"2025-05-26T10:04:06.749775Z","shell.execute_reply":"2025-05-26T10:04:13.140752Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"! rm -rf video.mp4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:04:16.554320Z","iopub.execute_input":"2025-05-26T10:04:16.554730Z","iopub.status.idle":"2025-05-26T10:04:16.681563Z","shell.execute_reply.started":"2025-05-26T10:04:16.554693Z","shell.execute_reply":"2025-05-26T10:04:16.679617Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import gdown\n\n# Update with your file's specific ID\nfile_id = \"1Qi2KRxQoLrv0_ukVkTBP6xLm4uGykihz\"\nurl = f\"https://drive.google.com/uc?id={file_id}\"\n\noutput = \"safety_detection.mp4\"\ngdown.download(url, output, quiet=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:04:18.713016Z","iopub.execute_input":"2025-05-26T10:04:18.713412Z","iopub.status.idle":"2025-05-26T10:04:24.099380Z","shell.execute_reply.started":"2025-05-26T10:04:18.713375Z","shell.execute_reply":"2025-05-26T10:04:24.097915Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1Qi2KRxQoLrv0_ukVkTBP6xLm4uGykihz\nTo: /kaggle/working/safety_detection.mp4\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 192k/192k [00:00<00:00, 58.1MB/s]\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'safety_detection.mp4'"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\nprint(HOME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:04:53.013880Z","iopub.execute_input":"2025-05-26T10:04:53.014422Z","iopub.status.idle":"2025-05-26T10:04:53.021014Z","shell.execute_reply.started":"2025-05-26T10:04:53.014393Z","shell.execute_reply":"2025-05-26T10:04:53.019807Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"SOURCE_VIDEO_PATH = \"/kaggle/working/safety_detection.mp4\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:04:56.092229Z","iopub.execute_input":"2025-05-26T10:04:56.093250Z","iopub.status.idle":"2025-05-26T10:04:56.097893Z","shell.execute_reply.started":"2025-05-26T10:04:56.093214Z","shell.execute_reply":"2025-05-26T10:04:56.096723Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Pip install method (recommended)\n\n!pip install \"ultralytics<=8.3.40\"\n\nfrom IPython import display\ndisplay.clear_output()\n\nimport ultralytics\nultralytics.checks()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:04:59.473273Z","iopub.execute_input":"2025-05-26T10:04:59.473624Z","iopub.status.idle":"2025-05-26T10:06:57.071046Z","shell.execute_reply.started":"2025-05-26T10:04:59.473598Z","shell.execute_reply":"2025-05-26T10:06:57.069766Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.40 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\nSetup complete âœ… (4 CPUs, 31.4 GB RAM, 6362.0/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"MODEL = \"/kaggle/input/safety-detection-model/ppe.pt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:07:00.924288Z","iopub.execute_input":"2025-05-26T10:07:00.924659Z","iopub.status.idle":"2025-05-26T10:07:00.932187Z","shell.execute_reply.started":"2025-05-26T10:07:00.924635Z","shell.execute_reply":"2025-05-26T10:07:00.930453Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO(MODEL)\nmodel.fuse()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:07:04.583610Z","iopub.execute_input":"2025-05-26T10:07:04.584040Z","iopub.status.idle":"2025-05-26T10:07:07.431226Z","shell.execute_reply.started":"2025-05-26T10:07:04.584005Z","shell.execute_reply":"2025-05-26T10:07:07.429213Z"}},"outputs":[{"name":"stdout","text":"Model summary (fused): 268 layers, 43,614,318 parameters, 0 gradients, 164.9 GFLOPs\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!pip install supervision==0.3.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:07:09.763385Z","iopub.execute_input":"2025-05-26T10:07:09.763810Z","iopub.status.idle":"2025-05-26T10:07:15.117524Z","shell.execute_reply.started":"2025-05-26T10:07:09.763778Z","shell.execute_reply":"2025-05-26T10:07:15.115571Z"}},"outputs":[{"name":"stdout","text":"Collecting supervision==0.3.0\n  Downloading supervision-0.3.0-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from supervision==0.3.0) (1.26.4)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from supervision==0.3.0) (4.11.0.86)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from supervision==0.3.0) (3.7.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->supervision==0.3.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->supervision==0.3.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->supervision==0.3.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->supervision==0.3.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->supervision==0.3.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->supervision==0.3.0) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->supervision==0.3.0) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->supervision==0.3.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->supervision==0.3.0) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->supervision==0.3.0) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->supervision==0.3.0) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->supervision==0.3.0) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->supervision==0.3.0) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->supervision==0.3.0) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->supervision==0.3.0) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20.0->supervision==0.3.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20.0->supervision==0.3.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20.0->supervision==0.3.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20.0->supervision==0.3.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20.0->supervision==0.3.0) (2024.2.0)\nDownloading supervision-0.3.0-py3-none-any.whl (21 kB)\nInstalling collected packages: supervision\nSuccessfully installed supervision-0.3.0\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import supervision as sv\nfrom ultralytics import YOLO\nimport os\nimport json\nimport cv2  # OpenCV for image saving\nimport numpy as np\n\n# -------------------------------\n# CONFIGURATION\n# -------------------------------\nTARGET_VIDEO_PATH = 'output_video.mp4'\nFRAME_SAVE_DIR = 'frames/'  # Directory to save frames\nFRAME_DATA_PATH = 'frame_data.json'  # JSON file to save frame data\n\n# All classes in our custom model\nclassNames = [\n    'Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest',\n    'Person', 'Safety Cone', 'Safety Vest', 'machinery', 'vehicle'\n]\n\nSAFETY_CLASSES = {\"Hardhat\", \"Mask\", \"Safety Vest\"}\nUNSAFE_CLASSES = {\"NO-Hardhat\", \"NO-Mask\", \"NO-Safety Vest\"}\n\n# -------------------------------\n# INITIAL SETUP\n# -------------------------------\nos.makedirs(FRAME_SAVE_DIR, exist_ok=True)\n\nvideo_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\nbox_annotator = sv.BoxAnnotator(thickness=2, text_thickness=2, text_scale=1)\n\nid_counter = 1\nid_map = {}\nframe_data_list = []\n\n# -------------------------------\n# UTILITY FUNCTION\n# -------------------------------\ndef get_class_name(class_id):\n    return classNames[class_id] if class_id < len(classNames) else f\"Class {class_id}\"\n\n# -------------------------------\n# PROCESSING FRAMES\n# -------------------------------\nwith sv.VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n    for frame_number, result in enumerate(\n        model.track(\n            source=SOURCE_VIDEO_PATH,\n            tracker='bytetrack.yaml',\n            show=False,\n            stream=True,\n            agnostic_nms=True,\n            persist=True\n        )\n    ):\n        frame = result.orig_img\n        detections = sv.Detections.from_yolov8(result)\n\n        if result.boxes.id is not None:\n            ids = result.boxes.id.cpu().numpy().astype(int)\n            class_ids = result.boxes.cls.cpu().numpy().astype(int)\n            confs = result.boxes.conf.cpu().numpy()\n            boxes = result.boxes.xyxy.cpu().numpy()\n\n            detected = []\n\n            for i in range(len(ids)):\n                tracker_id = ids[i]\n                class_id = class_ids[i]\n                confidence = float(confs[i])\n                bbox = list(map(int, boxes[i]))\n                class_name = get_class_name(class_id)\n\n                # Assign new sequential ID\n                if tracker_id not in id_map:\n                    id_map[tracker_id] = id_counter\n                    id_counter += 1\n                new_id = id_map[tracker_id]\n\n                detected.append({\n                    \"id\": new_id,\n                    \"tracker_id\": tracker_id,\n                    \"class_id\": class_id,\n                    \"class_name\": class_name,\n                    \"confidence\": confidence,\n                    \"bbox\": bbox\n                })\n\n           \n            # Separate people and other objects\n            people = [d for d in detected if d[\"class_name\"] == \"Person\"]\n            objects = [d for d in detected if d[\"class_name\"] != \"Person\"]\n\n            people_info = []\n\n            for person in people:\n                tid = person[\"tracker_id\"]\n                new_id = id_map[tid]\n                person_bbox = person[\"bbox\"]\n            \n                # Initialize\n                person_state = {\n                    \"hardhat\": None,\n                    \"mask\": None,\n                    \"safety_vest\": None\n                }\n\n                # Check which objects are near the personâ€™s bounding box\n                for obj in objects:\n                    obj_class = obj[\"class_name\"]\n                    obj_bbox = obj[\"bbox\"]\n            \n                    # IoU or proximity check â€” here we use simple overlap\n                    px1, py1, px2, py2 = person_bbox\n                    ox1, oy1, ox2, oy2 = obj_bbox\n            \n                    is_near = not (ox2 < px1 or ox1 > px2 or oy2 < py1 or oy1 > py2)\n            \n                    if is_near:\n                        if obj_class == \"Hardhat\":\n                            person_state[\"hardhat\"] = True\n                        elif obj_class == \"NO-Hardhat\":\n                            person_state[\"hardhat\"] = False\n                        elif obj_class == \"Mask\":\n                            person_state[\"mask\"] = True\n                        elif obj_class == \"NO-Mask\":\n                            person_state[\"mask\"] = False\n                        elif obj_class == \"Safety Vest\":\n                            person_state[\"safety_vest\"] = True\n                        elif obj_class == \"NO-Safety Vest\":\n                            person_state[\"safety_vest\"] = False\n\n                # Determine safety status\n                missing_items = [item for item, value in person_state.items() if value != True]\n                status = \"Safe\" if not missing_items else \"Unsafe\"\n                color = (0, 255, 0) if status == \"Safe\" else (0, 0, 255)\n            \n                label = f\"ID {new_id} | {status}\"\n                cv2.rectangle(frame, (person_bbox[0], person_bbox[1]), (person_bbox[2], person_bbox[3]), color, 2)\n                cv2.putText(frame, label, (person_bbox[0], person_bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n            \n                person_state.update({\n                    \"tracker_id\": new_id,\n                    \"safety_status\": status,\n                    \"missing_items\": missing_items,\n                    \"bbox\": person_bbox\n                })\n            \n                people_info.append(person_state)\n\n            # Save frame\n            frame_path = os.path.join(FRAME_SAVE_DIR, f\"frame_{frame_number:04d}.jpg\")\n            cv2.imwrite(frame_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n\n            # Save JSON info\n            frame_data_list.append({\n                \"frame_number\": frame_number,\n                \"people\": people_info\n            })\n\n            # Write annotated frame to video\n            sink.write_frame(frame)\n\nprint(\"Safety detection and video generation completed.\")\n\n# -------------------------------\n# SAVE FRAME DATA TO JSON\n# -------------------------------\nwith open(FRAME_DATA_PATH, 'w') as json_file:\n    json.dump(frame_data_list, json_file, indent=4)\n\nprint(f\"Frames saved to '{FRAME_SAVE_DIR}' and data saved to '{FRAME_DATA_PATH}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:36:41.666402Z","iopub.execute_input":"2025-05-26T10:36:41.666935Z","iopub.status.idle":"2025-05-26T10:38:01.521275Z","shell.execute_reply.started":"2025-05-26T10:36:41.666903Z","shell.execute_reply":"2025-05-26T10:38:01.519831Z"}},"outputs":[{"name":"stdout","text":"\nvideo 1/1 (frame 1/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1412.7ms\nvideo 1/1 (frame 2/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 Person, 1353.7ms\nvideo 1/1 (frame 3/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 Person, 1395.8ms\nvideo 1/1 (frame 4/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 Person, 1379.0ms\nvideo 1/1 (frame 5/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 Person, 1414.9ms\nvideo 1/1 (frame 6/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 Person, 1381.0ms\nvideo 1/1 (frame 7/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 Person, 1363.9ms\nvideo 1/1 (frame 8/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 Person, 1374.1ms\nvideo 1/1 (frame 9/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Safety Vest, 1 Person, 1369.7ms\nvideo 1/1 (frame 10/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Safety Vest, 1 Person, 1359.0ms\nvideo 1/1 (frame 11/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Safety Vest, 1 Person, 1416.6ms\nvideo 1/1 (frame 12/56) /kaggle/working/safety_detection.mp4: 384x640 2 Hardhats, 2 NO-Safety Vests, 2 Persons, 1387.9ms\nvideo 1/1 (frame 13/56) /kaggle/working/safety_detection.mp4: 384x640 2 Hardhats, 2 NO-Safety Vests, 2 Persons, 1363.2ms\nvideo 1/1 (frame 14/56) /kaggle/working/safety_detection.mp4: 384x640 2 Hardhats, 2 NO-Safety Vests, 2 Persons, 1378.8ms\nvideo 1/1 (frame 15/56) /kaggle/working/safety_detection.mp4: 384x640 2 Hardhats, 2 NO-Safety Vests, 2 Persons, 1404.9ms\nvideo 1/1 (frame 16/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Safety Vest, 1 Person, 1388.5ms\nvideo 1/1 (frame 17/56) /kaggle/working/safety_detection.mp4: 384x640 2 Hardhats, 1 NO-Safety Vest, 2 Persons, 1405.2ms\nvideo 1/1 (frame 18/56) /kaggle/working/safety_detection.mp4: 384x640 2 Hardhats, 2 Persons, 1419.6ms\nvideo 1/1 (frame 19/56) /kaggle/working/safety_detection.mp4: 384x640 2 Hardhats, 2 Persons, 1428.3ms\nvideo 1/1 (frame 20/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 2 Persons, 1416.3ms\nvideo 1/1 (frame 21/56) /kaggle/working/safety_detection.mp4: 384x640 2 Hardhats, 2 Persons, 1386.4ms\nvideo 1/1 (frame 22/56) /kaggle/working/safety_detection.mp4: 384x640 2 Hardhats, 1 NO-Safety Vest, 2 Persons, 1433.9ms\nvideo 1/1 (frame 23/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Hardhat, 1 NO-Safety Vest, 2 Persons, 1375.3ms\nvideo 1/1 (frame 24/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 2 Persons, 1395.8ms\nvideo 1/1 (frame 25/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 2 Persons, 1416.4ms\nvideo 1/1 (frame 26/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 2 Persons, 1731.8ms\nvideo 1/1 (frame 27/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Hardhat, 2 Persons, 1456.9ms\nvideo 1/1 (frame 28/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Hardhat, 2 Persons, 1389.1ms\nvideo 1/1 (frame 29/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 2 Persons, 1400.2ms\nvideo 1/1 (frame 30/56) /kaggle/working/safety_detection.mp4: 384x640 1 Person, 1400.1ms\nvideo 1/1 (frame 31/56) /kaggle/working/safety_detection.mp4: 384x640 1 machinery, 1402.8ms\nvideo 1/1 (frame 32/56) /kaggle/working/safety_detection.mp4: 384x640 1 vehicle, 1355.0ms\nvideo 1/1 (frame 33/56) /kaggle/working/safety_detection.mp4: 384x640 1 machinery, 1 vehicle, 1353.6ms\nvideo 1/1 (frame 34/56) /kaggle/working/safety_detection.mp4: 384x640 1 NO-Hardhat, 1 Person, 1 machinery, 1381.9ms\nvideo 1/1 (frame 35/56) /kaggle/working/safety_detection.mp4: 384x640 1 NO-Hardhat, 1 Person, 1385.2ms\nvideo 1/1 (frame 36/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Hardhat, 1 Person, 1401.7ms\nvideo 1/1 (frame 37/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Hardhat, 1 Person, 1408.4ms\nvideo 1/1 (frame 38/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Hardhat, 1374.6ms\nvideo 1/1 (frame 39/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Hardhat, 1 Person, 1407.7ms\nvideo 1/1 (frame 40/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Hardhat, 1 Person, 1377.1ms\nvideo 1/1 (frame 41/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Hardhat, 1402.0ms\nvideo 1/1 (frame 42/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 Person, 1466.7ms\nvideo 1/1 (frame 43/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1539.6ms\nvideo 1/1 (frame 44/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 Person, 1398.5ms\nvideo 1/1 (frame 45/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 Person, 1 machinery, 1386.7ms\nvideo 1/1 (frame 46/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Hardhat, 1 Person, 1 machinery, 1368.0ms\nvideo 1/1 (frame 47/56) /kaggle/working/safety_detection.mp4: 384x640 1 NO-Hardhat, 3 Persons, 1386.0ms\nvideo 1/1 (frame 48/56) /kaggle/working/safety_detection.mp4: 384x640 1 NO-Safety Vest, 3 Persons, 1398.4ms\nvideo 1/1 (frame 49/56) /kaggle/working/safety_detection.mp4: 384x640 1 NO-Safety Vest, 3 Persons, 1405.8ms\nvideo 1/1 (frame 50/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Safety Vest, 3 Persons, 1420.7ms\nvideo 1/1 (frame 51/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Safety Vest, 2 Persons, 1351.4ms\nvideo 1/1 (frame 52/56) /kaggle/working/safety_detection.mp4: 384x640 1 NO-Safety Vest, 2 Persons, 1388.7ms\nvideo 1/1 (frame 53/56) /kaggle/working/safety_detection.mp4: 384x640 1 NO-Safety Vest, 2 Persons, 1388.6ms\nvideo 1/1 (frame 54/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Safety Vest, 1 Person, 1403.4ms\nvideo 1/1 (frame 55/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Safety Vest, 1 Person, 1390.9ms\nvideo 1/1 (frame 56/56) /kaggle/working/safety_detection.mp4: 384x640 1 Hardhat, 1 NO-Safety Vest, 2 Persons, 1372.6ms\nSpeed: 3.2ms preprocess, 1402.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\nSafety detection and video generation completed.\nFrames saved to 'frames/' and data saved to 'frame_data.json'.\n","output_type":"stream"}],"execution_count":16}]}