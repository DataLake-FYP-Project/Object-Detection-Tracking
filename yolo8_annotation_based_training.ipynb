{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBrkJac7SyRx"
      },
      "source": [
        "# Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivUDJbeWS2rF",
        "outputId": "b0ae804d-8a2d-409b-a2b9-891b0c38994c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.53-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.53-py3-none-any.whl (902 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m902.2/902.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.53 ultralytics-thop-2.0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "#!pip install ultralytics opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_oIEejebWXg2"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0VObujDS-cg"
      },
      "source": [
        "**Object detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RHHvIG2Tpoa",
        "outputId": "f4700c5c-cd89-48e2-e436-fecc00633eef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 384x640 7 persons, 1 car, 1 bus, 1 truck, 149.4ms\n",
            "Speed: 3.5ms preprocess, 149.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 1, FPS: 3.73\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 buss, 1 truck, 138.3ms\n",
            "Speed: 5.1ms preprocess, 138.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 2, FPS: 4.56\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 1 bus, 2 trucks, 169.8ms\n",
            "Speed: 5.2ms preprocess, 169.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 3, FPS: 4.69\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 2 cars, 1 motorcycle, 2 buss, 1 truck, 134.7ms\n",
            "Speed: 4.5ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 4, FPS: 4.96\n",
            "\n",
            "0: 384x640 6 persons, 1 bicycle, 2 cars, 1 motorcycle, 2 buss, 2 trucks, 135.3ms\n",
            "Speed: 4.6ms preprocess, 135.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 5, FPS: 5.14\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 motorcycle, 2 buss, 1 truck, 141.2ms\n",
            "Speed: 5.3ms preprocess, 141.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 6, FPS: 5.23\n",
            "\n",
            "0: 384x640 6 persons, 1 bicycle, 3 cars, 2 buss, 1 truck, 147.9ms\n",
            "Speed: 5.5ms preprocess, 147.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 7, FPS: 5.27\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 2 buss, 2 trucks, 145.9ms\n",
            "Speed: 4.9ms preprocess, 145.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 8, FPS: 5.28\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 2 buss, 1 truck, 164.5ms\n",
            "Speed: 3.5ms preprocess, 164.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 9, FPS: 5.25\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 2 buss, 1 truck, 141.3ms\n",
            "Speed: 4.7ms preprocess, 141.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 10, FPS: 5.25\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 buss, 1 truck, 141.5ms\n",
            "Speed: 4.7ms preprocess, 141.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 11, FPS: 5.28\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 2 buss, 1 truck, 147.9ms\n",
            "Speed: 5.2ms preprocess, 147.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 12, FPS: 5.30\n",
            "\n",
            "0: 384x640 7 persons, 1 bicycle, 2 cars, 2 buss, 143.7ms\n",
            "Speed: 5.7ms preprocess, 143.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 13, FPS: 5.33\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 buss, 1 truck, 1 traffic light, 194.1ms\n",
            "Speed: 5.1ms preprocess, 194.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 14, FPS: 5.25\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 4 cars, 2 buss, 1 traffic light, 149.2ms\n",
            "Speed: 5.8ms preprocess, 149.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 15, FPS: 5.25\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 5 cars, 3 buss, 1 traffic light, 146.6ms\n",
            "Speed: 5.2ms preprocess, 146.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 16, FPS: 5.26\n",
            "\n",
            "0: 384x640 4 persons, 3 bicycles, 3 cars, 3 buss, 2 traffic lights, 144.6ms\n",
            "Speed: 5.2ms preprocess, 144.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 17, FPS: 5.28\n",
            "\n",
            "0: 384x640 4 persons, 2 bicycles, 3 cars, 2 buss, 153.7ms\n",
            "Speed: 5.9ms preprocess, 153.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 18, FPS: 5.28\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 2 buss, 1 traffic light, 159.2ms\n",
            "Speed: 5.3ms preprocess, 159.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 19, FPS: 5.26\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 2 buss, 2 traffic lights, 150.9ms\n",
            "Speed: 5.5ms preprocess, 150.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 20, FPS: 5.27\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 2 buss, 144.3ms\n",
            "Speed: 5.6ms preprocess, 144.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 21, FPS: 5.28\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 2 buss, 1 traffic light, 145.5ms\n",
            "Speed: 5.6ms preprocess, 145.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 22, FPS: 5.27\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 2 buss, 1 traffic light, 145.8ms\n",
            "Speed: 5.9ms preprocess, 145.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 23, FPS: 5.28\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 2 buss, 149.0ms\n",
            "Speed: 5.1ms preprocess, 149.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 24, FPS: 5.29\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 buss, 2 traffic lights, 168.6ms\n",
            "Speed: 5.6ms preprocess, 168.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 25, FPS: 5.28\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 buss, 2 traffic lights, 148.5ms\n",
            "Speed: 5.2ms preprocess, 148.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 26, FPS: 5.28\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 2 buss, 2 traffic lights, 151.2ms\n",
            "Speed: 5.3ms preprocess, 151.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 27, FPS: 5.29\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 2 buss, 1 traffic light, 148.2ms\n",
            "Speed: 5.3ms preprocess, 148.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 28, FPS: 5.30\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 2 buss, 152.7ms\n",
            "Speed: 4.8ms preprocess, 152.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 29, FPS: 5.30\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 2 buss, 1 traffic light, 175.4ms\n",
            "Speed: 5.3ms preprocess, 175.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 30, FPS: 5.28\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 2 buss, 144.8ms\n",
            "Speed: 4.9ms preprocess, 144.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 31, FPS: 5.29\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 2 buss, 2 trucks, 1 traffic light, 157.0ms\n",
            "Speed: 4.7ms preprocess, 157.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 32, FPS: 5.28\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 3 buss, 1 truck, 1 traffic light, 194.6ms\n",
            "Speed: 5.2ms preprocess, 194.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 33, FPS: 5.25\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 3 buss, 1 truck, 1 traffic light, 249.1ms\n",
            "Speed: 8.5ms preprocess, 249.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 34, FPS: 5.16\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 3 buss, 1 traffic light, 243.3ms\n",
            "Speed: 6.0ms preprocess, 243.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 35, FPS: 5.10\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 3 buss, 1 truck, 229.1ms\n",
            "Speed: 6.6ms preprocess, 229.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 36, FPS: 5.05\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 2 buss, 1 truck, 219.9ms\n",
            "Speed: 5.2ms preprocess, 219.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 37, FPS: 5.00\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 buss, 1 truck, 1 traffic light, 235.7ms\n",
            "Speed: 5.4ms preprocess, 235.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 38, FPS: 4.96\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 buss, 1 truck, 2 traffic lights, 235.4ms\n",
            "Speed: 5.0ms preprocess, 235.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 39, FPS: 4.91\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 buss, 3 trucks, 2 traffic lights, 228.3ms\n",
            "Speed: 5.9ms preprocess, 228.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 40, FPS: 4.87\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 buss, 1 truck, 1 traffic light, 223.5ms\n",
            "Speed: 5.3ms preprocess, 223.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 41, FPS: 4.84\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 buss, 1 truck, 241.1ms\n",
            "Speed: 5.4ms preprocess, 241.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 42, FPS: 4.80\n",
            "\n",
            "0: 384x640 6 persons, 2 buss, 2 trucks, 223.4ms\n",
            "Speed: 5.5ms preprocess, 223.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 43, FPS: 4.77\n",
            "\n",
            "0: 384x640 6 persons, 2 buss, 1 truck, 222.5ms\n",
            "Speed: 9.3ms preprocess, 222.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 44, FPS: 4.74\n",
            "\n",
            "0: 384x640 7 persons, 2 buss, 1 truck, 227.2ms\n",
            "Speed: 5.3ms preprocess, 227.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 45, FPS: 4.71\n",
            "\n",
            "0: 384x640 7 persons, 2 buss, 1 truck, 1 traffic light, 251.3ms\n",
            "Speed: 5.4ms preprocess, 251.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 46, FPS: 4.67\n",
            "\n",
            "0: 384x640 4 persons, 2 buss, 1 truck, 262.2ms\n",
            "Speed: 5.2ms preprocess, 262.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 47, FPS: 4.63\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 motorcycle, 2 buss, 1 truck, 233.3ms\n",
            "Speed: 7.0ms preprocess, 233.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 48, FPS: 4.59\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 buss, 1 truck, 252.5ms\n",
            "Speed: 5.3ms preprocess, 252.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 49, FPS: 4.56\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 buss, 1 truck, 2 traffic lights, 154.0ms\n",
            "Speed: 5.0ms preprocess, 154.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 50, FPS: 4.57\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 buss, 2 trucks, 1 traffic light, 149.9ms\n",
            "Speed: 6.7ms preprocess, 149.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 51, FPS: 4.58\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 2 buss, 1 truck, 143.6ms\n",
            "Speed: 5.4ms preprocess, 143.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 52, FPS: 4.59\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 1 motorcycle, 2 buss, 1 truck, 153.5ms\n",
            "Speed: 5.5ms preprocess, 153.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 53, FPS: 4.60\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 2 motorcycles, 2 buss, 1 truck, 1 traffic light, 160.6ms\n",
            "Speed: 5.1ms preprocess, 160.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 54, FPS: 4.61\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 2 buss, 1 truck, 146.4ms\n",
            "Speed: 5.0ms preprocess, 146.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 55, FPS: 4.63\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 2 motorcycles, 2 buss, 1 truck, 1 traffic light, 154.3ms\n",
            "Speed: 5.1ms preprocess, 154.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 56, FPS: 4.64\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 2 buss, 1 truck, 1 traffic light, 143.7ms\n",
            "Speed: 4.7ms preprocess, 143.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 57, FPS: 4.65\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 1 truck, 143.7ms\n",
            "Speed: 4.7ms preprocess, 143.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 58, FPS: 4.67\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 1 truck, 156.4ms\n",
            "Speed: 5.1ms preprocess, 156.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 59, FPS: 4.67\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 2 buss, 1 truck, 146.3ms\n",
            "Speed: 5.7ms preprocess, 146.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 60, FPS: 4.68\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 motorcycles, 2 buss, 1 truck, 148.9ms\n",
            "Speed: 9.6ms preprocess, 148.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 61, FPS: 4.69\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 3 buss, 1 truck, 148.0ms\n",
            "Speed: 5.7ms preprocess, 148.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 62, FPS: 4.70\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 1 truck, 144.8ms\n",
            "Speed: 5.2ms preprocess, 144.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 63, FPS: 4.71\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 2 buss, 1 truck, 1 traffic light, 148.8ms\n",
            "Speed: 4.6ms preprocess, 148.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 64, FPS: 4.72\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 1 truck, 1 traffic light, 153.1ms\n",
            "Speed: 5.8ms preprocess, 153.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 65, FPS: 4.73\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 2 buss, 1 truck, 1 traffic light, 140.7ms\n",
            "Speed: 3.9ms preprocess, 140.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 66, FPS: 4.74\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 2 buss, 1 truck, 1 traffic light, 155.1ms\n",
            "Speed: 5.4ms preprocess, 155.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 67, FPS: 4.74\n",
            "\n",
            "0: 384x640 11 persons, 1 motorcycle, 2 buss, 1 truck, 1 traffic light, 144.4ms\n",
            "Speed: 5.6ms preprocess, 144.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 68, FPS: 4.75\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 motorcycle, 2 buss, 1 truck, 2 traffic lights, 151.4ms\n",
            "Speed: 5.4ms preprocess, 151.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 69, FPS: 4.76\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 motorcycles, 2 buss, 1 truck, 1 traffic light, 166.7ms\n",
            "Speed: 6.0ms preprocess, 166.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 70, FPS: 4.76\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 motorcycles, 2 buss, 1 truck, 141.6ms\n",
            "Speed: 5.2ms preprocess, 141.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 71, FPS: 4.77\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 2 motorcycles, 2 buss, 1 truck, 1 traffic light, 158.5ms\n",
            "Speed: 5.5ms preprocess, 158.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 72, FPS: 4.77\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 1 truck, 2 traffic lights, 153.3ms\n",
            "Speed: 8.6ms preprocess, 153.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 73, FPS: 4.78\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 2 buss, 1 truck, 1 traffic light, 146.6ms\n",
            "Speed: 4.7ms preprocess, 146.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 74, FPS: 4.79\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 1 truck, 1 traffic light, 163.7ms\n",
            "Speed: 4.2ms preprocess, 163.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 75, FPS: 4.79\n",
            "\n",
            "0: 384x640 10 persons, 2 buss, 1 truck, 1 traffic light, 148.4ms\n",
            "Speed: 5.1ms preprocess, 148.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 76, FPS: 4.80\n",
            "\n",
            "0: 384x640 8 persons, 1 bicycle, 2 buss, 1 truck, 1 traffic light, 148.9ms\n",
            "Speed: 5.1ms preprocess, 148.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 77, FPS: 4.81\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 1 motorcycle, 2 buss, 1 truck, 158.1ms\n",
            "Speed: 4.0ms preprocess, 158.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 78, FPS: 4.81\n",
            "\n",
            "0: 384x640 10 persons, 1 bicycle, 2 buss, 1 truck, 143.5ms\n",
            "Speed: 6.1ms preprocess, 143.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 79, FPS: 4.82\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 2 buss, 1 truck, 155.3ms\n",
            "Speed: 5.2ms preprocess, 155.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 80, FPS: 4.82\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 3 buss, 1 truck, 161.2ms\n",
            "Speed: 5.0ms preprocess, 161.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 81, FPS: 4.82\n",
            "\n",
            "0: 384x640 9 persons, 1 bicycle, 1 car, 2 buss, 1 truck, 1 traffic light, 142.5ms\n",
            "Speed: 7.4ms preprocess, 142.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 82, FPS: 4.83\n",
            "\n",
            "0: 384x640 8 persons, 1 bicycle, 3 buss, 1 truck, 1 traffic light, 149.3ms\n",
            "Speed: 5.3ms preprocess, 149.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 83, FPS: 4.83\n",
            "\n",
            "0: 384x640 10 persons, 2 bicycles, 3 buss, 1 truck, 1 traffic light, 145.0ms\n",
            "Speed: 6.3ms preprocess, 145.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 84, FPS: 4.84\n",
            "\n",
            "0: 384x640 8 persons, 3 buss, 1 truck, 1 traffic light, 147.4ms\n",
            "Speed: 3.8ms preprocess, 147.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 85, FPS: 4.84\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 2 buss, 1 truck, 157.7ms\n",
            "Speed: 7.4ms preprocess, 157.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 86, FPS: 4.85\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 2 buss, 1 truck, 1 traffic light, 146.5ms\n",
            "Speed: 5.0ms preprocess, 146.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 87, FPS: 4.85\n",
            "\n",
            "0: 384x640 8 persons, 1 bicycle, 1 car, 2 buss, 1 truck, 149.6ms\n",
            "Speed: 6.4ms preprocess, 149.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 88, FPS: 4.86\n",
            "\n",
            "0: 384x640 8 persons, 1 bicycle, 1 motorcycle, 2 buss, 1 truck, 166.1ms\n",
            "Speed: 5.5ms preprocess, 166.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 89, FPS: 4.86\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 2 buss, 1 truck, 149.9ms\n",
            "Speed: 5.4ms preprocess, 149.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 90, FPS: 4.86\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 1 truck, 168.1ms\n",
            "Speed: 5.8ms preprocess, 168.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 91, FPS: 4.86\n",
            "\n",
            "0: 384x640 10 persons, 2 buss, 1 truck, 142.1ms\n",
            "Speed: 5.3ms preprocess, 142.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 92, FPS: 4.87\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 2 buss, 1 truck, 147.7ms\n",
            "Speed: 5.0ms preprocess, 147.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 93, FPS: 4.88\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 2 buss, 1 truck, 144.8ms\n",
            "Speed: 4.9ms preprocess, 144.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 94, FPS: 4.88\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 2 buss, 1 truck, 145.0ms\n",
            "Speed: 4.4ms preprocess, 145.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 95, FPS: 4.89\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 buss, 1 truck, 178.5ms\n",
            "Speed: 3.9ms preprocess, 178.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 96, FPS: 4.88\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 2 buss, 1 truck, 142.2ms\n",
            "Speed: 4.2ms preprocess, 142.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 97, FPS: 4.89\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 motorcycle, 2 buss, 1 truck, 153.1ms\n",
            "Speed: 5.6ms preprocess, 153.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 98, FPS: 4.89\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 motorcycle, 2 buss, 1 truck, 146.6ms\n",
            "Speed: 5.6ms preprocess, 146.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 99, FPS: 4.90\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 2 motorcycles, 2 buss, 1 truck, 157.2ms\n",
            "Speed: 4.0ms preprocess, 157.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 100, FPS: 4.90\n",
            "\n",
            "0: 384x640 10 persons, 2 motorcycles, 2 buss, 1 truck, 160.1ms\n",
            "Speed: 5.5ms preprocess, 160.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 101, FPS: 4.90\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 2 buss, 1 truck, 1 traffic light, 153.0ms\n",
            "Speed: 7.0ms preprocess, 153.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 102, FPS: 4.90\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 2 buss, 1 truck, 1 traffic light, 261.2ms\n",
            "Speed: 7.6ms preprocess, 261.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 103, FPS: 4.88\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 2 buss, 1 truck, 1 traffic light, 228.7ms\n",
            "Speed: 5.4ms preprocess, 228.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 104, FPS: 4.86\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 2 buss, 1 truck, 2 traffic lights, 228.2ms\n",
            "Speed: 6.5ms preprocess, 228.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 105, FPS: 4.85\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 2 buss, 1 truck, 2 traffic lights, 223.3ms\n",
            "Speed: 5.5ms preprocess, 223.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 106, FPS: 4.83\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 motorcycle, 2 buss, 2 trucks, 2 traffic lights, 221.5ms\n",
            "Speed: 8.5ms preprocess, 221.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 107, FPS: 4.82\n",
            "\n",
            "0: 384x640 10 persons, 2 motorcycles, 2 buss, 2 trucks, 2 traffic lights, 248.6ms\n",
            "Speed: 7.8ms preprocess, 248.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 108, FPS: 4.80\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 2 buss, 3 trucks, 2 traffic lights, 243.1ms\n",
            "Speed: 7.0ms preprocess, 243.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 109, FPS: 4.78\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 2 buss, 2 trucks, 2 traffic lights, 229.0ms\n",
            "Speed: 5.5ms preprocess, 229.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 110, FPS: 4.77\n",
            "\n",
            "0: 384x640 9 persons, 2 buss, 3 trucks, 2 traffic lights, 248.2ms\n",
            "Speed: 8.6ms preprocess, 248.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 111, FPS: 4.75\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 3 trucks, 2 traffic lights, 227.1ms\n",
            "Speed: 8.4ms preprocess, 227.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 112, FPS: 4.74\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 3 trucks, 2 traffic lights, 230.1ms\n",
            "Speed: 5.0ms preprocess, 230.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 113, FPS: 4.73\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 2 buss, 2 trucks, 2 traffic lights, 228.8ms\n",
            "Speed: 5.1ms preprocess, 228.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 114, FPS: 4.71\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 2 trucks, 2 traffic lights, 236.2ms\n",
            "Speed: 5.2ms preprocess, 236.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 115, FPS: 4.70\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 2 trucks, 2 traffic lights, 252.4ms\n",
            "Speed: 5.5ms preprocess, 252.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 116, FPS: 4.69\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 2 buss, 2 trucks, 2 traffic lights, 289.3ms\n",
            "Speed: 6.5ms preprocess, 289.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 117, FPS: 4.66\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 3 trucks, 3 traffic lights, 237.7ms\n",
            "Speed: 5.8ms preprocess, 237.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 118, FPS: 4.65\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 2 buss, 3 trucks, 3 traffic lights, 282.0ms\n",
            "Speed: 6.5ms preprocess, 282.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 119, FPS: 4.63\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 4 trucks, 3 traffic lights, 151.3ms\n",
            "Speed: 4.8ms preprocess, 151.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 120, FPS: 4.63\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 2 buss, 4 trucks, 3 traffic lights, 159.3ms\n",
            "Speed: 5.3ms preprocess, 159.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 121, FPS: 4.64\n",
            "\n",
            "0: 384x640 9 persons, 2 buss, 3 trucks, 3 traffic lights, 156.3ms\n",
            "Speed: 6.6ms preprocess, 156.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 122, FPS: 4.64\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 4 trucks, 3 traffic lights, 165.1ms\n",
            "Speed: 5.5ms preprocess, 165.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 123, FPS: 4.64\n",
            "\n",
            "0: 384x640 9 persons, 2 buss, 2 trucks, 2 traffic lights, 194.3ms\n",
            "Speed: 5.0ms preprocess, 194.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 124, FPS: 4.64\n",
            "\n",
            "0: 384x640 11 persons, 2 buss, 2 trucks, 2 traffic lights, 162.1ms\n",
            "Speed: 5.2ms preprocess, 162.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 125, FPS: 4.64\n",
            "\n",
            "0: 384x640 11 persons, 2 buss, 2 trucks, 2 traffic lights, 168.7ms\n",
            "Speed: 4.3ms preprocess, 168.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 126, FPS: 4.64\n",
            "\n",
            "0: 384x640 11 persons, 2 buss, 2 trucks, 1 traffic light, 142.7ms\n",
            "Speed: 5.1ms preprocess, 142.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 127, FPS: 4.65\n",
            "\n",
            "0: 384x640 11 persons, 2 buss, 2 trucks, 1 traffic light, 146.8ms\n",
            "Speed: 6.2ms preprocess, 146.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 128, FPS: 4.66\n",
            "\n",
            "0: 384x640 12 persons, 2 buss, 2 trucks, 1 traffic light, 178.7ms\n",
            "Speed: 5.2ms preprocess, 178.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 129, FPS: 4.66\n",
            "\n",
            "0: 384x640 10 persons, 2 buss, 2 trucks, 1 traffic light, 143.6ms\n",
            "Speed: 5.5ms preprocess, 143.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 130, FPS: 4.66\n",
            "\n",
            "0: 384x640 9 persons, 2 buss, 2 trucks, 1 traffic light, 157.5ms\n",
            "Speed: 5.5ms preprocess, 157.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 131, FPS: 4.66\n",
            "\n",
            "0: 384x640 9 persons, 2 buss, 2 trucks, 1 traffic light, 169.7ms\n",
            "Speed: 5.6ms preprocess, 169.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 132, FPS: 4.67\n",
            "\n",
            "0: 384x640 11 persons, 1 motorcycle, 2 buss, 2 trucks, 1 traffic light, 146.0ms\n",
            "Speed: 5.3ms preprocess, 146.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 133, FPS: 4.67\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 1 bus, 2 trucks, 1 traffic light, 170.7ms\n",
            "Speed: 6.3ms preprocess, 170.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 134, FPS: 4.67\n",
            "\n",
            "0: 384x640 7 persons, 1 motorcycle, 1 bus, 2 trucks, 1 traffic light, 156.0ms\n",
            "Speed: 6.5ms preprocess, 156.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 135, FPS: 4.67\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 1 bus, 2 trucks, 1 traffic light, 155.6ms\n",
            "Speed: 5.3ms preprocess, 155.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 136, FPS: 4.68\n",
            "\n",
            "0: 384x640 7 persons, 1 motorcycle, 1 bus, 2 trucks, 1 traffic light, 151.4ms\n",
            "Speed: 5.0ms preprocess, 151.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 137, FPS: 4.68\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 1 bus, 2 trucks, 1 traffic light, 148.9ms\n",
            "Speed: 5.3ms preprocess, 148.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 138, FPS: 4.69\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 2 trucks, 2 traffic lights, 158.8ms\n",
            "Speed: 5.3ms preprocess, 158.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 139, FPS: 4.69\n",
            "\n",
            "0: 384x640 12 persons, 1 motorcycle, 1 bus, 2 trucks, 2 traffic lights, 159.7ms\n",
            "Speed: 5.2ms preprocess, 159.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 140, FPS: 4.69\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 2 buss, 2 trucks, 2 traffic lights, 146.2ms\n",
            "Speed: 5.2ms preprocess, 146.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 141, FPS: 4.70\n",
            "\n",
            "0: 384x640 11 persons, 1 motorcycle, 2 buss, 2 trucks, 1 traffic light, 158.3ms\n",
            "Speed: 8.7ms preprocess, 158.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 142, FPS: 4.70\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 1 bus, 2 trucks, 1 traffic light, 148.2ms\n",
            "Speed: 6.7ms preprocess, 148.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 143, FPS: 4.70\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 2 trucks, 152.8ms\n",
            "Speed: 5.3ms preprocess, 152.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 144, FPS: 4.70\n",
            "\n",
            "0: 384x640 8 persons, 1 bicycle, 1 motorcycle, 1 bus, 2 trucks, 167.1ms\n",
            "Speed: 6.8ms preprocess, 167.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 145, FPS: 4.70\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 1 bus, 2 trucks, 142.0ms\n",
            "Speed: 5.9ms preprocess, 142.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 146, FPS: 4.71\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 1 bus, 2 trucks, 146.0ms\n",
            "Speed: 5.6ms preprocess, 146.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 147, FPS: 4.71\n",
            "\n",
            "0: 384x640 11 persons, 1 motorcycle, 1 bus, 2 trucks, 141.1ms\n",
            "Speed: 6.0ms preprocess, 141.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 148, FPS: 4.72\n",
            "\n",
            "0: 384x640 11 persons, 1 motorcycle, 1 bus, 2 trucks, 149.2ms\n",
            "Speed: 5.5ms preprocess, 149.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 149, FPS: 4.72\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 1 bus, 2 trucks, 157.1ms\n",
            "Speed: 7.1ms preprocess, 157.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 150, FPS: 4.72\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 1 bus, 2 trucks, 162.4ms\n",
            "Speed: 4.9ms preprocess, 162.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 151, FPS: 4.73\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 1 bus, 2 trucks, 142.4ms\n",
            "Speed: 6.0ms preprocess, 142.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 152, FPS: 4.73\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 1 bus, 2 trucks, 1 traffic light, 140.8ms\n",
            "Speed: 5.8ms preprocess, 140.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 153, FPS: 4.74\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 2 buss, 1 truck, 2 traffic lights, 142.3ms\n",
            "Speed: 5.1ms preprocess, 142.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 154, FPS: 4.74\n",
            "\n",
            "0: 384x640 9 persons, 1 bicycle, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 165.8ms\n",
            "Speed: 5.2ms preprocess, 165.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 155, FPS: 4.74\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 1 bus, 1 truck, 148.4ms\n",
            "Speed: 5.9ms preprocess, 148.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 156, FPS: 4.75\n",
            "\n",
            "0: 384x640 8 persons, 1 bicycle, 1 motorcycle, 1 bus, 1 truck, 141.9ms\n",
            "Speed: 5.0ms preprocess, 141.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 157, FPS: 4.75\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 165.8ms\n",
            "Speed: 3.8ms preprocess, 165.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 158, FPS: 4.75\n",
            "\n",
            "0: 384x640 7 persons, 1 bicycle, 1 motorcycle, 1 bus, 1 truck, 142.6ms\n",
            "Speed: 4.8ms preprocess, 142.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 159, FPS: 4.76\n",
            "\n",
            "0: 384x640 7 persons, 1 bicycle, 1 motorcycle, 1 bus, 1 truck, 154.0ms\n",
            "Speed: 5.8ms preprocess, 154.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 160, FPS: 4.76\n",
            "\n",
            "0: 384x640 7 persons, 1 bicycle, 1 motorcycle, 1 bus, 1 truck, 162.0ms\n",
            "Speed: 5.9ms preprocess, 162.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 161, FPS: 4.76\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 1 bus, 1 truck, 159.6ms\n",
            "Speed: 5.6ms preprocess, 159.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 162, FPS: 4.76\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 1 bus, 1 truck, 1 dog, 149.0ms\n",
            "Speed: 5.7ms preprocess, 149.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 163, FPS: 4.76\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 1 bus, 1 truck, 1 dog, 148.6ms\n",
            "Speed: 4.2ms preprocess, 148.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 164, FPS: 4.77\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 1 bus, 1 truck, 143.0ms\n",
            "Speed: 5.1ms preprocess, 143.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 165, FPS: 4.77\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 1 bus, 1 truck, 1 dog, 160.9ms\n",
            "Speed: 5.1ms preprocess, 160.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 166, FPS: 4.77\n",
            "\n",
            "0: 384x640 7 persons, 1 motorcycle, 1 bus, 1 truck, 159.1ms\n",
            "Speed: 6.5ms preprocess, 159.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 167, FPS: 4.77\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 1 bus, 1 truck, 1 dog, 161.3ms\n",
            "Speed: 6.2ms preprocess, 161.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 168, FPS: 4.77\n",
            "\n",
            "0: 384x640 7 persons, 1 motorcycle, 1 bus, 1 truck, 1 dog, 153.7ms\n",
            "Speed: 5.6ms preprocess, 153.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 169, FPS: 4.78\n",
            "\n",
            "0: 384x640 6 persons, 1 motorcycle, 1 bus, 1 truck, 1 dog, 154.8ms\n",
            "Speed: 7.2ms preprocess, 154.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 170, FPS: 4.78\n",
            "\n",
            "0: 384x640 5 persons, 1 motorcycle, 1 bus, 1 truck, 2 traffic lights, 200.6ms\n",
            "Speed: 6.4ms preprocess, 200.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 171, FPS: 4.77\n",
            "\n",
            "0: 384x640 5 persons, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 239.8ms\n",
            "Speed: 5.7ms preprocess, 239.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 172, FPS: 4.76\n",
            "\n",
            "0: 384x640 5 persons, 1 motorcycle, 1 bus, 1 truck, 2 traffic lights, 265.5ms\n",
            "Speed: 3.3ms preprocess, 265.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 173, FPS: 4.75\n",
            "\n",
            "0: 384x640 5 persons, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 233.3ms\n",
            "Speed: 8.7ms preprocess, 233.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 174, FPS: 4.74\n",
            "\n",
            "0: 384x640 5 persons, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 217.3ms\n",
            "Speed: 7.4ms preprocess, 217.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 175, FPS: 4.73\n",
            "\n",
            "0: 384x640 4 persons, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 247.5ms\n",
            "Speed: 5.1ms preprocess, 247.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 176, FPS: 4.72\n",
            "\n",
            "0: 384x640 4 persons, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 219.0ms\n",
            "Speed: 5.4ms preprocess, 219.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 177, FPS: 4.72\n",
            "\n",
            "0: 384x640 6 persons, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 243.7ms\n",
            "Speed: 7.7ms preprocess, 243.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 178, FPS: 4.71\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 222.1ms\n",
            "Speed: 6.7ms preprocess, 222.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 179, FPS: 4.70\n",
            "\n",
            "0: 384x640 4 persons, 2 motorcycles, 1 bus, 2 trucks, 221.8ms\n",
            "Speed: 9.3ms preprocess, 221.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 180, FPS: 4.69\n",
            "\n",
            "0: 384x640 6 persons, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 211.2ms\n",
            "Speed: 5.0ms preprocess, 211.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 181, FPS: 4.69\n",
            "\n",
            "0: 384x640 7 persons, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 219.1ms\n",
            "Speed: 5.3ms preprocess, 219.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 182, FPS: 4.68\n",
            "\n",
            "0: 384x640 7 persons, 2 motorcycles, 1 bus, 1 truck, 226.9ms\n",
            "Speed: 5.2ms preprocess, 226.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 183, FPS: 4.67\n",
            "\n",
            "0: 384x640 7 persons, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 253.9ms\n",
            "Speed: 7.2ms preprocess, 253.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 184, FPS: 4.66\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 1 bus, 1 truck, 227.2ms\n",
            "Speed: 5.2ms preprocess, 227.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 185, FPS: 4.65\n",
            "\n",
            "0: 384x640 7 persons, 2 motorcycles, 1 bus, 1 truck, 2 traffic lights, 237.5ms\n",
            "Speed: 9.3ms preprocess, 237.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 186, FPS: 4.65\n",
            "\n",
            "0: 384x640 7 persons, 2 motorcycles, 1 bus, 1 truck, 3 traffic lights, 237.1ms\n",
            "Speed: 5.2ms preprocess, 237.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 187, FPS: 4.64\n",
            "\n",
            "0: 384x640 6 persons, 2 motorcycles, 1 bus, 1 truck, 2 traffic lights, 165.7ms\n",
            "Speed: 6.7ms preprocess, 165.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 188, FPS: 4.64\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 1 bus, 1 truck, 174.6ms\n",
            "Speed: 5.8ms preprocess, 174.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 189, FPS: 4.64\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 148.0ms\n",
            "Speed: 5.4ms preprocess, 148.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 190, FPS: 4.64\n",
            "\n",
            "0: 384x640 8 persons, 3 motorcycles, 1 bus, 1 truck, 150.2ms\n",
            "Speed: 5.7ms preprocess, 150.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 191, FPS: 4.64\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 154.8ms\n",
            "Speed: 5.5ms preprocess, 154.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 192, FPS: 4.65\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 2 buss, 1 truck, 142.8ms\n",
            "Speed: 5.1ms preprocess, 142.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 193, FPS: 4.65\n",
            "\n",
            "0: 384x640 5 persons, 2 motorcycles, 2 buss, 1 truck, 154.1ms\n",
            "Speed: 4.5ms preprocess, 154.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 194, FPS: 4.65\n",
            "\n",
            "0: 384x640 5 persons, 2 motorcycles, 1 bus, 1 truck, 149.5ms\n",
            "Speed: 4.1ms preprocess, 149.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 195, FPS: 4.66\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 140.1ms\n",
            "Speed: 4.9ms preprocess, 140.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 196, FPS: 4.66\n",
            "\n",
            "0: 384x640 8 persons, 3 motorcycles, 1 bus, 1 truck, 1 traffic light, 139.0ms\n",
            "Speed: 5.1ms preprocess, 139.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 197, FPS: 4.67\n",
            "\n",
            "0: 384x640 9 persons, 3 motorcycles, 2 buss, 160.8ms\n",
            "Speed: 5.5ms preprocess, 160.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 198, FPS: 4.67\n",
            "\n",
            "0: 384x640 7 persons, 3 motorcycles, 1 bus, 150.7ms\n",
            "Speed: 4.6ms preprocess, 150.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 199, FPS: 4.67\n",
            "\n",
            "0: 384x640 6 persons, 2 motorcycles, 1 bus, 143.3ms\n",
            "Speed: 4.2ms preprocess, 143.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 200, FPS: 4.67\n",
            "\n",
            "0: 384x640 5 persons, 2 motorcycles, 1 bus, 140.5ms\n",
            "Speed: 5.9ms preprocess, 140.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 201, FPS: 4.68\n",
            "\n",
            "0: 384x640 6 persons, 2 motorcycles, 1 bus, 139.6ms\n",
            "Speed: 5.2ms preprocess, 139.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 202, FPS: 4.68\n",
            "\n",
            "0: 384x640 6 persons, 2 motorcycles, 1 bus, 136.7ms\n",
            "Speed: 5.1ms preprocess, 136.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 203, FPS: 4.69\n",
            "\n",
            "0: 384x640 7 persons, 3 motorcycles, 1 bus, 167.9ms\n",
            "Speed: 5.2ms preprocess, 167.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 204, FPS: 4.69\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 motorcycles, 1 bus, 157.7ms\n",
            "Speed: 4.5ms preprocess, 157.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 205, FPS: 4.69\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 2 motorcycles, 1 bus, 142.2ms\n",
            "Speed: 5.3ms preprocess, 142.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 206, FPS: 4.69\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 2 motorcycles, 1 bus, 1 traffic light, 151.0ms\n",
            "Speed: 5.2ms preprocess, 151.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 207, FPS: 4.69\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 4 motorcycles, 1 bus, 1 traffic light, 143.3ms\n",
            "Speed: 6.7ms preprocess, 143.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 208, FPS: 4.70\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 bus, 1 traffic light, 158.0ms\n",
            "Speed: 3.0ms preprocess, 158.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 209, FPS: 4.70\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 4 motorcycles, 1 bus, 1 truck, 1 traffic light, 173.3ms\n",
            "Speed: 4.8ms preprocess, 173.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 210, FPS: 4.70\n",
            "\n",
            "0: 384x640 4 persons, 4 motorcycles, 1 bus, 1 truck, 1 traffic light, 143.9ms\n",
            "Speed: 5.2ms preprocess, 143.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 211, FPS: 4.71\n",
            "\n",
            "0: 384x640 5 persons, 4 motorcycles, 1 bus, 1 truck, 1 traffic light, 144.8ms\n",
            "Speed: 6.1ms preprocess, 144.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 212, FPS: 4.71\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 3 motorcycles, 1 bus, 1 truck, 2 traffic lights, 141.4ms\n",
            "Speed: 8.0ms preprocess, 141.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 213, FPS: 4.71\n",
            "\n",
            "0: 384x640 5 persons, 2 motorcycles, 1 bus, 1 truck, 2 traffic lights, 156.5ms\n",
            "Speed: 5.2ms preprocess, 156.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 214, FPS: 4.71\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 3 motorcycles, 1 bus, 1 truck, 1 traffic light, 167.4ms\n",
            "Speed: 5.3ms preprocess, 167.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 215, FPS: 4.71\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 150.6ms\n",
            "Speed: 5.3ms preprocess, 150.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 216, FPS: 4.71\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 146.3ms\n",
            "Speed: 4.6ms preprocess, 146.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 217, FPS: 4.72\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 142.2ms\n",
            "Speed: 6.7ms preprocess, 142.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 218, FPS: 4.72\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 141.9ms\n",
            "Speed: 4.8ms preprocess, 141.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 219, FPS: 4.72\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 160.7ms\n",
            "Speed: 6.7ms preprocess, 160.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 220, FPS: 4.73\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 149.2ms\n",
            "Speed: 7.1ms preprocess, 149.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 221, FPS: 4.73\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 2 motorcycles, 1 bus, 1 traffic light, 145.7ms\n",
            "Speed: 4.4ms preprocess, 145.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 222, FPS: 4.73\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 motorcycles, 1 bus, 159.3ms\n",
            "Speed: 5.1ms preprocess, 159.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 223, FPS: 4.73\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 motorcycles, 1 bus, 142.7ms\n",
            "Speed: 5.2ms preprocess, 142.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 224, FPS: 4.74\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 motorcycles, 1 bus, 139.8ms\n",
            "Speed: 5.3ms preprocess, 139.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 225, FPS: 4.74\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 2 motorcycles, 1 bus, 170.0ms\n",
            "Speed: 5.1ms preprocess, 170.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 226, FPS: 4.74\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 motorcycles, 1 bus, 166.2ms\n",
            "Speed: 6.3ms preprocess, 166.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 227, FPS: 4.74\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 2 motorcycles, 1 bus, 144.9ms\n",
            "Speed: 5.1ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 228, FPS: 4.74\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 3 motorcycles, 2 buss, 1 traffic light, 144.7ms\n",
            "Speed: 6.7ms preprocess, 144.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 229, FPS: 4.75\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 3 motorcycles, 1 bus, 2 traffic lights, 151.6ms\n",
            "Speed: 6.7ms preprocess, 151.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 230, FPS: 4.75\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 motorcycles, 1 bus, 2 traffic lights, 164.1ms\n",
            "Speed: 4.9ms preprocess, 164.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 231, FPS: 4.75\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 2 motorcycles, 1 bus, 2 traffic lights, 137.9ms\n",
            "Speed: 4.9ms preprocess, 137.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 232, FPS: 4.75\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 2 motorcycles, 1 bus, 1 traffic light, 145.9ms\n",
            "Speed: 5.5ms preprocess, 145.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 233, FPS: 4.75\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 2 motorcycles, 1 bus, 1 truck, 1 traffic light, 161.9ms\n",
            "Speed: 5.9ms preprocess, 161.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 234, FPS: 4.75\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 3 motorcycles, 1 bus, 1 truck, 2 traffic lights, 139.6ms\n",
            "Speed: 6.0ms preprocess, 139.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 235, FPS: 4.76\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 1 traffic light, 166.5ms\n",
            "Speed: 5.2ms preprocess, 166.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 236, FPS: 4.76\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 2 traffic lights, 146.5ms\n",
            "Speed: 7.1ms preprocess, 146.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 237, FPS: 4.76\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 motorcycles, 1 bus, 5 trucks, 2 traffic lights, 144.3ms\n",
            "Speed: 6.0ms preprocess, 144.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 238, FPS: 4.76\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 4 motorcycles, 1 bus, 1 truck, 153.5ms\n",
            "Speed: 8.1ms preprocess, 153.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 239, FPS: 4.76\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 3 motorcycles, 2 trucks, 139.8ms\n",
            "Speed: 5.1ms preprocess, 139.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 240, FPS: 4.77\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 4 motorcycles, 2 trucks, 205.9ms\n",
            "Speed: 6.0ms preprocess, 205.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 241, FPS: 4.76\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 4 motorcycles, 2 trucks, 226.6ms\n",
            "Speed: 5.0ms preprocess, 226.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 242, FPS: 4.76\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 4 motorcycles, 3 trucks, 224.9ms\n",
            "Speed: 12.1ms preprocess, 224.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 243, FPS: 4.75\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 4 motorcycles, 3 trucks, 220.1ms\n",
            "Speed: 7.1ms preprocess, 220.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 244, FPS: 4.74\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 5 motorcycles, 5 trucks, 2 traffic lights, 223.0ms\n",
            "Speed: 7.9ms preprocess, 223.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 245, FPS: 4.74\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 5 motorcycles, 1 bus, 2 trucks, 2 traffic lights, 211.9ms\n",
            "Speed: 5.8ms preprocess, 211.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 246, FPS: 4.73\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 bus, 2 trucks, 1 traffic light, 1 dog, 234.1ms\n",
            "Speed: 8.2ms preprocess, 234.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 247, FPS: 4.73\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 5 motorcycles, 1 bus, 2 trucks, 1 traffic light, 1 dog, 246.8ms\n",
            "Speed: 8.3ms preprocess, 246.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 248, FPS: 4.72\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 6 motorcycles, 1 bus, 2 trucks, 1 traffic light, 1 dog, 236.3ms\n",
            "Speed: 5.8ms preprocess, 236.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 249, FPS: 4.71\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 4 motorcycles, 2 buss, 2 trucks, 1 traffic light, 1 dog, 230.2ms\n",
            "Speed: 5.1ms preprocess, 230.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 250, FPS: 4.71\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 3 motorcycles, 1 bus, 2 trucks, 1 traffic light, 1 dog, 230.2ms\n",
            "Speed: 5.3ms preprocess, 230.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 251, FPS: 4.70\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 3 motorcycles, 1 bus, 1 truck, 1 traffic light, 1 dog, 227.7ms\n",
            "Speed: 7.9ms preprocess, 227.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 252, FPS: 4.70\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 3 motorcycles, 2 buss, 1 truck, 1 traffic light, 1 dog, 226.6ms\n",
            "Speed: 6.4ms preprocess, 226.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 253, FPS: 4.69\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 3 motorcycles, 2 buss, 1 truck, 1 traffic light, 1 dog, 249.2ms\n",
            "Speed: 8.8ms preprocess, 249.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 254, FPS: 4.69\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 3 motorcycles, 1 truck, 1 traffic light, 1 dog, 246.7ms\n",
            "Speed: 6.6ms preprocess, 246.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 255, FPS: 4.68\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 3 motorcycles, 2 trucks, 1 traffic light, 1 dog, 241.7ms\n",
            "Speed: 7.1ms preprocess, 241.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 256, FPS: 4.67\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 3 motorcycles, 1 bus, 2 trucks, 1 traffic light, 1 dog, 249.0ms\n",
            "Speed: 5.3ms preprocess, 249.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 257, FPS: 4.66\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 3 motorcycles, 1 bus, 2 trucks, 1 traffic light, 1 dog, 198.3ms\n",
            "Speed: 6.4ms preprocess, 198.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 258, FPS: 4.66\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 1 traffic light, 1 fire hydrant, 1 dog, 147.4ms\n",
            "Speed: 6.0ms preprocess, 147.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 259, FPS: 4.67\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 1 traffic light, 1 dog, 165.6ms\n",
            "Speed: 5.9ms preprocess, 165.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 260, FPS: 4.67\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 1 traffic light, 1 dog, 140.2ms\n",
            "Speed: 5.2ms preprocess, 140.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 261, FPS: 4.67\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 1 dog, 169.5ms\n",
            "Speed: 6.6ms preprocess, 169.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 262, FPS: 4.67\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 1 dog, 148.0ms\n",
            "Speed: 5.7ms preprocess, 148.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 263, FPS: 4.67\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 3 motorcycles, 2 buss, 2 trucks, 1 dog, 142.3ms\n",
            "Speed: 5.6ms preprocess, 142.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 264, FPS: 4.67\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 3 motorcycles, 1 bus, 2 trucks, 2 dogs, 161.9ms\n",
            "Speed: 5.4ms preprocess, 161.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 265, FPS: 4.67\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 3 motorcycles, 2 buss, 1 truck, 1 dog, 143.1ms\n",
            "Speed: 4.0ms preprocess, 143.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 266, FPS: 4.68\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 3 motorcycles, 1 bus, 2 trucks, 1 dog, 164.6ms\n",
            "Speed: 5.8ms preprocess, 164.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 267, FPS: 4.68\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 3 motorcycles, 1 bus, 2 trucks, 1 traffic light, 1 dog, 143.7ms\n",
            "Speed: 5.7ms preprocess, 143.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 268, FPS: 4.68\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 3 motorcycles, 1 bus, 2 trucks, 1 traffic light, 1 dog, 143.4ms\n",
            "Speed: 5.5ms preprocess, 143.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 269, FPS: 4.68\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 3 motorcycles, 1 bus, 2 trucks, 1 dog, 154.0ms\n",
            "Speed: 6.7ms preprocess, 154.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 270, FPS: 4.69\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 4 motorcycles, 1 bus, 2 trucks, 1 dog, 157.2ms\n",
            "Speed: 5.8ms preprocess, 157.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 271, FPS: 4.69\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 3 motorcycles, 2 trucks, 163.7ms\n",
            "Speed: 5.6ms preprocess, 163.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 272, FPS: 4.69\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 3 motorcycles, 1 bus, 2 trucks, 172.8ms\n",
            "Speed: 5.9ms preprocess, 172.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 273, FPS: 4.69\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 3 motorcycles, 1 bus, 2 trucks, 151.6ms\n",
            "Speed: 5.4ms preprocess, 151.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 274, FPS: 4.69\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 1 traffic light, 159.9ms\n",
            "Speed: 5.3ms preprocess, 159.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 275, FPS: 4.69\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 3 motorcycles, 1 bus, 2 trucks, 1 traffic light, 149.2ms\n",
            "Speed: 5.7ms preprocess, 149.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 276, FPS: 4.69\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 2 motorcycles, 2 trucks, 1 traffic light, 146.8ms\n",
            "Speed: 7.0ms preprocess, 146.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 277, FPS: 4.69\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 2 motorcycles, 2 trucks, 155.7ms\n",
            "Speed: 5.9ms preprocess, 155.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 278, FPS: 4.70\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 motorcycles, 1 bus, 2 trucks, 1 traffic light, 146.9ms\n",
            "Speed: 5.0ms preprocess, 146.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 279, FPS: 4.70\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 motorcycles, 2 trucks, 1 traffic light, 145.5ms\n",
            "Speed: 6.0ms preprocess, 145.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 280, FPS: 4.70\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 3 motorcycles, 3 trucks, 1 traffic light, 174.3ms\n",
            "Speed: 7.7ms preprocess, 174.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 281, FPS: 4.70\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 3 motorcycles, 2 trucks, 1 traffic light, 142.3ms\n",
            "Speed: 5.7ms preprocess, 142.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 282, FPS: 4.70\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 3 motorcycles, 2 trucks, 1 traffic light, 171.2ms\n",
            "Speed: 5.2ms preprocess, 171.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 283, FPS: 4.70\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 3 motorcycles, 2 trucks, 1 traffic light, 141.5ms\n",
            "Speed: 5.2ms preprocess, 141.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 284, FPS: 4.71\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 3 motorcycles, 2 trucks, 1 traffic light, 153.5ms\n",
            "Speed: 3.9ms preprocess, 153.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 285, FPS: 4.71\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 4 motorcycles, 2 trucks, 1 traffic light, 163.9ms\n",
            "Speed: 5.2ms preprocess, 163.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 286, FPS: 4.71\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 4 motorcycles, 2 trucks, 1 traffic light, 145.0ms\n",
            "Speed: 5.4ms preprocess, 145.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 287, FPS: 4.71\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 4 motorcycles, 2 trucks, 2 traffic lights, 157.6ms\n",
            "Speed: 5.6ms preprocess, 157.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 288, FPS: 4.71\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 motorcycles, 2 trucks, 2 traffic lights, 148.1ms\n",
            "Speed: 5.0ms preprocess, 148.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed Frame: 289, FPS: 4.71\n",
            "Processed 289 frames.\n",
            "Annotated video saved at: /content/drive/MyDrive/FYP/output_video/output_video_20241223_143143.mp4\n",
            "Detection metadata saved at: /content/drive/MyDrive/FYP/json_data/detected_metadata_20241223_143143.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "# Load YOLOv8 model (pre-trained)\n",
        "model = YOLO('yolov8n.pt')  # You can use other models like yolov8s.pt, yolov8m.pt, etc.\n",
        "\n",
        "# Open the video file in the drive\n",
        "video_path = '/content/drive/MyDrive/FYP/input_videos/sl_2.mp4'  # Ensure the correct path format\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Couldn't open the video file.\")\n",
        "    exit()\n",
        "\n",
        "# Create output directory\n",
        "output_dir = '/content/drive/MyDrive/FYP/output_video'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "frame_dir = f'/content/drive/MyDrive/FYP/extracted_frames/processed_frames_{timestamp}'  # Specify the subdirectory with timestamp\n",
        "os.makedirs(frame_dir, exist_ok=True)\n",
        "\n",
        "json_dir = '/content/drive/MyDrive/FYP/json_data'\n",
        "os.makedirs(json_dir, exist_ok=True)\n",
        "\n",
        "# Get video properties for output video\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "output_video_path = os.path.join(output_dir, f'output_video_{timestamp}.mp4')\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for mp4\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# JSON file to save metadata\n",
        "output_json_path = os.path.join(json_dir, f'detected_metadata_{timestamp}.json')\n",
        "metadata = []\n",
        "\n",
        "# Process each frame\n",
        "frame_count = 0\n",
        "start_time = time.time()  # Start time for FPS calculation\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Resize the frame\n",
        "    frame_resized = cv2.resize(frame, (frame_width , frame_height))\n",
        "\n",
        "    # Run object detection on the resized frame\n",
        "    results = model(frame_resized)\n",
        "\n",
        "    # Get the frame with bounding boxes and labels drawn\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Save metadata for the current frame\n",
        "    detections = []\n",
        "    for box in results[0].boxes:\n",
        "        bbox = box.xyxy.tolist()[0]  # (x1, y1, x2, y2)\n",
        "        class_id = int(box.cls)\n",
        "        confidence = float(box.conf)\n",
        "        detections.append({\n",
        "            'class': model.names[class_id],\n",
        "            'confidence': confidence,\n",
        "            'box': bbox\n",
        "        })\n",
        "\n",
        "    metadata.append({\n",
        "        'frame': frame_count,\n",
        "        'detections': detections\n",
        "    })\n",
        "\n",
        "    # Write the annotated frame to the output video\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "    # Save each annotated frame as an image file\n",
        "    frame_output_path = os.path.join(frame_dir, f'frame_{frame_count:04d}.jpg')\n",
        "    cv2.imwrite(frame_output_path, annotated_frame)\n",
        "\n",
        "    # Optional: Display the annotated frame\n",
        "    #cv2.imshow(\"YOLOv8 Object Detection - Video\", annotated_frame)\n",
        "\n",
        "    # Break the loop if the user presses 'q'\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    # Calculate and display FPS\n",
        "    frame_count += 1\n",
        "    elapsed_time = time.time() - start_time\n",
        "    if elapsed_time > 0:\n",
        "        fps = frame_count / elapsed_time\n",
        "        print(f\"Processed Frame: {frame_count}, FPS: {fps:.2f}\")\n",
        "\n",
        "# Write metadata to JSON file\n",
        "with open(output_json_path, 'w') as json_file:\n",
        "    json.dump(metadata, json_file, indent=4)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"Processed {frame_count} frames.\")\n",
        "print(f\"Annotated video saved at: {output_video_path}\")\n",
        "print(f\"Detection metadata saved at: {output_json_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kpA5EZ6XcI6"
      },
      "source": [
        "# Handle Incorrect Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFr4dVhCXoDQ"
      },
      "source": [
        "***1. Prepare Dataset***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qQiic41XzYe"
      },
      "source": [
        "Extract frames from videos or use existing images containing the objects want to detect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsrPvjWpireL",
        "outputId": "100fef06-27da-4c5a-eba7-efa6aa68247f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted 353 frames to /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Path to your video file\n",
        "video_path = '/content/drive/MyDrive/FYP/input_videos/sl_1.mp4'  # Update with your video path\n",
        "output_dir = f'/content/drive/MyDrive/FYP/training_yolo8/video_frames_{timestamp}'  # Output directory for extracted frames\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Frame extraction\n",
        "frame_count = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save the extracted frame as an image\n",
        "    frame_output_path = os.path.join(output_dir, f'frame_{frame_count:04d}.jpg')\n",
        "    cv2.imwrite(frame_output_path, frame)\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\"Extracted {frame_count} frames to {output_dir}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcFRutnhajZI"
      },
      "source": [
        "***2. Annotations -  Label each image with bounding boxes and class names***\n",
        "\n",
        "Save the annotations in YOLO format, which specifies the class ID and normalized coordinates of the bounding boxes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3fKpMj_U336",
        "outputId": "120f46e9-e881-48e7-db8b-60bb86db0ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616\n"
          ]
        }
      ],
      "source": [
        "print(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_lE75S7AWdr",
        "outputId": "48e49159-7b0e-44c3-8b7f-c1467682db92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 226MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0000.jpg: 512x640 9 persons, 3 cars, 1 motorcycle, 4 trucks, 582.5ms\n",
            "image 2/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0001.jpg: 512x640 6 persons, 4 cars, 1 motorcycle, 3 trucks, 507.9ms\n",
            "image 3/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0002.jpg: 512x640 6 persons, 2 cars, 1 motorcycle, 3 trucks, 512.9ms\n",
            "image 4/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0003.jpg: 512x640 6 persons, 2 cars, 1 motorcycle, 3 trucks, 953.8ms\n",
            "image 5/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0004.jpg: 512x640 6 persons, 3 cars, 1 motorcycle, 4 trucks, 795.2ms\n",
            "image 6/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0005.jpg: 512x640 7 persons, 3 cars, 2 motorcycles, 2 trucks, 768.8ms\n",
            "image 7/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0006.jpg: 512x640 10 persons, 5 cars, 1 motorcycle, 3 trucks, 777.2ms\n",
            "image 8/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0007.jpg: 512x640 6 persons, 6 cars, 1 motorcycle, 3 trucks, 781.3ms\n",
            "image 9/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0008.jpg: 512x640 7 persons, 5 cars, 1 motorcycle, 3 trucks, 794.3ms\n",
            "image 10/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0009.jpg: 512x640 6 persons, 6 cars, 1 motorcycle, 3 trucks, 554.3ms\n",
            "image 11/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0010.jpg: 512x640 5 persons, 3 cars, 1 motorcycle, 3 trucks, 480.7ms\n",
            "image 12/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0011.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 4 trucks, 487.4ms\n",
            "image 13/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0012.jpg: 512x640 8 persons, 1 car, 1 motorcycle, 2 trucks, 486.7ms\n",
            "image 14/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0013.jpg: 512x640 7 persons, 3 cars, 1 motorcycle, 2 trucks, 478.6ms\n",
            "image 15/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0014.jpg: 512x640 8 persons, 4 cars, 1 motorcycle, 2 trucks, 481.9ms\n",
            "image 16/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0015.jpg: 512x640 8 persons, 4 cars, 1 motorcycle, 2 trucks, 520.8ms\n",
            "image 17/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0016.jpg: 512x640 6 persons, 5 cars, 1 motorcycle, 2 trucks, 476.5ms\n",
            "image 18/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0017.jpg: 512x640 7 persons, 4 cars, 1 motorcycle, 3 trucks, 490.0ms\n",
            "image 19/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0018.jpg: 512x640 6 persons, 4 cars, 1 motorcycle, 4 trucks, 484.7ms\n",
            "image 20/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0019.jpg: 512x640 6 persons, 5 cars, 1 motorcycle, 3 trucks, 497.9ms\n",
            "image 21/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0020.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 3 trucks, 486.6ms\n",
            "image 22/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0021.jpg: 512x640 6 persons, 3 cars, 1 motorcycle, 3 trucks, 515.8ms\n",
            "image 23/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0022.jpg: 512x640 6 persons, 3 cars, 2 motorcycles, 2 trucks, 487.0ms\n",
            "image 24/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0023.jpg: 512x640 7 persons, 3 cars, 1 motorcycle, 1 bus, 2 trucks, 1 refrigerator, 493.5ms\n",
            "image 25/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0024.jpg: 512x640 9 persons, 3 cars, 1 motorcycle, 3 trucks, 498.2ms\n",
            "image 26/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0025.jpg: 512x640 8 persons, 4 cars, 1 motorcycle, 3 trucks, 491.0ms\n",
            "image 27/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0026.jpg: 512x640 7 persons, 1 bicycle, 4 cars, 1 motorcycle, 2 trucks, 489.6ms\n",
            "image 28/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0027.jpg: 512x640 7 persons, 1 bicycle, 4 cars, 1 motorcycle, 2 trucks, 488.3ms\n",
            "image 29/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0028.jpg: 512x640 7 persons, 1 bicycle, 3 cars, 1 motorcycle, 2 trucks, 731.4ms\n",
            "image 30/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0029.jpg: 512x640 7 persons, 1 bicycle, 2 cars, 1 motorcycle, 4 trucks, 755.7ms\n",
            "image 31/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0030.jpg: 512x640 6 persons, 1 bicycle, 2 cars, 1 bus, 2 trucks, 790.1ms\n",
            "image 32/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0031.jpg: 512x640 5 persons, 1 bicycle, 3 cars, 1 motorcycle, 2 buss, 3 trucks, 800.5ms\n",
            "image 33/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0032.jpg: 512x640 7 persons, 3 cars, 1 motorcycle, 2 trucks, 1 refrigerator, 788.8ms\n",
            "image 34/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0033.jpg: 512x640 7 persons, 3 cars, 1 motorcycle, 2 trucks, 1 refrigerator, 760.8ms\n",
            "image 35/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0034.jpg: 512x640 7 persons, 2 bicycles, 3 cars, 2 trucks, 507.3ms\n",
            "image 36/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0035.jpg: 512x640 8 persons, 2 bicycles, 3 cars, 3 trucks, 505.4ms\n",
            "image 37/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0036.jpg: 512x640 8 persons, 1 bicycle, 2 cars, 2 trucks, 507.3ms\n",
            "image 38/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0037.jpg: 512x640 6 persons, 2 bicycles, 3 cars, 2 trucks, 489.4ms\n",
            "image 39/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0038.jpg: 512x640 6 persons, 2 bicycles, 2 cars, 2 trucks, 494.2ms\n",
            "image 40/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0039.jpg: 512x640 6 persons, 2 bicycles, 2 cars, 2 trucks, 482.8ms\n",
            "image 41/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0040.jpg: 512x640 6 persons, 2 bicycles, 2 cars, 2 trucks, 1 refrigerator, 491.5ms\n",
            "image 42/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0041.jpg: 512x640 5 persons, 3 bicycles, 3 cars, 2 trucks, 484.2ms\n",
            "image 43/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0042.jpg: 512x640 7 persons, 1 bicycle, 4 cars, 2 trucks, 492.3ms\n",
            "image 44/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0043.jpg: 512x640 6 persons, 1 bicycle, 3 cars, 1 motorcycle, 2 trucks, 498.0ms\n",
            "image 45/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0044.jpg: 512x640 5 persons, 1 bicycle, 2 cars, 1 motorcycle, 2 trucks, 778.5ms\n",
            "image 46/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0045.jpg: 512x640 5 persons, 1 bicycle, 2 cars, 1 motorcycle, 2 trucks, 788.8ms\n",
            "image 47/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0046.jpg: 512x640 7 persons, 3 cars, 1 motorcycle, 2 trucks, 779.3ms\n",
            "image 48/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0047.jpg: 512x640 7 persons, 2 cars, 1 motorcycle, 2 trucks, 806.3ms\n",
            "image 49/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0048.jpg: 512x640 8 persons, 2 cars, 1 motorcycle, 2 trucks, 786.2ms\n",
            "image 50/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0049.jpg: 512x640 6 persons, 2 cars, 1 motorcycle, 2 trucks, 1 chair, 886.6ms\n",
            "image 51/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0050.jpg: 512x640 6 persons, 2 cars, 1 motorcycle, 2 trucks, 795.9ms\n",
            "image 52/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0051.jpg: 512x640 6 persons, 2 cars, 1 motorcycle, 2 trucks, 775.6ms\n",
            "image 53/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0052.jpg: 512x640 6 persons, 1 bicycle, 2 cars, 1 motorcycle, 2 trucks, 763.1ms\n",
            "image 54/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0053.jpg: 512x640 7 persons, 1 car, 1 motorcycle, 2 trucks, 773.6ms\n",
            "image 55/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0054.jpg: 512x640 8 persons, 1 car, 1 motorcycle, 1 truck, 819.8ms\n",
            "image 56/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0055.jpg: 512x640 8 persons, 1 car, 1 motorcycle, 1 truck, 603.2ms\n",
            "image 57/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0056.jpg: 512x640 7 persons, 2 cars, 1 motorcycle, 1 truck, 472.9ms\n",
            "image 58/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0057.jpg: 512x640 7 persons, 2 bicycles, 2 cars, 1 motorcycle, 1 truck, 496.1ms\n",
            "image 59/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0058.jpg: 512x640 8 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 483.2ms\n",
            "image 60/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0059.jpg: 512x640 7 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 502.0ms\n",
            "image 61/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0060.jpg: 512x640 8 persons, 2 bicycles, 1 car, 1 truck, 471.2ms\n",
            "image 62/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0061.jpg: 512x640 9 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 513.6ms\n",
            "image 63/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0062.jpg: 512x640 9 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 474.6ms\n",
            "image 64/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0063.jpg: 512x640 9 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 509.1ms\n",
            "image 65/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0064.jpg: 512x640 10 persons, 2 bicycles, 1 car, 1 truck, 478.7ms\n",
            "image 66/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0065.jpg: 512x640 8 persons, 2 bicycles, 1 car, 1 truck, 504.0ms\n",
            "image 67/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0066.jpg: 512x640 7 persons, 1 bicycle, 2 cars, 1 truck, 491.8ms\n",
            "image 68/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0067.jpg: 512x640 7 persons, 3 bicycles, 1 car, 2 trucks, 522.8ms\n",
            "image 69/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0068.jpg: 512x640 7 persons, 2 cars, 1 motorcycle, 2 trucks, 484.8ms\n",
            "image 70/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0069.jpg: 512x640 8 persons, 2 cars, 1 motorcycle, 2 trucks, 484.1ms\n",
            "image 71/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0070.jpg: 512x640 7 persons, 2 cars, 1 motorcycle, 1 truck, 484.7ms\n",
            "image 72/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0071.jpg: 512x640 8 persons, 2 bicycles, 2 cars, 1 truck, 491.9ms\n",
            "image 73/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0072.jpg: 512x640 9 persons, 1 bicycle, 2 cars, 1 truck, 481.8ms\n",
            "image 74/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0073.jpg: 512x640 9 persons, 2 cars, 1 motorcycle, 2 trucks, 484.3ms\n",
            "image 75/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0074.jpg: 512x640 9 persons, 1 bicycle, 3 cars, 1 truck, 693.9ms\n",
            "image 76/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0075.jpg: 512x640 9 persons, 1 bicycle, 2 cars, 1 motorcycle, 1 truck, 783.6ms\n",
            "image 77/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0076.jpg: 512x640 7 persons, 3 cars, 1 motorcycle, 2 trucks, 759.1ms\n",
            "image 78/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0077.jpg: 512x640 9 persons, 2 cars, 1 motorcycle, 2 trucks, 788.9ms\n",
            "image 79/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0078.jpg: 512x640 9 persons, 1 car, 1 motorcycle, 1 truck, 784.5ms\n",
            "image 80/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0079.jpg: 512x640 7 persons, 1 car, 1 motorcycle, 1 truck, 805.0ms\n",
            "image 81/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0080.jpg: 512x640 7 persons, 1 bicycle, 1 car, 1 motorcycle, 2 trucks, 482.3ms\n",
            "image 82/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0081.jpg: 512x640 7 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 491.9ms\n",
            "image 83/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0082.jpg: 512x640 7 persons, 1 car, 1 motorcycle, 2 trucks, 502.8ms\n",
            "image 84/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0083.jpg: 512x640 7 persons, 1 car, 1 motorcycle, 1 truck, 488.3ms\n",
            "image 85/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0084.jpg: 512x640 7 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 494.5ms\n",
            "image 86/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0085.jpg: 512x640 7 persons, 1 car, 1 motorcycle, 2 trucks, 1 potted plant, 494.5ms\n",
            "image 87/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0086.jpg: 512x640 6 persons, 1 bicycle, 1 motorcycle, 2 trucks, 1 potted plant, 494.7ms\n",
            "image 88/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0087.jpg: 512x640 8 persons, 1 motorcycle, 2 trucks, 501.7ms\n",
            "image 89/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0088.jpg: 512x640 7 persons, 1 bicycle, 1 motorcycle, 1 truck, 482.8ms\n",
            "image 90/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0089.jpg: 512x640 7 persons, 1 bicycle, 1 motorcycle, 1 truck, 489.6ms\n",
            "image 91/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0090.jpg: 512x640 7 persons, 1 bicycle, 1 motorcycle, 1 truck, 483.9ms\n",
            "image 92/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0091.jpg: 512x640 8 persons, 1 bicycle, 1 truck, 1 handbag, 526.6ms\n",
            "image 93/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0092.jpg: 512x640 8 persons, 1 bicycle, 1 car, 1 motorcycle, 2 trucks, 1 handbag, 480.8ms\n",
            "image 94/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0093.jpg: 512x640 8 persons, 1 bicycle, 1 car, 1 motorcycle, 2 trucks, 1 handbag, 501.6ms\n",
            "image 95/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0094.jpg: 512x640 9 persons, 1 bicycle, 2 cars, 1 motorcycle, 2 trucks, 3 handbags, 475.8ms\n",
            "image 96/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0095.jpg: 512x640 11 persons, 1 bicycle, 1 car, 1 motorcycle, 2 trucks, 487.9ms\n",
            "image 97/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0096.jpg: 512x640 9 persons, 1 bicycle, 1 car, 1 motorcycle, 2 trucks, 486.9ms\n",
            "image 98/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0097.jpg: 512x640 10 persons, 1 bicycle, 1 car, 2 trucks, 2 handbags, 490.2ms\n",
            "image 99/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0098.jpg: 512x640 10 persons, 1 bicycle, 1 car, 1 motorcycle, 2 trucks, 4 handbags, 534.9ms\n",
            "image 100/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0099.jpg: 512x640 9 persons, 1 bicycle, 1 car, 1 motorcycle, 2 trucks, 3 handbags, 773.7ms\n",
            "image 101/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0100.jpg: 512x640 11 persons, 1 bicycle, 1 car, 1 motorcycle, 2 trucks, 3 handbags, 783.3ms\n",
            "image 102/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0101.jpg: 512x640 10 persons, 1 car, 1 motorcycle, 2 trucks, 2 handbags, 782.1ms\n",
            "image 103/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0102.jpg: 512x640 10 persons, 1 car, 1 motorcycle, 2 trucks, 2 handbags, 920.5ms\n",
            "image 104/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0103.jpg: 512x640 9 persons, 1 car, 1 motorcycle, 2 trucks, 1 handbag, 796.6ms\n",
            "image 105/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0104.jpg: 512x640 9 persons, 1 car, 1 motorcycle, 2 trucks, 2 handbags, 582.1ms\n",
            "image 106/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0105.jpg: 512x640 9 persons, 1 car, 1 motorcycle, 2 trucks, 2 handbags, 496.5ms\n",
            "image 107/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0106.jpg: 512x640 8 persons, 2 cars, 1 motorcycle, 3 trucks, 1 handbag, 475.6ms\n",
            "image 108/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0107.jpg: 512x640 8 persons, 1 car, 1 motorcycle, 2 trucks, 1 handbag, 493.6ms\n",
            "image 109/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0108.jpg: 512x640 8 persons, 1 car, 1 motorcycle, 1 truck, 1 handbag, 479.8ms\n",
            "image 110/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0109.jpg: 512x640 8 persons, 1 car, 1 motorcycle, 2 trucks, 1 handbag, 510.8ms\n",
            "image 111/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0110.jpg: 512x640 8 persons, 1 car, 1 motorcycle, 2 trucks, 2 handbags, 474.5ms\n",
            "image 112/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0111.jpg: 512x640 8 persons, 1 car, 1 motorcycle, 2 trucks, 1 handbag, 502.4ms\n",
            "image 113/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0112.jpg: 512x640 7 persons, 1 car, 1 motorcycle, 4 trucks, 2 handbags, 486.6ms\n",
            "image 114/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0113.jpg: 512x640 7 persons, 1 car, 1 motorcycle, 4 trucks, 1 handbag, 513.9ms\n",
            "image 115/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0114.jpg: 512x640 8 persons, 1 car, 1 motorcycle, 3 trucks, 1 handbag, 485.6ms\n",
            "image 116/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0115.jpg: 512x640 9 persons, 1 car, 1 motorcycle, 3 trucks, 492.0ms\n",
            "image 117/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0116.jpg: 512x640 5 persons, 1 car, 3 trucks, 495.7ms\n",
            "image 118/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0117.jpg: 512x640 7 persons, 1 car, 3 trucks, 507.1ms\n",
            "image 119/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0118.jpg: 512x640 4 persons, 1 car, 3 trucks, 481.3ms\n",
            "image 120/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0119.jpg: 512x640 4 persons, 1 car, 3 trucks, 491.5ms\n",
            "image 121/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0120.jpg: 512x640 4 persons, 1 car, 3 trucks, 484.5ms\n",
            "image 122/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0121.jpg: 512x640 6 persons, 1 car, 3 trucks, 501.0ms\n",
            "image 123/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0122.jpg: 512x640 5 persons, 1 car, 5 trucks, 499.7ms\n",
            "image 124/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0123.jpg: 512x640 4 persons, 1 car, 4 trucks, 764.1ms\n",
            "image 125/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0124.jpg: 512x640 3 persons, 1 bicycle, 1 car, 4 trucks, 771.4ms\n",
            "image 126/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0125.jpg: 512x640 3 persons, 1 bicycle, 1 car, 5 trucks, 767.6ms\n",
            "image 127/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0126.jpg: 512x640 3 persons, 1 bicycle, 1 car, 3 trucks, 2 handbags, 767.3ms\n",
            "image 128/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0127.jpg: 512x640 3 persons, 1 bicycle, 1 car, 5 trucks, 810.0ms\n",
            "image 129/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0128.jpg: 512x640 3 persons, 1 car, 4 trucks, 732.2ms\n",
            "image 130/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0129.jpg: 512x640 3 persons, 1 car, 4 trucks, 489.5ms\n",
            "image 131/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0130.jpg: 512x640 3 persons, 1 car, 3 trucks, 497.9ms\n",
            "image 132/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0131.jpg: 512x640 3 persons, 1 car, 4 trucks, 490.2ms\n",
            "image 133/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0132.jpg: 512x640 3 persons, 1 car, 1 truck, 1 potted plant, 494.8ms\n",
            "image 134/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0133.jpg: 512x640 3 persons, 1 car, 3 trucks, 1 umbrella, 1 potted plant, 482.3ms\n",
            "image 135/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0134.jpg: 512x640 3 persons, 1 car, 2 trucks, 490.0ms\n",
            "image 136/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0135.jpg: 512x640 3 persons, 1 car, 2 trucks, 483.9ms\n",
            "image 137/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0136.jpg: 512x640 3 persons, 1 car, 2 trucks, 512.6ms\n",
            "image 138/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0137.jpg: 512x640 4 persons, 3 cars, 2 trucks, 478.3ms\n",
            "image 139/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0138.jpg: 512x640 3 persons, 1 car, 2 trucks, 485.4ms\n",
            "image 140/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0139.jpg: 512x640 3 persons, 2 trucks, 502.8ms\n",
            "image 141/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0140.jpg: 512x640 3 persons, 1 car, 2 trucks, 485.1ms\n",
            "image 142/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0141.jpg: 512x640 3 persons, 1 car, 2 trucks, 552.8ms\n",
            "image 143/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0142.jpg: 512x640 4 persons, 2 cars, 2 trucks, 484.1ms\n",
            "image 144/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0143.jpg: 512x640 3 persons, 2 cars, 2 trucks, 490.5ms\n",
            "image 145/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0144.jpg: 512x640 3 persons, 1 car, 2 trucks, 497.2ms\n",
            "image 146/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0145.jpg: 512x640 3 persons, 1 car, 1 truck, 496.0ms\n",
            "image 147/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0146.jpg: 512x640 3 persons, 1 car, 1 truck, 483.7ms\n",
            "image 148/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0147.jpg: 512x640 3 persons, 1 car, 1 truck, 590.7ms\n",
            "image 149/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0148.jpg: 512x640 3 persons, 1 car, 2 trucks, 775.1ms\n",
            "image 150/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0149.jpg: 512x640 3 persons, 2 trucks, 787.8ms\n",
            "image 151/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0150.jpg: 512x640 3 persons, 2 trucks, 791.9ms\n",
            "image 152/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0151.jpg: 512x640 3 persons, 2 trucks, 780.7ms\n",
            "image 153/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0152.jpg: 512x640 3 persons, 2 trucks, 818.7ms\n",
            "image 154/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0153.jpg: 512x640 3 persons, 2 trucks, 602.4ms\n",
            "image 155/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0154.jpg: 512x640 3 persons, 2 trucks, 506.3ms\n",
            "image 156/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0155.jpg: 512x640 3 persons, 2 trucks, 498.1ms\n",
            "image 157/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0156.jpg: 512x640 3 persons, 2 trucks, 491.7ms\n",
            "image 158/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0157.jpg: 512x640 4 persons, 2 trucks, 490.6ms\n",
            "image 159/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0158.jpg: 512x640 3 persons, 2 trucks, 495.8ms\n",
            "image 160/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0159.jpg: 512x640 3 persons, 2 trucks, 494.8ms\n",
            "image 161/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0160.jpg: 512x640 4 persons, 2 cars, 2 trucks, 501.2ms\n",
            "image 162/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0161.jpg: 512x640 3 persons, 2 cars, 2 trucks, 497.4ms\n",
            "image 163/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0162.jpg: 512x640 3 persons, 2 cars, 2 trucks, 502.1ms\n",
            "image 164/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0163.jpg: 512x640 5 persons, 1 car, 2 trucks, 1 traffic light, 486.7ms\n",
            "image 165/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0164.jpg: 512x640 5 persons, 1 car, 2 trucks, 494.9ms\n",
            "image 166/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0165.jpg: 512x640 5 persons, 2 cars, 2 trucks, 491.1ms\n",
            "image 167/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0166.jpg: 512x640 4 persons, 1 car, 2 trucks, 1 traffic light, 483.0ms\n",
            "image 168/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0167.jpg: 512x640 3 persons, 1 car, 2 trucks, 480.6ms\n",
            "image 169/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0168.jpg: 512x640 5 persons, 1 car, 2 trucks, 482.8ms\n",
            "image 170/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0169.jpg: 512x640 7 persons, 1 car, 2 trucks, 492.2ms\n",
            "image 171/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0170.jpg: 512x640 5 persons, 1 car, 2 trucks, 503.4ms\n",
            "image 172/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0171.jpg: 512x640 5 persons, 2 cars, 2 trucks, 564.5ms\n",
            "image 173/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0172.jpg: 512x640 5 persons, 1 car, 2 trucks, 772.8ms\n",
            "image 174/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0173.jpg: 512x640 5 persons, 2 cars, 4 trucks, 804.2ms\n",
            "image 175/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0174.jpg: 512x640 4 persons, 2 cars, 3 trucks, 793.8ms\n",
            "image 176/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0175.jpg: 512x640 4 persons, 2 cars, 4 trucks, 776.1ms\n",
            "image 177/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0176.jpg: 512x640 4 persons, 1 car, 1 bus, 3 trucks, 822.4ms\n",
            "image 178/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0177.jpg: 512x640 4 persons, 1 car, 1 bus, 3 trucks, 636.0ms\n",
            "image 179/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0178.jpg: 512x640 6 persons, 1 car, 1 bus, 4 trucks, 497.7ms\n",
            "image 180/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0179.jpg: 512x640 6 persons, 1 car, 1 bus, 4 trucks, 482.3ms\n",
            "image 181/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0180.jpg: 512x640 4 persons, 1 car, 1 bus, 3 trucks, 499.4ms\n",
            "image 182/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0181.jpg: 512x640 5 persons, 2 cars, 1 bus, 2 trucks, 487.3ms\n",
            "image 183/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0182.jpg: 512x640 4 persons, 2 cars, 1 bus, 3 trucks, 504.4ms\n",
            "image 184/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0183.jpg: 512x640 4 persons, 2 cars, 1 bus, 3 trucks, 491.2ms\n",
            "image 185/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0184.jpg: 512x640 5 persons, 1 car, 3 trucks, 508.3ms\n",
            "image 186/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0185.jpg: 512x640 7 persons, 3 trucks, 490.6ms\n",
            "image 187/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0186.jpg: 512x640 6 persons, 3 trucks, 524.2ms\n",
            "image 188/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0187.jpg: 512x640 6 persons, 3 trucks, 496.8ms\n",
            "image 189/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0188.jpg: 512x640 5 persons, 1 motorcycle, 3 trucks, 505.1ms\n",
            "image 190/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0189.jpg: 512x640 5 persons, 1 motorcycle, 3 trucks, 487.9ms\n",
            "image 191/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0190.jpg: 512x640 5 persons, 1 motorcycle, 3 trucks, 523.5ms\n",
            "image 192/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0191.jpg: 512x640 5 persons, 3 trucks, 489.8ms\n",
            "image 193/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0192.jpg: 512x640 5 persons, 1 motorcycle, 3 trucks, 494.7ms\n",
            "image 194/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0193.jpg: 512x640 4 persons, 1 motorcycle, 3 trucks, 483.1ms\n",
            "image 195/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0194.jpg: 512x640 4 persons, 1 motorcycle, 3 trucks, 486.2ms\n",
            "image 196/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0195.jpg: 512x640 4 persons, 1 motorcycle, 3 trucks, 497.1ms\n",
            "image 197/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0196.jpg: 512x640 4 persons, 1 motorcycle, 3 trucks, 747.3ms\n",
            "image 198/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0197.jpg: 512x640 3 persons, 1 car, 3 trucks, 768.2ms\n",
            "image 199/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0198.jpg: 512x640 3 persons, 1 car, 1 motorcycle, 3 trucks, 793.3ms\n",
            "image 200/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0199.jpg: 512x640 1 person, 1 car, 1 motorcycle, 3 trucks, 774.8ms\n",
            "image 201/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0200.jpg: 512x640 3 persons, 2 motorcycles, 3 trucks, 801.5ms\n",
            "image 202/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0201.jpg: 512x640 4 persons, 1 motorcycle, 3 trucks, 778.3ms\n",
            "image 203/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0202.jpg: 512x640 4 persons, 1 car, 2 motorcycles, 3 trucks, 497.5ms\n",
            "image 204/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0203.jpg: 512x640 4 persons, 2 cars, 2 motorcycles, 3 trucks, 499.4ms\n",
            "image 205/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0204.jpg: 512x640 3 persons, 1 car, 2 motorcycles, 3 trucks, 503.4ms\n",
            "image 206/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0205.jpg: 512x640 3 persons, 2 cars, 1 motorcycle, 3 trucks, 2 handbags, 482.0ms\n",
            "image 207/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0206.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 3 trucks, 487.5ms\n",
            "image 208/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0207.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 3 trucks, 487.0ms\n",
            "image 209/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0208.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 3 trucks, 485.4ms\n",
            "image 210/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0209.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 3 trucks, 476.5ms\n",
            "image 211/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0210.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 3 trucks, 512.7ms\n",
            "image 212/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0211.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 1 truck, 478.9ms\n",
            "image 213/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0212.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 1 truck, 1 handbag, 503.8ms\n",
            "image 214/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0213.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 1 truck, 1 handbag, 482.3ms\n",
            "image 215/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0214.jpg: 512x640 4 persons, 3 cars, 1 motorcycle, 2 trucks, 1 handbag, 504.7ms\n",
            "image 216/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0215.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 1 truck, 1 handbag, 475.4ms\n",
            "image 217/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0216.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 2 trucks, 1 handbag, 497.0ms\n",
            "image 218/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0217.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 2 trucks, 1 handbag, 505.9ms\n",
            "image 219/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0218.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 2 trucks, 491.1ms\n",
            "image 220/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0219.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 2 trucks, 481.0ms\n",
            "image 221/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0220.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 2 trucks, 611.2ms\n",
            "image 222/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0221.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 1 truck, 801.7ms\n",
            "image 223/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0222.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 1 truck, 768.8ms\n",
            "image 224/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0223.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 1 truck, 779.9ms\n",
            "image 225/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0224.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 1 truck, 793.0ms\n",
            "image 226/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0225.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 1 truck, 811.6ms\n",
            "image 227/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0226.jpg: 512x640 5 persons, 2 cars, 2 motorcycles, 1 truck, 587.6ms\n",
            "image 228/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0227.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 1 truck, 483.6ms\n",
            "image 229/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0228.jpg: 512x640 5 persons, 2 cars, 2 motorcycles, 1 truck, 1 potted plant, 493.5ms\n",
            "image 230/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0229.jpg: 512x640 5 persons, 2 cars, 2 motorcycles, 1 truck, 1 potted plant, 500.4ms\n",
            "image 231/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0230.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 1 truck, 498.8ms\n",
            "image 232/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0231.jpg: 512x640 5 persons, 2 cars, 1 motorcycle, 1 truck, 503.4ms\n",
            "image 233/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0232.jpg: 512x640 5 persons, 2 cars, 2 motorcycles, 1 truck, 501.5ms\n",
            "image 234/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0233.jpg: 512x640 5 persons, 2 cars, 2 motorcycles, 1 truck, 486.0ms\n",
            "image 235/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0234.jpg: 512x640 5 persons, 2 cars, 2 motorcycles, 1 truck, 499.2ms\n",
            "image 236/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0235.jpg: 512x640 5 persons, 2 cars, 2 motorcycles, 1 truck, 505.1ms\n",
            "image 237/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0236.jpg: 512x640 6 persons, 2 cars, 2 motorcycles, 1 truck, 497.8ms\n",
            "image 238/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0237.jpg: 512x640 5 persons, 2 cars, 2 motorcycles, 1 truck, 496.7ms\n",
            "image 239/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0238.jpg: 512x640 6 persons, 3 cars, 2 motorcycles, 1 truck, 503.5ms\n",
            "image 240/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0239.jpg: 512x640 5 persons, 3 cars, 1 motorcycle, 1 truck, 541.1ms\n",
            "image 241/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0240.jpg: 512x640 7 persons, 3 cars, 2 motorcycles, 1 truck, 1 handbag, 532.8ms\n",
            "image 242/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0241.jpg: 512x640 4 persons, 3 cars, 1 motorcycle, 1 truck, 485.8ms\n",
            "image 243/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0242.jpg: 512x640 6 persons, 4 cars, 1 motorcycle, 1 truck, 516.9ms\n",
            "image 244/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0243.jpg: 512x640 5 persons, 3 cars, 1 motorcycle, 1 truck, 505.7ms\n",
            "image 245/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0244.jpg: 512x640 6 persons, 3 cars, 1 motorcycle, 1 truck, 596.9ms\n",
            "image 246/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0245.jpg: 512x640 5 persons, 2 cars, 2 motorcycles, 1 truck, 780.2ms\n",
            "image 247/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0246.jpg: 512x640 5 persons, 1 bicycle, 2 cars, 1 motorcycle, 1 truck, 762.2ms\n",
            "image 248/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0247.jpg: 512x640 6 persons, 1 bicycle, 3 cars, 1 motorcycle, 1 truck, 769.0ms\n",
            "image 249/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0248.jpg: 512x640 5 persons, 3 cars, 1 motorcycle, 1 truck, 770.6ms\n",
            "image 250/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0249.jpg: 512x640 5 persons, 3 cars, 1 motorcycle, 1 truck, 821.9ms\n",
            "image 251/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0250.jpg: 512x640 7 persons, 3 cars, 1 motorcycle, 1 truck, 590.2ms\n",
            "image 252/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0251.jpg: 512x640 7 persons, 3 cars, 1 motorcycle, 1 truck, 501.8ms\n",
            "image 253/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0252.jpg: 512x640 8 persons, 2 cars, 1 motorcycle, 1 truck, 500.1ms\n",
            "image 254/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0253.jpg: 512x640 7 persons, 2 cars, 1 motorcycle, 1 truck, 485.9ms\n",
            "image 255/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0254.jpg: 512x640 7 persons, 2 cars, 2 motorcycles, 2 trucks, 529.9ms\n",
            "image 256/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0255.jpg: 512x640 8 persons, 2 cars, 1 motorcycle, 2 trucks, 478.3ms\n",
            "image 257/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0256.jpg: 512x640 7 persons, 3 cars, 1 motorcycle, 1 truck, 505.8ms\n",
            "image 258/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0257.jpg: 512x640 7 persons, 3 cars, 2 motorcycles, 1 truck, 497.6ms\n",
            "image 259/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0258.jpg: 512x640 6 persons, 2 cars, 2 motorcycles, 2 trucks, 507.5ms\n",
            "image 260/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0259.jpg: 512x640 7 persons, 2 cars, 1 motorcycle, 1 truck, 485.1ms\n",
            "image 261/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0260.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 1 truck, 506.1ms\n",
            "image 262/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0261.jpg: 512x640 6 persons, 2 cars, 2 motorcycles, 1 truck, 479.4ms\n",
            "image 263/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0262.jpg: 512x640 7 persons, 2 cars, 2 motorcycles, 1 truck, 493.3ms\n",
            "image 264/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0263.jpg: 512x640 4 persons, 2 cars, 1 motorcycle, 1 truck, 490.9ms\n",
            "image 265/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0264.jpg: 512x640 9 persons, 2 cars, 1 motorcycle, 1 truck, 493.3ms\n",
            "image 266/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0265.jpg: 512x640 10 persons, 2 cars, 1 motorcycle, 1 truck, 496.1ms\n",
            "image 267/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0266.jpg: 512x640 7 persons, 3 cars, 1 motorcycle, 1 truck, 493.0ms\n",
            "image 268/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0267.jpg: 512x640 6 persons, 4 cars, 1 motorcycle, 1 truck, 496.2ms\n",
            "image 269/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0268.jpg: 512x640 6 persons, 3 cars, 1 motorcycle, 1 truck, 503.7ms\n",
            "image 270/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0269.jpg: 512x640 7 persons, 3 cars, 2 motorcycles, 1 truck, 794.1ms\n",
            "image 271/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0270.jpg: 512x640 5 persons, 4 cars, 3 motorcycles, 1 truck, 772.7ms\n",
            "image 272/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0271.jpg: 512x640 4 persons, 3 cars, 2 motorcycles, 1 truck, 779.9ms\n",
            "image 273/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0272.jpg: 512x640 6 persons, 3 cars, 1 motorcycle, 1 truck, 821.0ms\n",
            "image 274/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0273.jpg: 512x640 6 persons, 3 cars, 2 motorcycles, 1 truck, 817.7ms\n",
            "image 275/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0274.jpg: 512x640 6 persons, 5 cars, 3 motorcycles, 1 truck, 698.5ms\n",
            "image 276/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0275.jpg: 512x640 5 persons, 3 cars, 3 motorcycles, 2 trucks, 498.2ms\n",
            "image 277/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0276.jpg: 512x640 5 persons, 2 cars, 3 motorcycles, 2 trucks, 500.9ms\n",
            "image 278/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0277.jpg: 512x640 9 persons, 4 cars, 2 motorcycles, 2 trucks, 493.6ms\n",
            "image 279/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0278.jpg: 512x640 9 persons, 2 cars, 1 motorcycle, 2 trucks, 502.8ms\n",
            "image 280/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0279.jpg: 512x640 6 persons, 2 cars, 2 motorcycles, 1 bus, 2 trucks, 494.8ms\n",
            "image 281/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0280.jpg: 512x640 6 persons, 1 car, 3 motorcycles, 1 bus, 1 truck, 503.6ms\n",
            "image 282/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0281.jpg: 512x640 8 persons, 1 bicycle, 3 cars, 3 motorcycles, 1 bus, 1 truck, 482.8ms\n",
            "image 283/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0282.jpg: 512x640 9 persons, 2 cars, 2 motorcycles, 1 bus, 2 trucks, 1 umbrella, 503.4ms\n",
            "image 284/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0283.jpg: 512x640 7 persons, 2 cars, 2 motorcycles, 2 trucks, 1 umbrella, 511.9ms\n",
            "image 285/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0284.jpg: 512x640 6 persons, 2 cars, 3 motorcycles, 1 bus, 2 trucks, 1 umbrella, 514.9ms\n",
            "image 286/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0285.jpg: 512x640 6 persons, 2 cars, 3 motorcycles, 2 trucks, 1 umbrella, 507.9ms\n",
            "image 287/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0286.jpg: 512x640 7 persons, 3 cars, 2 motorcycles, 1 truck, 511.7ms\n",
            "image 288/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0287.jpg: 512x640 7 persons, 3 cars, 3 motorcycles, 1 truck, 500.2ms\n",
            "image 289/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0288.jpg: 512x640 7 persons, 2 cars, 4 motorcycles, 1 truck, 482.7ms\n",
            "image 290/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0289.jpg: 512x640 7 persons, 3 cars, 3 motorcycles, 1 truck, 508.1ms\n",
            "image 291/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0290.jpg: 512x640 7 persons, 3 cars, 4 motorcycles, 519.5ms\n",
            "image 292/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0291.jpg: 512x640 7 persons, 2 cars, 4 motorcycles, 1 truck, 495.6ms\n",
            "image 293/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0292.jpg: 512x640 7 persons, 2 cars, 3 motorcycles, 1 truck, 481.8ms\n",
            "image 294/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0293.jpg: 512x640 7 persons, 2 cars, 4 motorcycles, 1 truck, 782.4ms\n",
            "image 295/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0294.jpg: 512x640 7 persons, 2 cars, 4 motorcycles, 1 truck, 767.7ms\n",
            "image 296/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0295.jpg: 512x640 7 persons, 2 cars, 4 motorcycles, 1 truck, 1 umbrella, 772.2ms\n",
            "image 297/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0296.jpg: 512x640 9 persons, 2 cars, 3 motorcycles, 1 truck, 1 umbrella, 766.0ms\n",
            "image 298/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0297.jpg: 512x640 9 persons, 2 cars, 3 motorcycles, 1 truck, 1 umbrella, 817.7ms\n",
            "image 299/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0298.jpg: 512x640 10 persons, 2 cars, 6 motorcycles, 1 truck, 773.3ms\n",
            "image 300/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0299.jpg: 512x640 9 persons, 1 car, 6 motorcycles, 1 truck, 483.3ms\n",
            "image 301/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0300.jpg: 512x640 11 persons, 1 car, 6 motorcycles, 1 truck, 501.5ms\n",
            "image 302/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0301.jpg: 512x640 9 persons, 1 car, 4 motorcycles, 475.1ms\n",
            "image 303/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0302.jpg: 512x640 9 persons, 1 car, 4 motorcycles, 1 umbrella, 504.6ms\n",
            "image 304/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0303.jpg: 512x640 11 persons, 1 car, 4 motorcycles, 1 umbrella, 487.5ms\n",
            "image 305/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0304.jpg: 512x640 9 persons, 1 car, 5 motorcycles, 1 umbrella, 507.6ms\n",
            "image 306/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0305.jpg: 512x640 10 persons, 1 car, 5 motorcycles, 1 truck, 487.4ms\n",
            "image 307/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0306.jpg: 512x640 8 persons, 1 car, 5 motorcycles, 565.2ms\n",
            "image 308/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0307.jpg: 512x640 8 persons, 2 cars, 6 motorcycles, 483.2ms\n",
            "image 309/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0308.jpg: 512x640 7 persons, 2 cars, 7 motorcycles, 1 truck, 488.1ms\n",
            "image 310/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0309.jpg: 512x640 8 persons, 2 cars, 5 motorcycles, 1 truck, 511.9ms\n",
            "image 311/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0310.jpg: 512x640 8 persons, 2 cars, 4 motorcycles, 477.9ms\n",
            "image 312/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0311.jpg: 512x640 7 persons, 2 cars, 6 motorcycles, 1 truck, 508.2ms\n",
            "image 313/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0312.jpg: 512x640 7 persons, 2 cars, 6 motorcycles, 1 truck, 481.0ms\n",
            "image 314/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0313.jpg: 512x640 6 persons, 2 cars, 5 motorcycles, 1 truck, 489.8ms\n",
            "image 315/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0314.jpg: 512x640 7 persons, 2 cars, 5 motorcycles, 1 truck, 477.1ms\n",
            "image 316/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0315.jpg: 512x640 7 persons, 2 cars, 4 motorcycles, 1 truck, 505.6ms\n",
            "image 317/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0316.jpg: 512x640 9 persons, 2 cars, 4 motorcycles, 1 truck, 495.0ms\n",
            "image 318/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0317.jpg: 512x640 8 persons, 2 cars, 4 motorcycles, 665.8ms\n",
            "image 319/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0318.jpg: 512x640 11 persons, 1 car, 5 motorcycles, 1 truck, 804.5ms\n",
            "image 320/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0319.jpg: 512x640 8 persons, 1 car, 5 motorcycles, 1 truck, 782.5ms\n",
            "image 321/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0320.jpg: 512x640 8 persons, 1 car, 7 motorcycles, 1 truck, 765.6ms\n",
            "image 322/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0321.jpg: 512x640 8 persons, 1 car, 6 motorcycles, 1 bus, 790.6ms\n",
            "image 323/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0322.jpg: 512x640 9 persons, 1 car, 8 motorcycles, 1 truck, 798.6ms\n",
            "image 324/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0323.jpg: 512x640 7 persons, 1 car, 5 motorcycles, 1 bus, 498.5ms\n",
            "image 325/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0324.jpg: 512x640 9 persons, 1 car, 5 motorcycles, 1 bus, 2 trucks, 513.7ms\n",
            "image 326/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0325.jpg: 512x640 8 persons, 1 car, 5 motorcycles, 1 truck, 496.9ms\n",
            "image 327/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0326.jpg: 512x640 7 persons, 1 car, 5 motorcycles, 1 truck, 517.1ms\n",
            "image 328/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0327.jpg: 512x640 8 persons, 1 car, 5 motorcycles, 1 truck, 771.3ms\n",
            "image 329/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0328.jpg: 512x640 7 persons, 1 car, 4 motorcycles, 1 truck, 757.7ms\n",
            "image 330/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0329.jpg: 512x640 6 persons, 1 car, 5 motorcycles, 1 truck, 783.1ms\n",
            "image 331/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0330.jpg: 512x640 7 persons, 3 cars, 5 motorcycles, 785.6ms\n",
            "image 332/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0331.jpg: 512x640 7 persons, 2 cars, 4 motorcycles, 1 bus, 1 handbag, 800.4ms\n",
            "image 333/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0332.jpg: 512x640 10 persons, 2 cars, 7 motorcycles, 1 bus, 1 truck, 687.8ms\n",
            "image 334/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0333.jpg: 512x640 10 persons, 2 cars, 7 motorcycles, 1 bus, 502.2ms\n",
            "image 335/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0334.jpg: 512x640 5 persons, 4 cars, 6 motorcycles, 1 bus, 1 truck, 482.1ms\n",
            "image 336/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0335.jpg: 512x640 6 persons, 1 car, 5 motorcycles, 1 bus, 1 truck, 504.3ms\n",
            "image 337/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0336.jpg: 512x640 4 persons, 2 cars, 5 motorcycles, 1 truck, 510.1ms\n",
            "image 338/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0337.jpg: 512x640 6 persons, 2 cars, 5 motorcycles, 1 truck, 476.5ms\n",
            "image 339/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0338.jpg: 512x640 4 persons, 2 cars, 6 motorcycles, 676.8ms\n",
            "image 340/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0339.jpg: 512x640 4 persons, 2 cars, 6 motorcycles, 759.8ms\n",
            "image 341/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0340.jpg: 512x640 3 persons, 2 cars, 3 motorcycles, 2 trucks, 761.6ms\n",
            "image 342/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0341.jpg: 512x640 4 persons, 2 cars, 3 motorcycles, 1 truck, 788.1ms\n",
            "image 343/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0342.jpg: 512x640 5 persons, 1 bicycle, 2 cars, 3 motorcycles, 767.6ms\n",
            "image 344/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0343.jpg: 512x640 5 persons, 2 cars, 4 motorcycles, 1 truck, 815.1ms\n",
            "image 345/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0344.jpg: 512x640 6 persons, 1 bicycle, 2 cars, 4 motorcycles, 557.1ms\n",
            "image 346/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0345.jpg: 512x640 5 persons, 1 bicycle, 2 cars, 4 motorcycles, 495.0ms\n",
            "image 347/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0346.jpg: 512x640 4 persons, 1 bicycle, 2 cars, 4 motorcycles, 2 trucks, 485.4ms\n",
            "image 348/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0347.jpg: 512x640 5 persons, 2 bicycles, 2 cars, 4 motorcycles, 1 bus, 517.3ms\n",
            "image 349/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0348.jpg: 512x640 3 persons, 2 bicycles, 2 cars, 3 motorcycles, 1 bus, 516.1ms\n",
            "image 350/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0349.jpg: 512x640 5 persons, 2 bicycles, 2 cars, 4 motorcycles, 491.0ms\n",
            "image 351/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0350.jpg: 512x640 3 persons, 1 bicycle, 2 cars, 2 motorcycles, 487.4ms\n",
            "image 352/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0351.jpg: 512x640 5 persons, 1 bicycle, 2 cars, 3 motorcycles, 486.1ms\n",
            "image 353/353 /content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616/frame_0352.jpg: 512x640 2 persons, 1 bicycle, 2 cars, 3 motorcycles, 487.9ms\n",
            "Speed: 3.6ms preprocess, 577.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/FYP/training_yolo8/annotations_20241221_173616/predict\u001b[0m\n",
            "353 labels saved to /content/drive/MyDrive/FYP/training_yolo8/annotations_20241221_173616/predict/labels\n",
            "Inference complete. Annotations saved to: /content/drive/MyDrive/FYP/training_yolo8/annotations_20241221_173616\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('yolov8s.pt')  # Change model type as needed\n",
        "\n",
        "\n",
        "# Specify directories\n",
        "# input_dir = '/content/drive/MyDrive/FYP/training_yolo8/video_frames_20241221_173616'  # Directory with images to annotate #output_dir of previous part will be input_dir here\n",
        "input_dir=output_dir\n",
        "output_annotation_dir = f'/content/drive/MyDrive/FYP/training_yolo8/annotations_{timestamp}'  # Directory to save annotations\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(output_annotation_dir, exist_ok=True)\n",
        "\n",
        "# Run inference and save annotations\n",
        "results = model.predict(source=input_dir, save=True, save_txt=True, project=output_annotation_dir)\n",
        "\n",
        "# Print results summary\n",
        "print(\"Inference complete. Annotations saved to:\", output_annotation_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkZeDRscZYa5"
      },
      "source": [
        "**Get unique class IDs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq6q1g0sYgII",
        "outputId": "b8526c6c-c11b-4d50-d745-afb5f1f5597f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique class IDs: {'5', '58', '26', '7', '9', '72', '0', '25', '56', '2', '1', '3'}\n",
            "Number of classes: 12\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path to your labels folder(from above annotation method)\n",
        "labels_path = '/content/drive/MyDrive/FYP/training_yolo8/annotations_20241221_173616/predict/labels'\n",
        "\n",
        "# Initialize a set to store unique class IDs\n",
        "class_ids = set()\n",
        "\n",
        "# Loop through each label file\n",
        "for filename in os.listdir(labels_path):\n",
        "    if filename.endswith('.txt'):\n",
        "        with open(os.path.join(labels_path, filename), 'r') as file:\n",
        "            for line in file:\n",
        "                class_id = line.split()[0]  # Get the class ID\n",
        "                class_ids.add(class_id)  # Add it to the set\n",
        "\n",
        "# Print the unique class IDs and their count\n",
        "print(\"Unique class IDs:\", class_ids)\n",
        "print(\"Number of classes:\", len(class_ids))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF1-RHHBaAGz"
      },
      "source": [
        "**Verifying COCO Classes in YOLOv8**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkTNSdYmaBhm",
        "outputId": "fd849aa3-d383-4730-e049-ad1ce6b480db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')  # Replace with your specific model file if different\n",
        "print(model.names)  # Dictionary of class IDs to names\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nB61Du7azua"
      },
      "source": [
        "**Code to Save Class Names in a List**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6EPSUh5aN5F",
        "outputId": "acb6e54c-0fa3-4777-c730-4f6b0f26500c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Names List:\n",
            "['bus', 'potted plant', 'handbag', 'truck', 'traffic light', 'refrigerator', 'person', 'umbrella', 'chair', 'car', 'bicycle', 'motorcycle']\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')  # Replace with your specific model if different\n",
        "\n",
        "# Convert IDs to integers and fetch corresponding names, saved in a list\n",
        "class_names = [model.names[int(id_)] for id_ in class_ids]\n",
        "\n",
        "# Print the list of class names\n",
        "print(\"Class Names List:\")\n",
        "print(class_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3S3rri-bQaU"
      },
      "source": [
        "**Map IDs to Sequential Indices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvqBdOaQbRjy",
        "outputId": "da071164-36b7-418e-88cd-a72b46adf84d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID to Sequential Mapping:\n",
            "{'5': 0, '58': 1, '26': 2, '7': 3, '9': 4, '72': 5, '0': 6, '25': 7, '56': 8, '2': 9, '1': 10, '3': 11}\n",
            "\n",
            "Sequential Class Names List:\n",
            "['bus', 'potted plant', 'handbag', 'truck', 'traffic light', 'refrigerator', 'person', 'umbrella', 'chair', 'car', 'bicycle', 'motorcycle']\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')  # Replace with your specific model if different\n",
        "\n",
        "# The class IDs for which you want names\n",
        "# class_ids = ['5', '58', '26', '7', '9', '72', '0', '25', '56', '2', '1', '3']\n",
        "\n",
        "# Map original IDs to sequential indices (0-11)\n",
        "id_to_sequential = {original_id: i for i, original_id in enumerate(class_ids)}\n",
        "\n",
        "# Map sequential indices to class names\n",
        "sequential_names = {id_to_sequential[id_]: model.names[int(id_)] for id_ in class_ids}\n",
        "\n",
        "# Save the mapped names in a list\n",
        "mapped_names_list = [sequential_names[i] for i in range(len(class_ids))]\n",
        "\n",
        "# Print results\n",
        "print(\"ID to Sequential Mapping:\")\n",
        "print(id_to_sequential)\n",
        "print(\"\\nSequential Class Names List:\")\n",
        "print(mapped_names_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwMQSkzjcHgI"
      },
      "source": [
        "***3. Change IDs in labels to sequential pattern***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvVbG8VbBMbE",
        "outputId": "d657086f-21d5-4ea8-81a6-175e7ac60841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class IDs updated successfully in all label files.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Directory containing annotation files.(output_annotation_dir or labels_path in previous sections)\n",
        "label_dir= \"/content/drive/MyDrive/FYP/training_yolo8/annotations_20241221_173616/predict/labels\"  # Change this to your actual path\n",
        "\n",
        "# Mapping of non-contiguous IDs to contiguous ones\n",
        "id_mapping=id_to_sequential\n",
        "\n",
        "# Iterate through all `.txt` files in the directory\n",
        "for filename in os.listdir(label_dir):\n",
        "    if filename.endswith('.txt'):  # Process only .txt files\n",
        "        file_path = os.path.join(label_dir, filename)\n",
        "\n",
        "        # Read the file contents\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        # Replace class IDs using the mapping\n",
        "        updated_lines = []\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if parts:  # Ensure the line is not empty\n",
        "                old_id = parts[0]\n",
        "                if old_id in id_mapping:\n",
        "                    parts[0] = id_mapping[old_id]  # Replace with new ID\n",
        "                updated_lines.append(' '.join(str(part) for part in parts))  # Ensure all elements are strings\n",
        "\n",
        "        # Write the updated lines back to the file\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.write('\\n'.join(updated_lines))\n",
        "\n",
        "print(\"Class IDs updated successfully in all label files.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaaA8-TTiDeN"
      },
      "source": [
        "***4. Create train and val parts***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PJ2Op7AmIdD"
      },
      "source": [
        "divide labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyegU7SJFXh9",
        "outputId": "6e4b52a4-f621-4535-ef93-4d2a587514d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied 264 annotations and images to train and 89 to val.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the directories\n",
        "base_dir = \"/content/drive/MyDrive/FYP/training_yolo8/annotations_20241221_173616/predict\"\n",
        "label_dir = Path(base_dir) / \"labels\"\n",
        "\n",
        "# Create train and val directories\n",
        "train_dir = Path(base_dir) / \"train\"\n",
        "val_dir = Path(base_dir) / \"val\"\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "train_dir.mkdir(parents=True, exist_ok=True)\n",
        "val_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Get a list of all annotation files (labels)\n",
        "label_files = sorted(label_dir.glob(\"*.txt\"))  # Sort to maintain order\n",
        "\n",
        "# Calculate the split index for 3/4 train and 1/4 validation\n",
        "split_index = int(len(label_files) * 0.75)  # 75% for training\n",
        "\n",
        "# Copy the first half to the train directory\n",
        "for label_file in label_files[:split_index]:\n",
        "    # Copy the label file to train/labels\n",
        "    shutil.copy(label_file, train_dir)\n",
        "\n",
        "# Copy the second half to the val directory\n",
        "for label_file in label_files[split_index:]:\n",
        "    # Copy the label file to val/labels\n",
        "    shutil.copy(label_file, val_dir)\n",
        "\n",
        "print(f\"Copied {split_index} annotations and images to train and {len(label_files) - split_index} to val.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F93OIWmqmNM9"
      },
      "source": [
        "divide frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt6WN4Q7MeCc",
        "outputId": "7165f50a-922b-4dd6-f8f5-4681cbc84023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied 264 frames to train and 89 frames to val.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the base directory where the frames are located\n",
        "base_dir = Path(\"/content/drive/MyDrive/FYP/training_yolo8/annotations_20241221_173616/predict\")\n",
        "\n",
        "# Create train and val directories for images\n",
        "train_dir = base_dir / \"train\"\n",
        "val_dir = base_dir / \"val\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "train_dir.mkdir(parents=True, exist_ok=True)\n",
        "val_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Get a list of all image files (frames)\n",
        "image_files = sorted(base_dir.glob(\"*.jpg\"))  # Adjust the extension if necessary\n",
        "\n",
        "# Calculate the split index for 3/4 train and 1/4 validation\n",
        "split_index = int(len(label_files) * 0.75)  # 75% for training\n",
        "\n",
        "# Copy the first half of frames to the train directory\n",
        "for image_file in image_files[:split_index]:\n",
        "    shutil.copy(image_file, train_dir)\n",
        "\n",
        "# Copy the second half of frames to the val directory\n",
        "for image_file in image_files[split_index:]:\n",
        "    shutil.copy(image_file, val_dir)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Copied {split_index} frames to train and {len(image_files) - split_index} frames to val.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zARoAM5NWzE"
      },
      "source": [
        "# Create yaml file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWQ6lQEgNZa7",
        "outputId": "d0711b45-cf29-48b0-8d3f-247ae41a28da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YAML configuration file created successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a YAML configuration file\n",
        "config_content = \"\"\"\n",
        "path: /content/drive/MyDrive/FYP/training_yolo8  # Path to your dataset\n",
        "train: /content/drive/MyDrive/FYP/training_yolo8/annotations_20241221_173616/predict/train  # Training images\n",
        "val: /content/drive/MyDrive/FYP/training_yolo8/annotations_20241221_173616/predict/val  # Validation images\n",
        "nc: 12  # Number of classes\n",
        "\n",
        "names:\n",
        "  0: bus\n",
        "  1: potted plant\n",
        "  2: handbag\n",
        "  3: truck\n",
        "  4: traffic light\n",
        "  5: refrigerator\n",
        "  6: person\n",
        "  7: umbrella\n",
        "  8: chair\n",
        "  9: car\n",
        "  10: bicycle\n",
        "  11: motorcycle\n",
        "\"\"\"\n",
        "# Save the content to a file\n",
        "with open('/content/drive/MyDrive/FYP/training_yolo8/dataset.yaml', 'w') as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "print(\"YAML configuration file created successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOTFg9gkNsFT"
      },
      "source": [
        "# Fine tune model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svPvEXjQQm1U",
        "outputId": "e7ae036d-7884-4120-d257-f911b8697636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'models/yolov8n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 96.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.53 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=models/yolov8n.pt, data=/content/drive/MyDrive/FYP/training_yolo8/dataset.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 18.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753652  ultralytics.nn.modules.head.Detect           [12, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3,013,188 parameters, 3,013,172 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 80.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/FYP/training_yolo8/annotations_20241221_173616/predict/train.cache... 264 images, 0 backgrounds, 0 corrupt: 100%|██████████| 264/264 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/FYP/training_yolo8/annotations_20241221_173616/predict/val.cache... 89 images, 0 backgrounds, 0 corrupt: 100%|██████████| 89/89 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/50      2.37G      1.585      4.138      1.335        131        640: 100%|██████████| 17/17 [00:31<00:00,  1.86s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266     0.0367      0.211     0.0571     0.0493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/50       2.6G      1.314      2.487      1.078        139        640: 100%|██████████| 17/17 [00:04<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266     0.0394      0.262      0.126     0.0914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/50       2.4G      1.081      1.619     0.9906        116        640: 100%|██████████| 17/17 [00:05<00:00,  2.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266     0.0373      0.349      0.128       0.09\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/50      2.47G     0.9785      1.278     0.9613        152        640: 100%|██████████| 17/17 [00:05<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266       0.73      0.104      0.175      0.127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/50      2.45G     0.9276       1.12     0.9438        113        640: 100%|██████████| 17/17 [00:04<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.672      0.237      0.287      0.203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/50      2.32G     0.8604      1.038     0.9314        142        640: 100%|██████████| 17/17 [00:06<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.742      0.308      0.353       0.25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/50      2.48G      0.829     0.9701     0.9185        130        640: 100%|██████████| 17/17 [00:04<00:00,  3.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.734      0.335      0.365      0.269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/50      2.41G     0.7983     0.9064     0.9111        133        640: 100%|██████████| 17/17 [00:07<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266       0.74      0.363       0.41      0.309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/50      2.38G     0.7645     0.8563     0.9029        134        640: 100%|██████████| 17/17 [00:04<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.672       0.35      0.413      0.307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/50       2.5G     0.7389     0.8496     0.8989        150        640: 100%|██████████| 17/17 [00:05<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266       0.77      0.358      0.412      0.308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/50      2.53G     0.7288     0.8077      0.882        152        640: 100%|██████████| 17/17 [00:04<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.688      0.568      0.536       0.41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/50      2.41G      0.717     0.7978     0.8891        102        640: 100%|██████████| 17/17 [00:04<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.746      0.482      0.536      0.418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/50      2.36G     0.6944     0.7776     0.8839        167        640: 100%|██████████| 17/17 [00:06<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.708      0.554      0.547      0.419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/50      2.51G     0.6755     0.7509     0.8732        137        640: 100%|██████████| 17/17 [00:04<00:00,  3.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.779       0.49      0.549       0.43\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/50      2.39G     0.6567     0.7306     0.8729        142        640: 100%|██████████| 17/17 [00:07<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266       0.91      0.492      0.558      0.426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/50      2.64G     0.6411     0.7131      0.868        120        640: 100%|██████████| 17/17 [00:04<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.738      0.556      0.573      0.451\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/50      2.55G     0.6278     0.7056     0.8637        163        640: 100%|██████████| 17/17 [00:05<00:00,  2.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.784      0.539      0.581      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/50      2.61G     0.6304     0.6943     0.8612        165        640: 100%|██████████| 17/17 [00:04<00:00,  3.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.808      0.536      0.617      0.498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/50      2.46G     0.6114     0.6682     0.8534        118        640: 100%|██████████| 17/17 [00:05<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.811       0.55      0.596      0.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/50      2.42G     0.6186     0.6707     0.8599        163        640: 100%|██████████| 17/17 [00:05<00:00,  3.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.835      0.549      0.616       0.49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/50      2.58G     0.6151     0.6631     0.8523        152        640: 100%|██████████| 17/17 [00:04<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266       0.85      0.542      0.617      0.497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/50      2.45G     0.6001     0.6502     0.8546        178        640: 100%|██████████| 17/17 [00:07<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.755      0.572      0.599      0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/50      2.42G     0.5865     0.6419     0.8488        139        640: 100%|██████████| 17/17 [00:04<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266       0.82      0.551      0.613      0.484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/50      2.29G     0.5735     0.6372       0.85        185        640: 100%|██████████| 17/17 [00:07<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.753      0.603      0.602       0.49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      25/50       2.4G     0.5463       0.61     0.8441        115        640: 100%|██████████| 17/17 [00:04<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.922      0.513      0.596      0.484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      26/50      2.59G      0.575     0.6345     0.8473        142        640: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.842      0.555      0.613      0.497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      27/50      2.51G     0.5591      0.615     0.8394        132        640: 100%|██████████| 17/17 [00:05<00:00,  3.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.773      0.575      0.615      0.506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      28/50      2.42G     0.5481     0.6083     0.8447        133        640: 100%|██████████| 17/17 [00:04<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.946      0.494      0.603      0.488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      29/50      2.41G     0.5491     0.6037     0.8459        178        640: 100%|██████████| 17/17 [00:06<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.801      0.549      0.636      0.525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      30/50      2.35G     0.5509     0.5964     0.8461        135        640: 100%|██████████| 17/17 [00:04<00:00,  3.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.843      0.541      0.626       0.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      31/50      2.36G     0.5318     0.5928     0.8426        153        640: 100%|██████████| 17/17 [00:07<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.923      0.513       0.59      0.487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      32/50      2.51G     0.5454     0.5843     0.8441        191        640: 100%|██████████| 17/17 [00:04<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.792      0.569      0.616        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      33/50      2.45G     0.5217     0.5676     0.8407        154        640: 100%|██████████| 17/17 [00:05<00:00,  3.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.761      0.577      0.617      0.498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      34/50      2.52G     0.5414     0.5774     0.8447        183        640: 100%|██████████| 17/17 [00:04<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.696      0.588      0.622      0.504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      35/50      2.51G     0.5336     0.5645     0.8379        153        640: 100%|██████████| 17/17 [00:04<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.786      0.587      0.639       0.52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      36/50      2.38G     0.5249     0.5559      0.837        197        640: 100%|██████████| 17/17 [00:06<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.722      0.582      0.653      0.541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      37/50      2.49G     0.5056     0.5456     0.8377        127        640: 100%|██████████| 17/17 [00:04<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.676       0.58      0.636      0.529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      38/50      2.37G     0.5027     0.5446     0.8362        181        640: 100%|██████████| 17/17 [00:07<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.714      0.621      0.639       0.53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      39/50      2.31G     0.5232     0.5484       0.84        118        640: 100%|██████████| 17/17 [00:04<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266       0.82      0.561      0.643      0.531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      40/50      2.28G     0.5142     0.5414     0.8381        112        640: 100%|██████████| 17/17 [00:06<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266       0.85       0.55      0.637      0.531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      41/50      2.18G     0.4958     0.5859     0.8248         62        640: 100%|██████████| 17/17 [00:06<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.713      0.564      0.601      0.476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      42/50       2.2G     0.4853     0.5631     0.8205         88        640: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.791       0.57       0.61      0.482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      43/50      2.19G     0.4807     0.5536     0.8189         88        640: 100%|██████████| 17/17 [00:04<00:00,  3.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.843      0.548       0.62      0.497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      44/50       2.2G     0.4745     0.5415     0.8157         70        640: 100%|██████████| 17/17 [00:04<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.829      0.562      0.609      0.505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      45/50      2.19G     0.4626     0.5296       0.82         79        640: 100%|██████████| 17/17 [00:06<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.801      0.567      0.608      0.494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      46/50       2.2G     0.4666     0.5307     0.8172         80        640: 100%|██████████| 17/17 [00:04<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.853      0.544      0.605      0.492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      47/50      2.19G     0.4596     0.5144     0.8188         78        640: 100%|██████████| 17/17 [00:06<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.823      0.548      0.601      0.483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      48/50      2.19G      0.457     0.5156     0.8176         73        640: 100%|██████████| 17/17 [00:04<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.808      0.539      0.603      0.474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      49/50      2.19G     0.4509     0.5132     0.8183         90        640: 100%|██████████| 17/17 [00:04<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.817      0.538      0.603      0.486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      50/50       2.2G      0.453      0.514     0.8087         85        640: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.834      0.549      0.608      0.488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "50 epochs completed in 0.120 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.53 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,007,988 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         89       1266      0.718      0.582      0.653      0.542\n",
            "                   bus         15         15      0.549     0.0667      0.141     0.0871\n",
            "               handbag          1          1      0.841          1      0.995      0.995\n",
            "                 truck         64         76      0.637          1       0.96      0.866\n",
            "                person         89        618      0.732      0.907      0.919      0.747\n",
            "              umbrella         10         10          1          0      0.311      0.301\n",
            "                   car         89        180      0.752        0.7      0.748      0.519\n",
            "               bicycle         11         14      0.296      0.214      0.223      0.128\n",
            "            motorcycle         89        352       0.94       0.77      0.927       0.69\n",
            "Speed: 0.2ms preprocess, 2.9ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary library\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "# Load YOLOv8 model (pre-trained)\n",
        "model = YOLO('models/yolov8n.pt')  # Ensure this path is correct\n",
        "\n",
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = '0'  # Use the first GPU\n",
        "else:\n",
        "    device = 'cpu'  # Fallback to CPU if no GPU is available\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    data='/content/drive/MyDrive/FYP/training_yolo8/dataset.yaml',  # Path to your dataset.yaml\n",
        "    epochs=50,         # Number of training epochs\n",
        "    batch=16,          # Batch size\n",
        "    imgsz=640,         # Image size\n",
        "    device=device,     # Use GPU if available\n",
        "    workers=4          # Adjust based on your CPU for data loading (optional)\n",
        ")\n",
        "\n",
        "# Save the trained model if needed\n",
        "model.save('/content/drive/MyDrive/FYP/training_yolo8/trained_yolov8_model.pt')  # Save the trained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sab28663RpKC"
      },
      "source": [
        "# Test using trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_WK1zhERt28",
        "outputId": "7b462952-eade-450f-b00f-f761d325fb0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 416.3ms\n",
            "Speed: 24.2ms preprocess, 416.3ms inference, 35.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 223.7ms\n",
            "Speed: 5.3ms preprocess, 223.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 220.1ms\n",
            "Speed: 7.1ms preprocess, 220.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 242.2ms\n",
            "Speed: 9.4ms preprocess, 242.2ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 213.7ms\n",
            "Speed: 8.9ms preprocess, 213.7ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 219.7ms\n",
            "Speed: 4.3ms preprocess, 219.7ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 217.7ms\n",
            "Speed: 8.5ms preprocess, 217.7ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 225.5ms\n",
            "Speed: 7.4ms preprocess, 225.5ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 208.0ms\n",
            "Speed: 7.7ms preprocess, 208.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 219.5ms\n",
            "Speed: 10.9ms preprocess, 219.5ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 225.9ms\n",
            "Speed: 7.9ms preprocess, 225.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 225.0ms\n",
            "Speed: 8.5ms preprocess, 225.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 206.9ms\n",
            "Speed: 6.3ms preprocess, 206.9ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 212.8ms\n",
            "Speed: 7.1ms preprocess, 212.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 187.1ms\n",
            "Speed: 5.0ms preprocess, 187.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 200.7ms\n",
            "Speed: 5.2ms preprocess, 200.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 243.6ms\n",
            "Speed: 6.8ms preprocess, 243.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 312.0ms\n",
            "Speed: 6.3ms preprocess, 312.0ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 319.8ms\n",
            "Speed: 7.2ms preprocess, 319.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 304.2ms\n",
            "Speed: 7.3ms preprocess, 304.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 313.8ms\n",
            "Speed: 7.0ms preprocess, 313.8ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 354.6ms\n",
            "Speed: 7.1ms preprocess, 354.6ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 320.1ms\n",
            "Speed: 12.7ms preprocess, 320.1ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 316.8ms\n",
            "Speed: 11.0ms preprocess, 316.8ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 332.2ms\n",
            "Speed: 9.7ms preprocess, 332.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 304.2ms\n",
            "Speed: 8.2ms preprocess, 304.2ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 344.7ms\n",
            "Speed: 7.7ms preprocess, 344.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 328.6ms\n",
            "Speed: 8.2ms preprocess, 328.6ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 314.1ms\n",
            "Speed: 8.0ms preprocess, 314.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 340.7ms\n",
            "Speed: 10.3ms preprocess, 340.7ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 208.2ms\n",
            "Speed: 7.7ms preprocess, 208.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 213.4ms\n",
            "Speed: 4.3ms preprocess, 213.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 199.7ms\n",
            "Speed: 5.1ms preprocess, 199.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 259.5ms\n",
            "Speed: 5.9ms preprocess, 259.5ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 209.0ms\n",
            "Speed: 7.6ms preprocess, 209.0ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 213.9ms\n",
            "Speed: 5.5ms preprocess, 213.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 202.2ms\n",
            "Speed: 9.8ms preprocess, 202.2ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 246.0ms\n",
            "Speed: 6.2ms preprocess, 246.0ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 198.5ms\n",
            "Speed: 8.0ms preprocess, 198.5ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 200.3ms\n",
            "Speed: 4.5ms preprocess, 200.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 200.1ms\n",
            "Speed: 8.5ms preprocess, 200.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 227.9ms\n",
            "Speed: 5.9ms preprocess, 227.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 206.0ms\n",
            "Speed: 8.5ms preprocess, 206.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 203.9ms\n",
            "Speed: 7.1ms preprocess, 203.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 196.6ms\n",
            "Speed: 7.1ms preprocess, 196.6ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 237.4ms\n",
            "Speed: 7.9ms preprocess, 237.4ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 208.6ms\n",
            "Speed: 8.0ms preprocess, 208.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 198.5ms\n",
            "Speed: 7.6ms preprocess, 198.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 221.0ms\n",
            "Speed: 8.9ms preprocess, 221.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 218.3ms\n",
            "Speed: 7.1ms preprocess, 218.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 184.3ms\n",
            "Speed: 7.8ms preprocess, 184.3ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 car, 189.0ms\n",
            "Speed: 10.1ms preprocess, 189.0ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 car, 189.5ms\n",
            "Speed: 5.5ms preprocess, 189.5ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 car, 226.3ms\n",
            "Speed: 10.2ms preprocess, 226.3ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 car, 223.2ms\n",
            "Speed: 8.7ms preprocess, 223.2ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 204.1ms\n",
            "Speed: 7.8ms preprocess, 204.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 212.9ms\n",
            "Speed: 5.4ms preprocess, 212.9ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 234.2ms\n",
            "Speed: 6.4ms preprocess, 234.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 221.2ms\n",
            "Speed: 5.4ms preprocess, 221.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 208.1ms\n",
            "Speed: 6.2ms preprocess, 208.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 189.1ms\n",
            "Speed: 6.3ms preprocess, 189.1ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 220.7ms\n",
            "Speed: 5.7ms preprocess, 220.7ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 214.2ms\n",
            "Speed: 7.9ms preprocess, 214.2ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 200.1ms\n",
            "Speed: 7.0ms preprocess, 200.1ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 210.2ms\n",
            "Speed: 7.4ms preprocess, 210.2ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 226.8ms\n",
            "Speed: 9.5ms preprocess, 226.8ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 225.2ms\n",
            "Speed: 6.0ms preprocess, 225.2ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 206.1ms\n",
            "Speed: 5.4ms preprocess, 206.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 192.3ms\n",
            "Speed: 8.1ms preprocess, 192.3ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 224.7ms\n",
            "Speed: 7.6ms preprocess, 224.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 307.6ms\n",
            "Speed: 7.7ms preprocess, 307.6ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 352.4ms\n",
            "Speed: 4.3ms preprocess, 352.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 365.7ms\n",
            "Speed: 7.7ms preprocess, 365.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 310.4ms\n",
            "Speed: 7.9ms preprocess, 310.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 329.8ms\n",
            "Speed: 8.2ms preprocess, 329.8ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 307.1ms\n",
            "Speed: 8.5ms preprocess, 307.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 306.5ms\n",
            "Speed: 5.7ms preprocess, 306.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 338.4ms\n",
            "Speed: 8.4ms preprocess, 338.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 315.3ms\n",
            "Speed: 10.1ms preprocess, 315.3ms inference, 3.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 329.5ms\n",
            "Speed: 9.1ms preprocess, 329.5ms inference, 3.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 347.7ms\n",
            "Speed: 9.5ms preprocess, 347.7ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 308.6ms\n",
            "Speed: 5.0ms preprocess, 308.6ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 338.6ms\n",
            "Speed: 5.9ms preprocess, 338.6ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 324.4ms\n",
            "Speed: 12.1ms preprocess, 324.4ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 1 motorcycle, 212.7ms\n",
            "Speed: 8.4ms preprocess, 212.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 persons, 209.8ms\n",
            "Speed: 4.8ms preprocess, 209.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 persons, 232.9ms\n",
            "Speed: 8.3ms preprocess, 232.9ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 persons, 212.1ms\n",
            "Speed: 10.1ms preprocess, 212.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 204.7ms\n",
            "Speed: 6.7ms preprocess, 204.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 211.8ms\n",
            "Speed: 5.5ms preprocess, 211.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 251.2ms\n",
            "Speed: 9.4ms preprocess, 251.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 189.6ms\n",
            "Speed: 4.9ms preprocess, 189.6ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 208.1ms\n",
            "Speed: 7.5ms preprocess, 208.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 247.1ms\n",
            "Speed: 5.9ms preprocess, 247.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 231.6ms\n",
            "Speed: 8.7ms preprocess, 231.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 220.6ms\n",
            "Speed: 8.3ms preprocess, 220.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 200.4ms\n",
            "Speed: 7.2ms preprocess, 200.4ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 232.0ms\n",
            "Speed: 9.5ms preprocess, 232.0ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 225.3ms\n",
            "Speed: 9.3ms preprocess, 225.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 224.9ms\n",
            "Speed: 8.1ms preprocess, 224.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 217.0ms\n",
            "Speed: 8.7ms preprocess, 217.0ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 221.9ms\n",
            "Speed: 7.8ms preprocess, 221.9ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 214.7ms\n",
            "Speed: 9.6ms preprocess, 214.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 200.2ms\n",
            "Speed: 5.8ms preprocess, 200.2ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 1 car, 226.6ms\n",
            "Speed: 4.3ms preprocess, 226.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 1 car, 226.2ms\n",
            "Speed: 7.6ms preprocess, 226.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 233.2ms\n",
            "Speed: 9.6ms preprocess, 233.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 1 car, 225.5ms\n",
            "Speed: 7.5ms preprocess, 225.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 1 car, 199.1ms\n",
            "Speed: 4.5ms preprocess, 199.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 2 cars, 1 motorcycle, 237.9ms\n",
            "Speed: 7.4ms preprocess, 237.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 1 car, 206.9ms\n",
            "Speed: 8.5ms preprocess, 206.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 1 car, 210.2ms\n",
            "Speed: 7.9ms preprocess, 210.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 1 car, 1 motorcycle, 196.7ms\n",
            "Speed: 8.3ms preprocess, 196.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 1 car, 239.1ms\n",
            "Speed: 7.0ms preprocess, 239.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 1 car, 195.8ms\n",
            "Speed: 8.0ms preprocess, 195.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 2 persons, 1 car, 196.4ms\n",
            "Speed: 8.3ms preprocess, 196.4ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 1 car, 191.3ms\n",
            "Speed: 7.8ms preprocess, 191.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 1 car, 229.8ms\n",
            "Speed: 4.3ms preprocess, 229.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 1 car, 206.9ms\n",
            "Speed: 7.9ms preprocess, 206.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 1 car, 194.8ms\n",
            "Speed: 6.2ms preprocess, 194.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 1 car, 196.8ms\n",
            "Speed: 6.9ms preprocess, 196.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 1 car, 242.6ms\n",
            "Speed: 8.6ms preprocess, 242.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 1 car, 214.1ms\n",
            "Speed: 7.3ms preprocess, 214.1ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 1 car, 296.7ms\n",
            "Speed: 9.1ms preprocess, 296.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 1 car, 336.1ms\n",
            "Speed: 6.2ms preprocess, 336.1ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 337.2ms\n",
            "Speed: 9.8ms preprocess, 337.2ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 298.0ms\n",
            "Speed: 7.7ms preprocess, 298.0ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 367.4ms\n",
            "Speed: 8.5ms preprocess, 367.4ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 324.7ms\n",
            "Speed: 13.2ms preprocess, 324.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 1 car, 332.6ms\n",
            "Speed: 8.2ms preprocess, 332.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 1 car, 327.1ms\n",
            "Speed: 11.2ms preprocess, 327.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 307.9ms\n",
            "Speed: 7.9ms preprocess, 307.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 366.3ms\n",
            "Speed: 10.4ms preprocess, 366.3ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 333.4ms\n",
            "Speed: 7.2ms preprocess, 333.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 349.1ms\n",
            "Speed: 7.8ms preprocess, 349.1ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 309.2ms\n",
            "Speed: 5.3ms preprocess, 309.2ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 298.5ms\n",
            "Speed: 7.3ms preprocess, 298.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 206.6ms\n",
            "Speed: 7.6ms preprocess, 206.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 221.8ms\n",
            "Speed: 11.1ms preprocess, 221.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 227.1ms\n",
            "Speed: 8.2ms preprocess, 227.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 217.8ms\n",
            "Speed: 7.8ms preprocess, 217.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 car, 190.1ms\n",
            "Speed: 5.8ms preprocess, 190.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 228.7ms\n",
            "Speed: 7.3ms preprocess, 228.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 198.7ms\n",
            "Speed: 6.8ms preprocess, 198.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 231.7ms\n",
            "Speed: 6.2ms preprocess, 231.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 203.5ms\n",
            "Speed: 6.9ms preprocess, 203.5ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 217.9ms\n",
            "Speed: 10.5ms preprocess, 217.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 213.4ms\n",
            "Speed: 8.9ms preprocess, 213.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 210.6ms\n",
            "Speed: 6.7ms preprocess, 210.6ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 220.0ms\n",
            "Speed: 8.1ms preprocess, 220.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 202.5ms\n",
            "Speed: 7.7ms preprocess, 202.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 206.4ms\n",
            "Speed: 8.3ms preprocess, 206.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 238.4ms\n",
            "Speed: 7.1ms preprocess, 238.4ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 218.8ms\n",
            "Speed: 7.1ms preprocess, 218.8ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 203.0ms\n",
            "Speed: 7.8ms preprocess, 203.0ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 217.7ms\n",
            "Speed: 6.8ms preprocess, 217.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 222.0ms\n",
            "Speed: 6.9ms preprocess, 222.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 224.1ms\n",
            "Speed: 8.0ms preprocess, 224.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 220.1ms\n",
            "Speed: 4.9ms preprocess, 220.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 206.8ms\n",
            "Speed: 7.7ms preprocess, 206.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 trucks, 216.9ms\n",
            "Speed: 7.0ms preprocess, 216.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 232.4ms\n",
            "Speed: 5.5ms preprocess, 232.4ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 215.2ms\n",
            "Speed: 7.8ms preprocess, 215.2ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 trucks, 1 person, 203.4ms\n",
            "Speed: 7.8ms preprocess, 203.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 trucks, 1 person, 219.0ms\n",
            "Speed: 8.4ms preprocess, 219.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 trucks, 1 person, 240.1ms\n",
            "Speed: 6.7ms preprocess, 240.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 206.1ms\n",
            "Speed: 6.1ms preprocess, 206.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 trucks, 202.2ms\n",
            "Speed: 7.5ms preprocess, 202.2ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 238.5ms\n",
            "Speed: 7.2ms preprocess, 238.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 233.3ms\n",
            "Speed: 7.9ms preprocess, 233.3ms inference, 3.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 215.1ms\n",
            "Speed: 6.9ms preprocess, 215.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 208.8ms\n",
            "Speed: 9.1ms preprocess, 208.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 208.9ms\n",
            "Speed: 5.3ms preprocess, 208.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 240.4ms\n",
            "Speed: 13.1ms preprocess, 240.4ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 259.1ms\n",
            "Speed: 7.4ms preprocess, 259.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 1 car, 320.1ms\n",
            "Speed: 8.2ms preprocess, 320.1ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 377.9ms\n",
            "Speed: 32.3ms preprocess, 377.9ms inference, 5.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 309.0ms\n",
            "Speed: 14.9ms preprocess, 309.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 321.9ms\n",
            "Speed: 4.7ms preprocess, 321.9ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 333.4ms\n",
            "Speed: 7.8ms preprocess, 333.4ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 314.0ms\n",
            "Speed: 7.9ms preprocess, 314.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 367.6ms\n",
            "Speed: 7.9ms preprocess, 367.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 325.2ms\n",
            "Speed: 11.6ms preprocess, 325.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 293.6ms\n",
            "Speed: 11.7ms preprocess, 293.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 335.0ms\n",
            "Speed: 9.3ms preprocess, 335.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 340.0ms\n",
            "Speed: 10.1ms preprocess, 340.0ms inference, 3.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 312.2ms\n",
            "Speed: 9.1ms preprocess, 312.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 315.1ms\n",
            "Speed: 6.8ms preprocess, 315.1ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 259.3ms\n",
            "Speed: 6.7ms preprocess, 259.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 216.4ms\n",
            "Speed: 8.2ms preprocess, 216.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 214.3ms\n",
            "Speed: 7.9ms preprocess, 214.3ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 216.1ms\n",
            "Speed: 7.5ms preprocess, 216.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 199.5ms\n",
            "Speed: 5.2ms preprocess, 199.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 216.8ms\n",
            "Speed: 9.0ms preprocess, 216.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 212.2ms\n",
            "Speed: 7.8ms preprocess, 212.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 230.2ms\n",
            "Speed: 6.8ms preprocess, 230.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 217.0ms\n",
            "Speed: 7.6ms preprocess, 217.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 226.2ms\n",
            "Speed: 8.9ms preprocess, 226.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 207.6ms\n",
            "Speed: 7.2ms preprocess, 207.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 222.3ms\n",
            "Speed: 7.6ms preprocess, 222.3ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 203.7ms\n",
            "Speed: 7.2ms preprocess, 203.7ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 231.1ms\n",
            "Speed: 7.6ms preprocess, 231.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 207.1ms\n",
            "Speed: 7.7ms preprocess, 207.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 230.1ms\n",
            "Speed: 10.0ms preprocess, 230.1ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 209.4ms\n",
            "Speed: 7.1ms preprocess, 209.4ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 238.9ms\n",
            "Speed: 7.9ms preprocess, 238.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 209.8ms\n",
            "Speed: 7.2ms preprocess, 209.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 240.3ms\n",
            "Speed: 8.5ms preprocess, 240.3ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 206.0ms\n",
            "Speed: 4.1ms preprocess, 206.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 257.0ms\n",
            "Speed: 7.5ms preprocess, 257.0ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 1 person, 233.1ms\n",
            "Speed: 10.2ms preprocess, 233.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 230.7ms\n",
            "Speed: 9.5ms preprocess, 230.7ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 226.2ms\n",
            "Speed: 6.5ms preprocess, 226.2ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 209.0ms\n",
            "Speed: 7.4ms preprocess, 209.0ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 228.7ms\n",
            "Speed: 7.7ms preprocess, 228.7ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 210.8ms\n",
            "Speed: 7.3ms preprocess, 210.8ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 233.2ms\n",
            "Speed: 8.2ms preprocess, 233.2ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 207.7ms\n",
            "Speed: 4.6ms preprocess, 207.7ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 209.3ms\n",
            "Speed: 13.7ms preprocess, 209.3ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 217.0ms\n",
            "Speed: 7.3ms preprocess, 217.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 226.5ms\n",
            "Speed: 7.8ms preprocess, 226.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 204.5ms\n",
            "Speed: 5.6ms preprocess, 204.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 204.2ms\n",
            "Speed: 6.3ms preprocess, 204.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 212.9ms\n",
            "Speed: 7.9ms preprocess, 212.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 227.8ms\n",
            "Speed: 7.3ms preprocess, 227.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 192.9ms\n",
            "Speed: 6.2ms preprocess, 192.9ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 204.8ms\n",
            "Speed: 7.1ms preprocess, 204.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 253.0ms\n",
            "Speed: 4.1ms preprocess, 253.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 332.4ms\n",
            "Speed: 6.4ms preprocess, 332.4ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 346.0ms\n",
            "Speed: 8.8ms preprocess, 346.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 305.8ms\n",
            "Speed: 7.3ms preprocess, 305.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 308.8ms\n",
            "Speed: 11.7ms preprocess, 308.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 323.6ms\n",
            "Speed: 8.2ms preprocess, 323.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 348.9ms\n",
            "Speed: 10.1ms preprocess, 348.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 357.0ms\n",
            "Speed: 8.0ms preprocess, 357.0ms inference, 4.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 323.7ms\n",
            "Speed: 8.1ms preprocess, 323.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 320.3ms\n",
            "Speed: 10.6ms preprocess, 320.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 369.0ms\n",
            "Speed: 8.4ms preprocess, 369.0ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 370.5ms\n",
            "Speed: 7.2ms preprocess, 370.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 337.6ms\n",
            "Speed: 7.7ms preprocess, 337.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 333.6ms\n",
            "Speed: 7.7ms preprocess, 333.6ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 275.1ms\n",
            "Speed: 8.1ms preprocess, 275.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 201.6ms\n",
            "Speed: 7.7ms preprocess, 201.6ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 208.9ms\n",
            "Speed: 7.5ms preprocess, 208.9ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 213.2ms\n",
            "Speed: 3.9ms preprocess, 213.2ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 266.3ms\n",
            "Speed: 7.8ms preprocess, 266.3ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 202.7ms\n",
            "Speed: 7.0ms preprocess, 202.7ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 221.7ms\n",
            "Speed: 8.4ms preprocess, 221.7ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 209.0ms\n",
            "Speed: 5.6ms preprocess, 209.0ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 239.7ms\n",
            "Speed: 8.5ms preprocess, 239.7ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 209.5ms\n",
            "Speed: 9.9ms preprocess, 209.5ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 194.9ms\n",
            "Speed: 6.1ms preprocess, 194.9ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 219.9ms\n",
            "Speed: 7.6ms preprocess, 219.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 221.1ms\n",
            "Speed: 6.2ms preprocess, 221.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 212.7ms\n",
            "Speed: 5.5ms preprocess, 212.7ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 208.9ms\n",
            "Speed: 8.3ms preprocess, 208.9ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 211.6ms\n",
            "Speed: 7.8ms preprocess, 211.6ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 217.6ms\n",
            "Speed: 5.2ms preprocess, 217.6ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 218.5ms\n",
            "Speed: 7.7ms preprocess, 218.5ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 216.0ms\n",
            "Speed: 7.9ms preprocess, 216.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 215.6ms\n",
            "Speed: 7.0ms preprocess, 215.6ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 223.3ms\n",
            "Speed: 7.9ms preprocess, 223.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 219.6ms\n",
            "Speed: 9.6ms preprocess, 219.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 211.2ms\n",
            "Speed: 7.7ms preprocess, 211.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 216.0ms\n",
            "Speed: 7.9ms preprocess, 216.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 210.8ms\n",
            "Speed: 9.3ms preprocess, 210.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 224.3ms\n",
            "Speed: 9.1ms preprocess, 224.3ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 217.1ms\n",
            "Speed: 7.6ms preprocess, 217.1ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 222.2ms\n",
            "Speed: 7.7ms preprocess, 222.2ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 205.8ms\n",
            "Speed: 4.8ms preprocess, 205.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 221.1ms\n",
            "Speed: 7.2ms preprocess, 221.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 213.6ms\n",
            "Speed: 8.2ms preprocess, 213.6ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 236.2ms\n",
            "Speed: 6.9ms preprocess, 236.2ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 199.7ms\n",
            "Speed: 10.8ms preprocess, 199.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 212.4ms\n",
            "Speed: 4.8ms preprocess, 212.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 207.3ms\n",
            "Speed: 9.2ms preprocess, 207.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 210.0ms\n",
            "Speed: 7.4ms preprocess, 210.0ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 200.2ms\n",
            "Speed: 4.6ms preprocess, 200.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 211.6ms\n",
            "Speed: 8.0ms preprocess, 211.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 208.7ms\n",
            "Speed: 8.8ms preprocess, 208.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 287.7ms\n",
            "Speed: 8.2ms preprocess, 287.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 345.2ms\n",
            "Speed: 8.1ms preprocess, 345.2ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 1 person, 394.9ms\n",
            "Speed: 9.7ms preprocess, 394.9ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 315.6ms\n",
            "Speed: 7.3ms preprocess, 315.6ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 331.4ms\n",
            "Speed: 7.3ms preprocess, 331.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 358.8ms\n",
            "Speed: 10.0ms preprocess, 358.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 328.9ms\n",
            "Speed: 7.4ms preprocess, 328.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 316.5ms\n",
            "Speed: 5.8ms preprocess, 316.5ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 311.0ms\n",
            "Speed: 9.9ms preprocess, 311.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 307.3ms\n",
            "Speed: 9.9ms preprocess, 307.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 340.4ms\n",
            "Speed: 11.4ms preprocess, 340.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 348.0ms\n",
            "Speed: 7.5ms preprocess, 348.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 340.4ms\n",
            "Speed: 8.9ms preprocess, 340.4ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 336.7ms\n",
            "Speed: 8.0ms preprocess, 336.7ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 252.6ms\n",
            "Speed: 11.3ms preprocess, 252.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 204.4ms\n",
            "Speed: 7.9ms preprocess, 204.4ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 218.7ms\n",
            "Speed: 10.4ms preprocess, 218.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 241.4ms\n",
            "Speed: 7.6ms preprocess, 241.4ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 227.1ms\n",
            "Speed: 7.7ms preprocess, 227.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 225.4ms\n",
            "Speed: 7.7ms preprocess, 225.4ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 218.0ms\n",
            "Speed: 7.4ms preprocess, 218.0ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 236.6ms\n",
            "Speed: 10.5ms preprocess, 236.6ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 211.5ms\n",
            "Speed: 5.4ms preprocess, 211.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 221.2ms\n",
            "Speed: 7.4ms preprocess, 221.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 517.0ms\n",
            "Speed: 6.6ms preprocess, 517.0ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 199.3ms\n",
            "Speed: 7.2ms preprocess, 199.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 320.1ms\n",
            "Speed: 8.6ms preprocess, 320.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 463.2ms\n",
            "Speed: 21.0ms preprocess, 463.2ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 215.0ms\n",
            "Speed: 8.3ms preprocess, 215.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 489.5ms\n",
            "Speed: 7.8ms preprocess, 489.5ms inference, 6.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 238.3ms\n",
            "Speed: 8.6ms preprocess, 238.3ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 207.1ms\n",
            "Speed: 7.3ms preprocess, 207.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 214.2ms\n",
            "Speed: 7.0ms preprocess, 214.2ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 220.3ms\n",
            "Speed: 9.6ms preprocess, 220.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 206.7ms\n",
            "Speed: 7.5ms preprocess, 206.7ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 213.3ms\n",
            "Speed: 8.2ms preprocess, 213.3ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 207.7ms\n",
            "Speed: 8.6ms preprocess, 207.7ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 218.7ms\n",
            "Speed: 10.2ms preprocess, 218.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 193.1ms\n",
            "Speed: 5.5ms preprocess, 193.1ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 215.1ms\n",
            "Speed: 7.4ms preprocess, 215.1ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 197.2ms\n",
            "Speed: 6.0ms preprocess, 197.2ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 214.4ms\n",
            "Speed: 12.1ms preprocess, 214.4ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 215.1ms\n",
            "Speed: 9.4ms preprocess, 215.1ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 229.4ms\n",
            "Speed: 9.3ms preprocess, 229.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 205.2ms\n",
            "Speed: 6.6ms preprocess, 205.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 191.9ms\n",
            "Speed: 7.2ms preprocess, 191.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 223.3ms\n",
            "Speed: 8.6ms preprocess, 223.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 217.6ms\n",
            "Speed: 8.4ms preprocess, 217.6ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 202.0ms\n",
            "Speed: 8.9ms preprocess, 202.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 219.8ms\n",
            "Speed: 8.6ms preprocess, 219.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 318.7ms\n",
            "Speed: 9.7ms preprocess, 318.7ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 301.2ms\n",
            "Speed: 6.5ms preprocess, 301.2ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 324.9ms\n",
            "Speed: 8.1ms preprocess, 324.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 320.4ms\n",
            "Speed: 4.4ms preprocess, 320.4ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 324.1ms\n",
            "Speed: 8.0ms preprocess, 324.1ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 323.6ms\n",
            "Speed: 9.7ms preprocess, 323.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 334.4ms\n",
            "Speed: 8.1ms preprocess, 334.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 323.8ms\n",
            "Speed: 7.9ms preprocess, 323.8ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 303.0ms\n",
            "Speed: 14.9ms preprocess, 303.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 336.7ms\n",
            "Speed: 7.8ms preprocess, 336.7ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 319.9ms\n",
            "Speed: 7.8ms preprocess, 319.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 315.5ms\n",
            "Speed: 7.9ms preprocess, 315.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 333.5ms\n",
            "Speed: 7.9ms preprocess, 333.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 331.6ms\n",
            "Speed: 8.9ms preprocess, 331.6ms inference, 4.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 233.9ms\n",
            "Speed: 12.6ms preprocess, 233.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 213.7ms\n",
            "Speed: 10.1ms preprocess, 213.7ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 214.4ms\n",
            "Speed: 8.6ms preprocess, 214.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 199.5ms\n",
            "Speed: 5.5ms preprocess, 199.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 218.0ms\n",
            "Speed: 6.9ms preprocess, 218.0ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 truck, 217.5ms\n",
            "Speed: 8.6ms preprocess, 217.5ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 trucks, 229.5ms\n",
            "Speed: 8.4ms preprocess, 229.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 trucks, 205.4ms\n",
            "Speed: 8.6ms preprocess, 205.4ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 trucks, 206.4ms\n",
            "Speed: 7.1ms preprocess, 206.4ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "Processed 353 frames.\n",
            "Annotated video saved at: /content/drive/MyDrive/FYP/trained_output_video/trained_output_video_20241222_162017.mp4\n",
            "Detection metadata saved at: /content/drive/MyDrive/FYP/trained_json_data/detected_trained_metadata_20241222_162017.json\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from ultralytics import YOLO  # Ensure you have the correct YOLO library installed\n",
        "\n",
        "# Timestamp for unique filenames\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "# Load your trained YOLOv8 model\n",
        "model = YOLO('/content/drive/MyDrive/FYP/training_yolo8/trained_yolov8_model.pt')\n",
        "\n",
        "# Open the video file\n",
        "video_path = '/content/drive/MyDrive/FYP/input_videos/sl_1.mp4'  # Ensure the correct path format\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Couldn't open the video file.\")\n",
        "    exit()\n",
        "\n",
        "# Create output directories\n",
        "output_dir = '/content/drive/MyDrive/FYP/trained_output_video'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "frame_dir = f'/content/drive/MyDrive/FYP/trained_extracted_frames/trained_processed_frames_{timestamp}'\n",
        "os.makedirs(frame_dir, exist_ok=True)\n",
        "\n",
        "json_dir = '/content/drive/MyDrive/FYP/trained_json_data'\n",
        "os.makedirs(json_dir, exist_ok=True)\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Initialize video writer\n",
        "output_video_path = os.path.join(output_dir, f'trained_output_video_{timestamp}.mp4')\n",
        "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "# JSON file for metadata\n",
        "output_json_path = os.path.join(json_dir, f'detected_trained_metadata_{timestamp}.json')\n",
        "metadata = []\n",
        "\n",
        "# Frame processing loop\n",
        "frame_count = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Run object detection on the frame (no resizing for better accuracy)\n",
        "    results = model(frame)\n",
        "\n",
        "    # Get the annotated frame with bounding boxes and labels\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Collect detection metadata\n",
        "    detections = []\n",
        "    for box in results[0].boxes:\n",
        "        bbox = box.xyxy.tolist()[0]  # (x1, y1, x2, y2)\n",
        "        class_id = int(box.cls)\n",
        "        confidence = float(box.conf)\n",
        "        detections.append({\n",
        "            'class': model.names[class_id],\n",
        "            'confidence': confidence,\n",
        "            'box': bbox\n",
        "        })\n",
        "\n",
        "    metadata.append({\n",
        "        'frame': frame_count,\n",
        "        'detections': detections\n",
        "    })\n",
        "\n",
        "    # Write the annotated frame to the output video\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "    # Save each annotated frame as an image file\n",
        "    frame_output_path = os.path.join(frame_dir, f'frame_{frame_count:04d}.jpg')\n",
        "    cv2.imwrite(frame_output_path, annotated_frame)\n",
        "\n",
        "    # Increment frame count\n",
        "    frame_count += 1\n",
        "\n",
        "# Save detection metadata to JSON file\n",
        "with open(output_json_path, 'w') as json_file:\n",
        "    json.dump(metadata, json_file, indent=4)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Print results\n",
        "print(f\"Processed {frame_count} frames.\")\n",
        "print(f\"Annotated video saved at: {output_video_path}\")\n",
        "print(f\"Detection metadata saved at: {output_json_path}\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
