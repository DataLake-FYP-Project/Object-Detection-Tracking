{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlGt_cBTBHeB"
      },
      "source": [
        "# Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s40AVlHVBBlH",
        "outputId": "1e29d07c-1b9f-4b45-b212-0b0d17fc07c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byw_zeLjBQpu"
      },
      "source": [
        "***Pip installs***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pre-requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read README(CVAT).md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugg05OuoBU6H"
      },
      "source": [
        "# Create yaml file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzrCbFOmAZL7",
        "outputId": "0f2db1ec-8cf0-4160-d6a2-4d6bee75efb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YAML configuration file created successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a YAML configuration file\n",
        "config_content = \"\"\"\n",
        "path: /content/drive/MyDrive/FYP/CVAT_training  # Path to your working directory\n",
        "train: /content/drive/MyDrive/FYP/CVAT_training/images/train  # path to training images wrt given path\n",
        "val: /content/drive/MyDrive/FYP/CVAT_training/images/train # path to validation images wrt given path\n",
        "nc: 8  # Number of classes\n",
        "\n",
        "names:\n",
        "  0: car\n",
        "  1: van\n",
        "  2: bus\n",
        "  3: truck\n",
        "  4: person\n",
        "  5: motorbike\n",
        "  6: threewheel\n",
        "  7: train\n",
        "\"\"\"\n",
        "# Save the content to a file\n",
        "with open('/content/drive/MyDrive/FYP/CVAT_training/CVAT_dataset.yaml', 'w') as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "print(\"YAML configuration file created successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Check content of yaml for clarification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkJ92HqaFxlF",
        "outputId": "8308c7c9-0bda-49f8-d038-f137c23a82ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "path: /content/drive/MyDrive/FYP/CVAT_training  # Path to your dataset\n",
            "train: /content/drive/MyDrive/FYP/CVAT_training/images/train  # Training images\n",
            "val: /content/drive/MyDrive/FYP/CVAT_training/images/train # Validation images\n",
            "nc: 8  # Number of classes\n",
            "\n",
            "names:\n",
            "  0: car\n",
            "  1: van\n",
            "  2: bus\n",
            "  3: truck\n",
            "  4: person\n",
            "  5: motorbike\n",
            "  6: threewheel\n",
            "  7: train\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check YAML file content\n",
        "yaml_path = '/content/drive/MyDrive/FYP/CVAT_training/CVAT_dataset.yaml'\n",
        "\n",
        "# Display the content of the YAML file\n",
        "with open(yaml_path, 'r') as f:\n",
        "    print(f.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Check train and val path**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGEl2PuqF2pJ",
        "outputId": "7e2aad46-485a-489d-b2cc-1aac5d01de92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample training images: ['frame_0005.jpg', 'frame_0008.txt', 'frame_0007.txt', 'frame_0009.txt', 'frame_0006.txt']\n",
            "Sample validation images: ['frame_0005.jpg', 'frame_0008.txt', 'frame_0007.txt', 'frame_0009.txt', 'frame_0006.txt']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Paths\n",
        "train_path = '/content/drive/MyDrive/FYP/CVAT_training/images/train'\n",
        "val_path = '/content/drive/MyDrive/FYP/CVAT_training/images/train'\n",
        "\n",
        "# Verify paths\n",
        "assert os.path.exists(train_path), f\"Training path does not exist: {train_path}\"\n",
        "assert os.path.exists(val_path), f\"Validation path does not exist: {val_path}\"\n",
        "\n",
        "# List sample files\n",
        "print(\"Sample training images:\", os.listdir(train_path)[:5])\n",
        "print(\"Sample validation images:\", os.listdir(val_path)[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine Tune Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXwpCB3PD4Q_",
        "outputId": "9643c301-7725-426f-979e-d6222dfdf04c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.53 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/drive/MyDrive/FYP/CVAT_training/CVAT_dataset.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train16, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train16\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,012,408 parameters, 3,012,392 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train16', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/FYP/CVAT_training/labels/train.cache... 106 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/FYP/CVAT_training/labels/train.cache... 106 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train16/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train16\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20      2.25G      1.565      4.243      1.299         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  3.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342     0.0368      0.837      0.175       0.11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20       2.2G      1.188      3.657      1.063         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342     0.0271      0.939      0.382      0.236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20      2.19G      1.142      2.604      1.004         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.553      0.381        0.5      0.355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20      2.19G       1.07      1.806     0.9929         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342     0.0796      0.926      0.591      0.432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20       2.2G       1.01      1.413     0.9745         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.979      0.432      0.652      0.484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20       2.2G      1.007      1.267     0.9692         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.683      0.764      0.697       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20       2.2G      1.003      1.166     0.9773         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  3.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.998      0.156      0.669      0.551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20       2.2G     0.9778      1.055     0.9579         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.975      0.164       0.75      0.623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20       2.2G     0.9614     0.9984     0.9543         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.968      0.557      0.878      0.701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20       2.2G     0.9717     0.9501     0.9675         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.957      0.639      0.919       0.73\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20      2.17G     0.9364       1.16     0.9477         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.965      0.503      0.935      0.742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20      2.17G     0.9205      1.233     0.9412         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.959      0.797      0.947      0.748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20      2.17G     0.9134       1.09     0.9529         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.957      0.821       0.95      0.761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20      2.17G     0.8975      1.014     0.9461         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.955      0.858      0.952       0.76\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20      2.17G     0.8863      0.993     0.9466         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  3.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.954      0.905      0.952      0.749\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20      2.17G     0.9033      1.008     0.9561         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.953      0.925      0.953      0.751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20      2.17G     0.8602     0.9849     0.9309         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.954      0.945      0.952      0.749\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20      2.18G     0.8815       0.99     0.9266         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.954      0.956      0.952       0.76\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20      2.17G     0.8646     0.9571     0.9332         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.959      0.957      0.952      0.765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20      2.17G      0.857     0.9343     0.9249         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  3.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.964      0.955      0.952      0.774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 0.032 hours.\n",
            "Optimizer stripped from runs/detect/train16/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train16/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train16/weights/best.pt...\n",
            "Ultralytics 8.3.53 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,007,208 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        106        342      0.964      0.955      0.952      0.773\n",
            "                   van          6          6      0.882      0.833      0.835      0.735\n",
            "                 truck        100        100      0.984          1      0.988      0.851\n",
            "             motorbike        106        106      0.999          1      0.995      0.715\n",
            "            threewheel        100        130      0.992      0.988       0.99      0.794\n",
            "Speed: 0.2ms preprocess, 3.7ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train16\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary library\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "# Load YOLOv8 model (pre-trained)\n",
        "model = YOLO('yolov8n.pt')  # Ensure this path is correct\n",
        "\n",
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = '0'  # Use the first GPU\n",
        "else:\n",
        "    device = 'cpu'  # Fallback to CPU if no GPU is available\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    data='/content/drive/MyDrive/FYP/CVAT_training/CVAT_dataset.yaml',  # Path to your dataset.yaml\n",
        "    epochs=20,         # Number of training epochs\n",
        "    batch=16,          # Batch size\n",
        "    imgsz=640,         # Image size\n",
        "    device=device,     # Use GPU if available\n",
        "    workers=4          # Adjust based on your CPU for data loading (optional)\n",
        ")\n",
        "\n",
        "# Save the trained model if needed\n",
        "model.save('/content/drive/MyDrive/FYP/CVAT_training/CVAT_trained_yolov8_model.pt')  # Save the trained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsRfJotzqCJi",
        "outputId": "ae1fc99d-a2a7-4532-b69a-81a7e2fd3f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 384x640 1 truck, 45.8ms\n",
            "Speed: 4.4ms preprocess, 45.8ms inference, 641.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 1 threewheel, 6.7ms\n",
            "Speed: 5.3ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 6.7ms\n",
            "Speed: 3.5ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 truck, 6.0ms\n",
            "Speed: 2.1ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 8.9ms\n",
            "Speed: 2.6ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 threewheel, 6.7ms\n",
            "Speed: 1.6ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 7.1ms\n",
            "Speed: 2.5ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 13.3ms\n",
            "Speed: 5.4ms preprocess, 13.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 9.7ms\n",
            "Speed: 3.7ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 threewheel, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.5ms\n",
            "Speed: 3.0ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 2.4ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.6ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 7.4ms\n",
            "Speed: 2.0ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 6.2ms\n",
            "Speed: 2.7ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.6ms\n",
            "Speed: 3.6ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 11.6ms\n",
            "Speed: 1.7ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 6.2ms\n",
            "Speed: 2.8ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.4ms\n",
            "Speed: 2.2ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.3ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 2.0ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.3ms\n",
            "Speed: 2.2ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 7.8ms\n",
            "Speed: 3.0ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.5ms\n",
            "Speed: 2.1ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.1ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.9ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 6.7ms\n",
            "Speed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 6.2ms\n",
            "Speed: 2.8ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 6.6ms\n",
            "Speed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 6.4ms\n",
            "Speed: 2.8ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.3ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.6ms\n",
            "Speed: 2.1ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 8.0ms\n",
            "Speed: 3.4ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 10.4ms\n",
            "Speed: 2.6ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 13.4ms\n",
            "Speed: 3.5ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 threewheel, 8.6ms\n",
            "Speed: 3.1ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 9.1ms\n",
            "Speed: 6.1ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 motorbike, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 2.5ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 9.1ms\n",
            "Speed: 2.5ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 motorbike, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 motorbike, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 motorbike, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 motorbike, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 motorbike, 8.5ms\n",
            "Speed: 3.3ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 motorbike, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 threewheel, 9.3ms\n",
            "Speed: 4.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 threewheel, 9.3ms\n",
            "Speed: 4.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 6.6ms\n",
            "Speed: 2.3ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 motorbike, 1 threewheel, 6.6ms\n",
            "Speed: 2.6ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 threewheel, 6.7ms\n",
            "Speed: 2.2ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 threewheel, 6.6ms\n",
            "Speed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 vans, 1 threewheel, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 threewheel, 6.2ms\n",
            "Speed: 2.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 threewheel, 6.2ms\n",
            "Speed: 2.4ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 threewheels, 7.3ms\n",
            "Speed: 2.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 8.2ms\n",
            "Speed: 2.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 6.3ms\n",
            "Speed: 2.8ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 6.3ms\n",
            "Speed: 2.1ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 6.9ms\n",
            "Speed: 3.4ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 6.4ms\n",
            "Speed: 2.9ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 6.3ms\n",
            "Speed: 2.3ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 1 threewheel, 6.1ms\n",
            "Speed: 3.6ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 6.8ms\n",
            "Speed: 2.7ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 9.3ms\n",
            "Speed: 2.5ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 6.1ms\n",
            "Speed: 2.9ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 6.5ms\n",
            "Speed: 2.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 1 threewheel, 6.8ms\n",
            "Speed: 2.8ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 1 threewheel, 6.9ms\n",
            "Speed: 3.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 1 threewheel, 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 1 threewheel, 6.3ms\n",
            "Speed: 2.1ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 1 threewheel, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 1 threewheel, 6.3ms\n",
            "Speed: 2.1ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 2 threewheels, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 1 threewheel, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 2 threewheels, 18.7ms\n",
            "Speed: 3.7ms preprocess, 18.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 9.1ms\n",
            "Speed: 2.6ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 10.5ms\n",
            "Speed: 2.5ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 11.9ms\n",
            "Speed: 2.7ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 9.1ms\n",
            "Speed: 2.5ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 11.4ms\n",
            "Speed: 2.7ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 1 threewheel, 6.5ms\n",
            "Speed: 3.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 8.3ms\n",
            "Speed: 2.6ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 7.2ms\n",
            "Speed: 2.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.8ms\n",
            "Speed: 2.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.7ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 9.3ms\n",
            "Speed: 6.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 1 motorbike, 2 threewheels, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 8.3ms\n",
            "Speed: 4.0ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 16.1ms\n",
            "Speed: 3.4ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 threewheel, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 18.9ms\n",
            "Speed: 2.6ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 12.8ms\n",
            "Speed: 2.6ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 12.1ms\n",
            "Speed: 4.6ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 18.4ms\n",
            "Speed: 2.7ms preprocess, 18.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 11.6ms\n",
            "Speed: 2.7ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 8.8ms\n",
            "Speed: 3.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 10.4ms\n",
            "Speed: 2.6ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 threewheels, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 threewheels, 8.0ms\n",
            "Speed: 3.4ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 12.2ms\n",
            "Speed: 4.8ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 8.3ms\n",
            "Speed: 3.6ms preprocess, 8.3ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 12.4ms\n",
            "Speed: 4.3ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 9.4ms\n",
            "Speed: 4.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 17.6ms\n",
            "Speed: 2.9ms preprocess, 17.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 12.0ms\n",
            "Speed: 3.8ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 11.9ms\n",
            "Speed: 4.2ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 15.5ms\n",
            "Speed: 2.9ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 13.1ms\n",
            "Speed: 4.5ms preprocess, 13.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 12.1ms\n",
            "Speed: 2.5ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 21.2ms\n",
            "Speed: 2.7ms preprocess, 21.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 8.8ms\n",
            "Speed: 4.0ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 11.9ms\n",
            "Speed: 4.9ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 9.1ms\n",
            "Speed: 4.1ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 7.9ms\n",
            "Speed: 3.5ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 8.4ms\n",
            "Speed: 2.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 8.4ms\n",
            "Speed: 3.0ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 8.3ms\n",
            "Speed: 2.9ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 8.5ms\n",
            "Speed: 3.1ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 8.7ms\n",
            "Speed: 5.0ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 13.7ms\n",
            "Speed: 5.0ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 14.4ms\n",
            "Speed: 2.6ms preprocess, 14.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 11.3ms\n",
            "Speed: 2.7ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.4ms\n",
            "Speed: 2.5ms preprocess, 20.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 14.7ms\n",
            "Speed: 3.1ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 11.7ms\n",
            "Speed: 4.2ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 7.8ms\n",
            "Speed: 2.4ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 8.3ms\n",
            "Speed: 3.4ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 8.1ms\n",
            "Speed: 2.5ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 4.1ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 15.5ms\n",
            "Speed: 2.7ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 12.0ms\n",
            "Speed: 2.8ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 15.7ms\n",
            "Speed: 2.9ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 14.4ms\n",
            "Speed: 3.9ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 13.8ms\n",
            "Speed: 2.4ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 13.6ms\n",
            "Speed: 2.3ms preprocess, 13.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 13.9ms\n",
            "Speed: 3.9ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 13.3ms\n",
            "Speed: 2.5ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 15.5ms\n",
            "Speed: 2.7ms preprocess, 15.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 8.7ms\n",
            "Speed: 4.8ms preprocess, 8.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 20.6ms\n",
            "Speed: 2.4ms preprocess, 20.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 13.2ms\n",
            "Speed: 2.5ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 30.2ms\n",
            "Speed: 2.3ms preprocess, 30.2ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 19.8ms\n",
            "Speed: 4.0ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 15.1ms\n",
            "Speed: 6.1ms preprocess, 15.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 12.0ms\n",
            "Speed: 4.3ms preprocess, 12.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 12.4ms\n",
            "Speed: 2.9ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 15.9ms\n",
            "Speed: 2.3ms preprocess, 15.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 2 motorbikes, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 12.4ms\n",
            "Speed: 2.3ms preprocess, 12.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 14.7ms\n",
            "Speed: 2.3ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 12.0ms\n",
            "Speed: 3.7ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 2 motorbikes, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 1 threewheel, 6.3ms\n",
            "Speed: 2.2ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 7.7ms\n",
            "Speed: 2.3ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 2 motorbikes, 6.5ms\n",
            "Speed: 2.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 2 motorbikes, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 2 motorbikes, 6.5ms\n",
            "Speed: 2.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 2 motorbikes, 6.6ms\n",
            "Speed: 2.3ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 1 threewheel, 7.2ms\n",
            "Speed: 2.3ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 2 threewheels, 6.7ms\n",
            "Speed: 4.4ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 2 threewheels, 6.5ms\n",
            "Speed: 3.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 motorbike, 2 threewheels, 6.3ms\n",
            "Speed: 2.6ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 2 motorbikes, 1 threewheel, 6.7ms\n",
            "Speed: 2.7ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 2 motorbikes, 6.3ms\n",
            "Speed: 2.3ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 truck, 3 threewheels, 6.6ms\n",
            "Speed: 2.6ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 6.7ms\n",
            "Speed: 2.2ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 3 threewheels, 6.2ms\n",
            "Speed: 2.1ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 2 threewheels, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 1 threewheel, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 10.2ms\n",
            "Speed: 2.7ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 4 threewheels, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 1 motorbike, 3 threewheels, 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 1 motorbike, 2 threewheels, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 2 threewheels, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 1 threewheel, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 1 threewheel, 8.1ms\n",
            "Speed: 3.4ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 6.7ms\n",
            "Speed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 2 threewheels, 7.2ms\n",
            "Speed: 2.5ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 truck, 1 threewheel, 6.8ms\n",
            "Speed: 3.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 truck, 1 threewheel, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 1 truck, 6.6ms\n",
            "Speed: 2.4ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 2 threewheels, 6.4ms\n",
            "Speed: 2.2ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 3 threewheels, 6.3ms\n",
            "Speed: 2.3ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 3.5ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 van, 2 threewheels, 6.4ms\n",
            "Speed: 2.2ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.2ms\n",
            "Speed: 2.5ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 1 threewheel, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.6ms\n",
            "Speed: 2.2ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 7.8ms\n",
            "Speed: 2.3ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.4ms\n",
            "Speed: 2.3ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 threewheels, 6.3ms\n",
            "Speed: 2.2ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 threewheels, 7.0ms\n",
            "Speed: 2.3ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 threewheels, 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 6.7ms\n",
            "Speed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 threewheels, 6.8ms\n",
            "Speed: 2.7ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 threewheel, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 3 threewheels, 9.7ms\n",
            "Speed: 2.6ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 2 threewheels, 10.3ms\n",
            "Speed: 3.6ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorbikes, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 8.9ms\n",
            "Speed: 4.3ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 11.2ms\n",
            "Speed: 5.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 1 threewheel, 10.3ms\n",
            "Speed: 4.0ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 10.4ms\n",
            "Speed: 3.9ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorbike, 9.5ms\n",
            "Speed: 4.1ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 289 frames.\n",
            "Annotated video saved at: /content/drive/MyDrive/FYP/CVAT_training/CVAT_trained_output_video2/CVAT_trained_output_video2_20241223_140247.mp4\n",
            "Detection metadata saved at: /content/drive/MyDrive/FYP/CVAT_training/CVAT_trained_json_data2/CVAT_detected_trained_metadata2_20241223_140247.json\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from ultralytics import YOLO  # Ensure you have the correct YOLO library installed\n",
        "\n",
        "# Timestamp for unique filenames\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "# Load your trained YOLOv8 model\n",
        "model = YOLO('/content/drive/MyDrive/FYP/CVAT_training/CVAT_trained_yolov8_model.pt')\n",
        "\n",
        "# Open the video file\n",
        "video_path = '/content/drive/MyDrive/FYP/input_videos/sl_2.mp4'  # Ensure the correct path format\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Couldn't open the video file.\")\n",
        "    exit()\n",
        "\n",
        "# Create output directories\n",
        "output_dir = '/content/drive/MyDrive/FYP/CVAT_training/CVAT_trained_output_video2'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "frame_dir = f'/content/drive/MyDrive/FYP/CVAT_training/CVAT_trained_extracted_frames2/trained_processed_frames2_{timestamp}'\n",
        "os.makedirs(frame_dir, exist_ok=True)\n",
        "\n",
        "json_dir = '/content/drive/MyDrive/FYP/CVAT_training/CVAT_trained_json_data2'\n",
        "os.makedirs(json_dir, exist_ok=True)\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Initialize video writer\n",
        "output_video_path = os.path.join(output_dir, f'CVAT_trained_output_video2_{timestamp}.mp4')\n",
        "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "# JSON file for metadata\n",
        "output_json_path = os.path.join(json_dir, f'CVAT_detected_trained_metadata2_{timestamp}.json')\n",
        "metadata = []\n",
        "\n",
        "# Frame processing loop\n",
        "frame_count = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Run object detection on the frame (no resizing for better accuracy)\n",
        "    results = model(frame)\n",
        "\n",
        "    # Get the annotated frame with bounding boxes and labels\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Collect detection metadata\n",
        "    detections = []\n",
        "    for box in results[0].boxes:\n",
        "        bbox = box.xyxy.tolist()[0]  # (x1, y1, x2, y2)\n",
        "        class_id = int(box.cls)\n",
        "        confidence = float(box.conf)\n",
        "        detections.append({\n",
        "            'class': model.names[class_id],\n",
        "            'confidence': confidence,\n",
        "            'box': bbox\n",
        "        })\n",
        "\n",
        "    metadata.append({\n",
        "        'frame': frame_count,\n",
        "        'detections': detections\n",
        "    })\n",
        "\n",
        "    # Write the annotated frame to the output video\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "    # Save each annotated frame as an image file\n",
        "    frame_output_path = os.path.join(frame_dir, f'frame_{frame_count:04d}.jpg')\n",
        "    cv2.imwrite(frame_output_path, annotated_frame)\n",
        "\n",
        "    # Increment frame count\n",
        "    frame_count += 1\n",
        "\n",
        "# Save detection metadata to JSON file\n",
        "with open(output_json_path, 'w') as json_file:\n",
        "    json.dump(metadata, json_file, indent=4)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Print results\n",
        "print(f\"Processed {frame_count} frames.\")\n",
        "print(f\"Annotated video saved at: {output_video_path}\")\n",
        "print(f\"Detection metadata saved at: {output_json_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
