{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KheG-DAyeS4",
        "outputId": "f21ab29b-9587-467d-91de-a98cdf597286"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMOgvb0zyeS7",
        "outputId": "1725bd6c-0f3a-4882-b47c-f528e82241c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GZQIASiGyeS7"
      },
      "outputs": [],
      "source": [
        "! rm -rf video.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "aJwZEe4myeS7",
        "outputId": "08d72cd7-9829-49de-a8fc-ee52da9acfe1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15C3ZIbvy4CemGBOmIkrGK7H7a2tpYaBJ\n",
            "To: /content/people-counting.mp4\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.5M/42.5M [00:00<00:00, 43.1MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'people-counting.mp4'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "# Update with your file's specific ID\n",
        "file_id = \"15C3ZIbvy4CemGBOmIkrGK7H7a2tpYaBJ\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "output = \"people-counting.mp4\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB8rlAdEyeS8",
        "outputId": "aa12d6c5-3aea-4f0b-e425-245e86b2aaf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y6itgqQiyeS8"
      },
      "outputs": [],
      "source": [
        "SOURCE_VIDEO_PATH = os.path.join(HOME, \"people-counting.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPnUh0tTyeS8",
        "outputId": "7ccca4a0-a24b-459d-f9f7-63958e878d43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.40 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 43.9/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install \"ultralytics<=8.3.40\"\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC4UIOlZyeS9",
        "outputId": "2d1b54f6-bdb9-4949-ae1d-3f047a632a69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "supervision.__version__: 0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install supervision==0.3.0\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UP8L8DEgyeS9"
      },
      "outputs": [],
      "source": [
        "# settings\n",
        "MODEL = \"yolov8x.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PDmE_WJyeS-",
        "outputId": "a3b08c6e-79ba-479c-e5c9-1e092a0c03ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLOv8x summary (fused): 268 layers, 68,200,608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmW3EbL2yeS-",
        "outputId": "d1be6d58-9dc6-4013-9ffa-fab4a234e132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:00<00:00, 145MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class ID: 0, Class Name: person\n",
            "Class ID: 1, Class Name: bicycle\n",
            "Class ID: 2, Class Name: car\n",
            "Class ID: 3, Class Name: motorcycle\n",
            "Class ID: 4, Class Name: airplane\n",
            "Class ID: 5, Class Name: bus\n",
            "Class ID: 6, Class Name: train\n",
            "Class ID: 7, Class Name: truck\n",
            "Class ID: 8, Class Name: boat\n",
            "Class ID: 9, Class Name: traffic light\n",
            "Class ID: 10, Class Name: fire hydrant\n",
            "Class ID: 11, Class Name: stop sign\n",
            "Class ID: 12, Class Name: parking meter\n",
            "Class ID: 13, Class Name: bench\n",
            "Class ID: 14, Class Name: bird\n",
            "Class ID: 15, Class Name: cat\n",
            "Class ID: 16, Class Name: dog\n",
            "Class ID: 17, Class Name: horse\n",
            "Class ID: 18, Class Name: sheep\n",
            "Class ID: 19, Class Name: cow\n",
            "Class ID: 20, Class Name: elephant\n",
            "Class ID: 21, Class Name: bear\n",
            "Class ID: 22, Class Name: zebra\n",
            "Class ID: 23, Class Name: giraffe\n",
            "Class ID: 24, Class Name: backpack\n",
            "Class ID: 25, Class Name: umbrella\n",
            "Class ID: 26, Class Name: handbag\n",
            "Class ID: 27, Class Name: tie\n",
            "Class ID: 28, Class Name: suitcase\n",
            "Class ID: 29, Class Name: frisbee\n",
            "Class ID: 30, Class Name: skis\n",
            "Class ID: 31, Class Name: snowboard\n",
            "Class ID: 32, Class Name: sports ball\n",
            "Class ID: 33, Class Name: kite\n",
            "Class ID: 34, Class Name: baseball bat\n",
            "Class ID: 35, Class Name: baseball glove\n",
            "Class ID: 36, Class Name: skateboard\n",
            "Class ID: 37, Class Name: surfboard\n",
            "Class ID: 38, Class Name: tennis racket\n",
            "Class ID: 39, Class Name: bottle\n",
            "Class ID: 40, Class Name: wine glass\n",
            "Class ID: 41, Class Name: cup\n",
            "Class ID: 42, Class Name: fork\n",
            "Class ID: 43, Class Name: knife\n",
            "Class ID: 44, Class Name: spoon\n",
            "Class ID: 45, Class Name: bowl\n",
            "Class ID: 46, Class Name: banana\n",
            "Class ID: 47, Class Name: apple\n",
            "Class ID: 48, Class Name: sandwich\n",
            "Class ID: 49, Class Name: orange\n",
            "Class ID: 50, Class Name: broccoli\n",
            "Class ID: 51, Class Name: carrot\n",
            "Class ID: 52, Class Name: hot dog\n",
            "Class ID: 53, Class Name: pizza\n",
            "Class ID: 54, Class Name: donut\n",
            "Class ID: 55, Class Name: cake\n",
            "Class ID: 56, Class Name: chair\n",
            "Class ID: 57, Class Name: couch\n",
            "Class ID: 58, Class Name: potted plant\n",
            "Class ID: 59, Class Name: bed\n",
            "Class ID: 60, Class Name: dining table\n",
            "Class ID: 61, Class Name: toilet\n",
            "Class ID: 62, Class Name: tv\n",
            "Class ID: 63, Class Name: laptop\n",
            "Class ID: 64, Class Name: mouse\n",
            "Class ID: 65, Class Name: remote\n",
            "Class ID: 66, Class Name: keyboard\n",
            "Class ID: 67, Class Name: cell phone\n",
            "Class ID: 68, Class Name: microwave\n",
            "Class ID: 69, Class Name: oven\n",
            "Class ID: 70, Class Name: toaster\n",
            "Class ID: 71, Class Name: sink\n",
            "Class ID: 72, Class Name: refrigerator\n",
            "Class ID: 73, Class Name: book\n",
            "Class ID: 74, Class Name: clock\n",
            "Class ID: 75, Class Name: vase\n",
            "Class ID: 76, Class Name: scissors\n",
            "Class ID: 77, Class Name: teddy bear\n",
            "Class ID: 78, Class Name: hair drier\n",
            "Class ID: 79, Class Name: toothbrush\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLO model\n",
        "model = YOLO('yolov8s.pt')\n",
        "\n",
        "# Get class names from the model\n",
        "class_names = model.names  # Dictionary {class_id: class_name}\n",
        "\n",
        "# Print all class IDs and names\n",
        "for class_id, class_name in class_names.items():\n",
        "    print(f\"Class ID: {class_id}, Class Name: {class_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vojQ-6o4fE_D"
      },
      "source": [
        "##### Install face detection pre trained models for age gender "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMMAAELCY1sY",
        "outputId": "6e64db7b-3da6-4910-cbd9-ba332a4e896d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: deepface==0.0.79 in /usr/local/lib/python3.11/dist-packages (0.0.79)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.79) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.79) (4.67.1)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.79) (5.2.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.79) (11.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.79) (4.11.0.86)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.79) (3.1.0)\n",
            "Requirement already satisfied: mtcnn>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.79) (1.0.0)\n",
            "Requirement already satisfied: retina-face>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.79) (0.0.17)\n",
            "Requirement already satisfied: fire>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.79) (0.7.0)\n",
            "Requirement already satisfied: gunicorn>=20.1.0 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.79) (23.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface==0.0.79) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface==0.0.79) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface==0.0.79) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface==0.0.79) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface==0.0.79) (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface==0.0.79) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface==0.0.79) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface==0.0.79) (2.32.3)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface==0.0.79) (1.4.2)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface==0.0.79) (4.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface==0.0.79) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface==0.0.79) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface==0.0.79) (2025.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface==0.0.79) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.79) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.79) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.79) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.79) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface==0.0.79) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.79) (1.7.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.12.0 deepface==0.0.79"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwqaxgwWth_d"
      },
      "source": [
        "##### Install ffmpeg-python to get video metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdCGaIfh2TT4",
        "outputId": "f8c02fc1-4933-43c3-8292-6b3ec2ce8896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhpGbAEiQ8gK"
      },
      "source": [
        "##### Face detection model and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxP14e6xRKcC",
        "outputId": "41ba6980-19ac-4ea9-f657-1c98cde9ed3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Face-Mask-Detection' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chandrikadeb7/Face-Mask-Detection.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coQMaUsERMx3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_path = \"Face-Mask-Detection/mask_detector.model\"\n",
        "mask_model = load_model(model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COXqqVRQb5Xf"
      },
      "source": [
        "### Tracking only when entering and exiting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bPDpw2FvqKX",
        "outputId": "5d5c38a1-9b7d-4459-9e98-b5ce722756eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "video 1/1 (frame 1/592) /content/people-counting.mp4: 384x640 1 potted plant, 5198.6ms\n",
            "video 1/1 (frame 2/592) /content/people-counting.mp4: 384x640 1 car, 1 potted plant, 4178.9ms\n",
            "video 1/1 (frame 3/592) /content/people-counting.mp4: 384x640 1 car, 1 potted plant, 4028.9ms\n",
            "video 1/1 (frame 4/592) /content/people-counting.mp4: 384x640 1 car, 1 potted plant, 5365.4ms\n",
            "video 1/1 (frame 5/592) /content/people-counting.mp4: 384x640 1 car, 1 potted plant, 3970.3ms\n",
            "video 1/1 (frame 6/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 potted plant, 4011.5ms\n",
            "video 1/1 (frame 7/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 potted plant, 5307.7ms\n",
            "video 1/1 (frame 8/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 potted plant, 4056.9ms\n",
            "video 1/1 (frame 9/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 potted plant, 3513.2ms\n",
            "video 1/1 (frame 10/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2932.0ms\n",
            "video 1/1 (frame 11/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2734.5ms\n",
            "video 1/1 (frame 12/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2392.7ms\n",
            "video 1/1 (frame 13/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2383.8ms\n",
            "video 1/1 (frame 14/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2365.7ms\n",
            "video 1/1 (frame 15/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 3341.6ms\n",
            "video 1/1 (frame 16/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2364.9ms\n",
            "video 1/1 (frame 17/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2377.3ms\n",
            "video 1/1 (frame 18/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2344.7ms\n",
            "video 1/1 (frame 19/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2393.2ms\n",
            "video 1/1 (frame 20/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 3282.9ms\n",
            "video 1/1 (frame 21/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2385.2ms\n",
            "video 1/1 (frame 22/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2721.3ms\n",
            "video 1/1 (frame 23/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2683.0ms\n",
            "video 1/1 (frame 24/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 3362.9ms\n",
            "video 1/1 (frame 25/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 3415.1ms\n",
            "video 1/1 (frame 26/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2363.8ms\n",
            "video 1/1 (frame 27/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2353.4ms\n",
            "video 1/1 (frame 28/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2359.3ms\n",
            "video 1/1 (frame 29/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 3333.9ms\n",
            "video 1/1 (frame 30/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2353.5ms\n",
            "video 1/1 (frame 31/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2368.1ms\n",
            "video 1/1 (frame 32/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2373.6ms\n",
            "video 1/1 (frame 33/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2363.4ms\n",
            "video 1/1 (frame 34/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 3318.9ms\n",
            "video 1/1 (frame 35/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2362.9ms\n",
            "video 1/1 (frame 36/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 2 potted plants, 2365.1ms\n",
            "video 1/1 (frame 37/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 2 potted plants, 2345.4ms\n",
            "video 1/1 (frame 38/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 2 potted plants, 2727.5ms\n",
            "video 1/1 (frame 39/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 bench, 1 potted plant, 2896.6ms\n",
            "video 1/1 (frame 40/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 bench, 1 potted plant, 2361.5ms\n",
            "video 1/1 (frame 41/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 bench, 1 potted plant, 2345.6ms\n",
            "video 1/1 (frame 42/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 bench, 1 potted plant, 2370.0ms\n",
            "video 1/1 (frame 43/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 bench, 1 potted plant, 3171.6ms\n",
            "video 1/1 (frame 44/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 1 potted plant, 2493.5ms\n",
            "video 1/1 (frame 45/592) /content/people-counting.mp4: 384x640 3 persons, 2 cars, 1 bench, 2389.2ms\n",
            "video 1/1 (frame 46/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 2347.6ms\n",
            "video 1/1 (frame 47/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 2370.3ms\n",
            "video 1/1 (frame 48/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 3828.1ms\n",
            "video 1/1 (frame 49/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 2359.1ms\n",
            "video 1/1 (frame 50/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 2350.4ms\n",
            "video 1/1 (frame 51/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 2343.0ms\n",
            "video 1/1 (frame 52/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 2775.6ms\n",
            "video 1/1 (frame 53/592) /content/people-counting.mp4: 384x640 4 persons, 1 bench, 2867.0ms\n",
            "video 1/1 (frame 54/592) /content/people-counting.mp4: 384x640 4 persons, 1 bench, 2383.7ms\n",
            "video 1/1 (frame 55/592) /content/people-counting.mp4: 384x640 4 persons, 1 bench, 2333.3ms\n",
            "video 1/1 (frame 56/592) /content/people-counting.mp4: 384x640 4 persons, 1 bench, 1 potted plant, 2395.4ms\n",
            "video 1/1 (frame 57/592) /content/people-counting.mp4: 384x640 4 persons, 1 bench, 1 potted plant, 3153.4ms\n",
            "video 1/1 (frame 58/592) /content/people-counting.mp4: 384x640 4 persons, 1 car, 1 bench, 1 potted plant, 2474.0ms\n",
            "video 1/1 (frame 59/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 potted plant, 2347.3ms\n",
            "video 1/1 (frame 60/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 potted plant, 2385.8ms\n",
            "video 1/1 (frame 61/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 potted plant, 2342.1ms\n",
            "video 1/1 (frame 62/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 potted plant, 3330.5ms\n",
            "video 1/1 (frame 63/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 potted plant, 2373.1ms\n",
            "video 1/1 (frame 64/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 1 potted plant, 2400.4ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Action: gender: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 60ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "video 1/1 (frame 65/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 1 potted plant, 2331.2ms\n",
            "video 1/1 (frame 66/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 1 potted plant, 3317.0ms\n",
            "video 1/1 (frame 67/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 1 potted plant, 2392.3ms\n",
            "video 1/1 (frame 68/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 1 potted plant, 2345.5ms\n",
            "video 1/1 (frame 69/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 1 potted plant, 2363.6ms\n",
            "video 1/1 (frame 70/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 1 potted plant, 2554.4ms\n",
            "video 1/1 (frame 71/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 bench, 1 potted plant, 3046.7ms\n",
            "video 1/1 (frame 72/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 potted plant, 2373.5ms\n",
            "video 1/1 (frame 73/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 potted plant, 2346.3ms\n",
            "video 1/1 (frame 74/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 potted plant, 2347.7ms\n",
            "video 1/1 (frame 75/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 2 potted plants, 3003.2ms\n",
            "video 1/1 (frame 76/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 2 potted plants, 2619.2ms\n",
            "video 1/1 (frame 77/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 potted plant, 2361.4ms\n",
            "video 1/1 (frame 78/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 potted plant, 2381.1ms\n",
            "video 1/1 (frame 79/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 potted plant, 2357.2ms\n",
            "video 1/1 (frame 80/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 potted plant, 3367.3ms\n",
            "video 1/1 (frame 81/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 potted plant, 2357.1ms\n",
            "video 1/1 (frame 82/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2346.5ms\n",
            "video 1/1 (frame 83/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2348.6ms\n",
            "video 1/1 (frame 84/592) /content/people-counting.mp4: 384x640 2 persons, 2344.3ms\n",
            "video 1/1 (frame 85/592) /content/people-counting.mp4: 384x640 2 persons, 3338.0ms\n",
            "video 1/1 (frame 86/592) /content/people-counting.mp4: 384x640 2 persons, 2348.5ms\n",
            "video 1/1 (frame 87/592) /content/people-counting.mp4: 384x640 2 persons, 2680.5ms\n",
            "video 1/1 (frame 88/592) /content/people-counting.mp4: 384x640 2 persons, 2401.2ms\n",
            "video 1/1 (frame 89/592) /content/people-counting.mp4: 384x640 2 persons, 2909.6ms\n",
            "video 1/1 (frame 90/592) /content/people-counting.mp4: 384x640 2 persons, 2688.9ms\n",
            "video 1/1 (frame 91/592) /content/people-counting.mp4: 384x640 2 persons, 2354.8ms\n",
            "video 1/1 (frame 92/592) /content/people-counting.mp4: 384x640 2 persons, 2362.1ms\n",
            "video 1/1 (frame 93/592) /content/people-counting.mp4: 384x640 2 persons, 2359.6ms\n",
            "video 1/1 (frame 94/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3285.2ms\n",
            "video 1/1 (frame 95/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2358.3ms\n",
            "video 1/1 (frame 96/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2361.0ms\n",
            "video 1/1 (frame 97/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2343.6ms\n",
            "video 1/1 (frame 98/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2353.8ms\n",
            "video 1/1 (frame 99/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3326.4ms\n",
            "video 1/1 (frame 100/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2360.5ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Action: gender: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 58ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "video 1/1 (frame 101/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2343.2ms\n",
            "video 1/1 (frame 102/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2336.9ms\n",
            "video 1/1 (frame 103/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3348.2ms\n",
            "video 1/1 (frame 104/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2354.2ms\n",
            "video 1/1 (frame 105/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2342.8ms\n",
            "video 1/1 (frame 106/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2352.4ms\n",
            "video 1/1 (frame 107/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2510.2ms\n",
            "video 1/1 (frame 108/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3101.6ms\n",
            "video 1/1 (frame 109/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2346.6ms\n",
            "video 1/1 (frame 110/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2342.7ms\n",
            "video 1/1 (frame 111/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2387.8ms\n",
            "video 1/1 (frame 112/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3015.4ms\n",
            "video 1/1 (frame 113/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2621.2ms\n",
            "video 1/1 (frame 114/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2356.1ms\n",
            "video 1/1 (frame 115/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2343.8ms\n",
            "video 1/1 (frame 116/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2357.8ms\n",
            "video 1/1 (frame 117/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3354.3ms\n",
            "video 1/1 (frame 118/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2340.3ms\n",
            "video 1/1 (frame 119/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2345.0ms\n",
            "video 1/1 (frame 120/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2372.1ms\n",
            "video 1/1 (frame 121/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2343.6ms\n",
            "video 1/1 (frame 122/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3309.0ms\n",
            "video 1/1 (frame 123/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2379.1ms\n",
            "video 1/1 (frame 124/592) /content/people-counting.mp4: 384x640 1 person, 1 parking meter, 1 potted plant, 2332.7ms\n",
            "video 1/1 (frame 125/592) /content/people-counting.mp4: 384x640 1 person, 1 parking meter, 1 potted plant, 2346.2ms\n",
            "video 1/1 (frame 126/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2683.0ms\n",
            "video 1/1 (frame 127/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2978.7ms\n",
            "video 1/1 (frame 128/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2360.7ms\n",
            "video 1/1 (frame 129/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2359.0ms\n",
            "video 1/1 (frame 130/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3131.9ms\n",
            "video 1/1 (frame 131/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3532.4ms\n",
            "video 1/1 (frame 132/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2355.4ms\n",
            "video 1/1 (frame 133/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2351.8ms\n",
            "video 1/1 (frame 134/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2371.6ms\n",
            "video 1/1 (frame 135/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2570.5ms\n",
            "video 1/1 (frame 136/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3014.8ms\n",
            "video 1/1 (frame 137/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2343.5ms\n",
            "video 1/1 (frame 138/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2357.9ms\n",
            "video 1/1 (frame 139/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2364.9ms\n",
            "video 1/1 (frame 140/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2954.5ms\n",
            "video 1/1 (frame 141/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2654.9ms\n",
            "video 1/1 (frame 142/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2352.4ms\n",
            "video 1/1 (frame 143/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2372.1ms\n",
            "video 1/1 (frame 144/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2354.0ms\n",
            "video 1/1 (frame 145/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3356.8ms\n",
            "video 1/1 (frame 146/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2359.2ms\n",
            "video 1/1 (frame 147/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2333.7ms\n",
            "video 1/1 (frame 148/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2347.2ms\n",
            "video 1/1 (frame 149/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2341.7ms\n",
            "video 1/1 (frame 150/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3301.6ms\n",
            "video 1/1 (frame 151/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2333.0ms\n",
            "video 1/1 (frame 152/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2361.5ms\n",
            "video 1/1 (frame 153/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2330.6ms\n",
            "video 1/1 (frame 154/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2645.6ms\n",
            "video 1/1 (frame 155/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2944.9ms\n",
            "video 1/1 (frame 156/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2366.2ms\n",
            "video 1/1 (frame 157/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2345.7ms\n",
            "video 1/1 (frame 158/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2348.0ms\n",
            "video 1/1 (frame 159/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3052.3ms\n",
            "video 1/1 (frame 160/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2536.1ms\n",
            "video 1/1 (frame 161/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2343.5ms\n",
            "video 1/1 (frame 162/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2350.1ms\n",
            "video 1/1 (frame 163/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2325.5ms\n",
            "video 1/1 (frame 164/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3346.2ms\n",
            "video 1/1 (frame 165/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2353.8ms\n",
            "video 1/1 (frame 166/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2354.5ms\n",
            "video 1/1 (frame 167/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2334.7ms\n",
            "video 1/1 (frame 168/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2398.9ms\n",
            "video 1/1 (frame 169/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3257.0ms\n",
            "video 1/1 (frame 170/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2343.4ms\n",
            "video 1/1 (frame 171/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2341.3ms\n",
            "video 1/1 (frame 172/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2383.2ms\n",
            "video 1/1 (frame 173/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2744.9ms\n",
            "video 1/1 (frame 174/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2872.8ms\n",
            "video 1/1 (frame 175/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2360.7ms\n",
            "video 1/1 (frame 176/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2355.7ms\n",
            "video 1/1 (frame 177/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2348.8ms\n",
            "video 1/1 (frame 178/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3325.9ms\n",
            "video 1/1 (frame 179/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2401.7ms\n",
            "video 1/1 (frame 180/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2330.9ms\n",
            "video 1/1 (frame 181/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2341.0ms\n",
            "video 1/1 (frame 182/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2341.2ms\n",
            "video 1/1 (frame 183/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3302.0ms\n",
            "video 1/1 (frame 184/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2341.6ms\n",
            "video 1/1 (frame 185/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2351.8ms\n",
            "video 1/1 (frame 186/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2327.0ms\n",
            "video 1/1 (frame 187/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2434.5ms\n",
            "video 1/1 (frame 188/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3184.7ms\n",
            "video 1/1 (frame 189/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2340.0ms\n",
            "video 1/1 (frame 190/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2346.2ms\n",
            "video 1/1 (frame 191/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2351.3ms\n",
            "video 1/1 (frame 192/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2841.3ms\n",
            "video 1/1 (frame 193/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2769.3ms\n",
            "video 1/1 (frame 194/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2353.3ms\n",
            "video 1/1 (frame 195/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2353.0ms\n",
            "video 1/1 (frame 196/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2381.8ms\n",
            "video 1/1 (frame 197/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3321.5ms\n",
            "video 1/1 (frame 198/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2337.2ms\n",
            "video 1/1 (frame 199/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2371.4ms\n",
            "video 1/1 (frame 200/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2360.5ms\n",
            "video 1/1 (frame 201/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2344.0ms\n",
            "video 1/1 (frame 202/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3335.5ms\n",
            "video 1/1 (frame 203/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2338.9ms\n",
            "video 1/1 (frame 204/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2336.4ms\n",
            "video 1/1 (frame 205/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2346.8ms\n",
            "video 1/1 (frame 206/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2535.0ms\n",
            "video 1/1 (frame 207/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3053.7ms\n",
            "video 1/1 (frame 208/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2341.3ms\n",
            "video 1/1 (frame 209/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2330.2ms\n",
            "video 1/1 (frame 210/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2349.9ms\n",
            "video 1/1 (frame 211/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2894.3ms\n",
            "video 1/1 (frame 212/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2695.0ms\n",
            "video 1/1 (frame 213/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2357.2ms\n",
            "video 1/1 (frame 214/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2337.2ms\n",
            "video 1/1 (frame 215/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2334.4ms\n",
            "video 1/1 (frame 216/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3278.5ms\n",
            "video 1/1 (frame 217/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2347.7ms\n",
            "video 1/1 (frame 218/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2330.1ms\n",
            "video 1/1 (frame 219/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2328.4ms\n",
            "video 1/1 (frame 220/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2357.2ms\n",
            "video 1/1 (frame 221/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3317.2ms\n",
            "video 1/1 (frame 222/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2333.3ms\n",
            "video 1/1 (frame 223/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2331.1ms\n",
            "video 1/1 (frame 224/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2341.7ms\n",
            "video 1/1 (frame 225/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2551.6ms\n",
            "video 1/1 (frame 226/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3087.0ms\n",
            "video 1/1 (frame 227/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2374.1ms\n",
            "video 1/1 (frame 228/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2349.7ms\n",
            "video 1/1 (frame 229/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2331.0ms\n",
            "video 1/1 (frame 230/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2878.8ms\n",
            "video 1/1 (frame 231/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2700.9ms\n",
            "video 1/1 (frame 232/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2337.9ms\n",
            "video 1/1 (frame 233/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2343.6ms\n",
            "video 1/1 (frame 234/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2336.8ms\n",
            "video 1/1 (frame 235/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3306.6ms\n",
            "video 1/1 (frame 236/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2365.5ms\n",
            "video 1/1 (frame 237/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2337.4ms\n",
            "video 1/1 (frame 238/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2330.5ms\n",
            "video 1/1 (frame 239/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2371.7ms\n",
            "video 1/1 (frame 240/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 4200.2ms\n",
            "video 1/1 (frame 241/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2442.6ms\n",
            "video 1/1 (frame 242/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2343.9ms\n",
            "video 1/1 (frame 243/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2348.2ms\n",
            "video 1/1 (frame 244/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2355.8ms\n",
            "video 1/1 (frame 245/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3341.2ms\n",
            "video 1/1 (frame 246/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2345.1ms\n",
            "video 1/1 (frame 247/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2390.4ms\n",
            "video 1/1 (frame 248/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2336.8ms\n",
            "video 1/1 (frame 249/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2444.4ms\n",
            "video 1/1 (frame 250/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3151.6ms\n",
            "video 1/1 (frame 251/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2366.2ms\n",
            "video 1/1 (frame 252/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2347.5ms\n",
            "video 1/1 (frame 253/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2341.8ms\n",
            "video 1/1 (frame 254/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2850.2ms\n",
            "video 1/1 (frame 255/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2773.8ms\n",
            "video 1/1 (frame 256/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2340.2ms\n",
            "video 1/1 (frame 257/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2400.5ms\n",
            "video 1/1 (frame 258/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2350.7ms\n",
            "video 1/1 (frame 259/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3351.1ms\n",
            "video 1/1 (frame 260/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2361.2ms\n",
            "video 1/1 (frame 261/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2355.7ms\n",
            "video 1/1 (frame 262/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2338.4ms\n",
            "video 1/1 (frame 263/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2351.1ms\n",
            "video 1/1 (frame 264/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3301.3ms\n",
            "video 1/1 (frame 265/592) /content/people-counting.mp4: 384x640 3 persons, 1 potted plant, 2343.6ms\n",
            "video 1/1 (frame 266/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 potted plant, 2345.7ms\n",
            "video 1/1 (frame 267/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 2355.2ms\n",
            "video 1/1 (frame 268/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 2672.1ms\n",
            "video 1/1 (frame 269/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 potted plant, 2996.8ms\n",
            "video 1/1 (frame 270/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 potted plant, 2378.2ms\n",
            "video 1/1 (frame 271/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 potted plant, 2326.3ms\n",
            "video 1/1 (frame 272/592) /content/people-counting.mp4: 384x640 3 persons, 1 potted plant, 2342.3ms\n",
            "video 1/1 (frame 273/592) /content/people-counting.mp4: 384x640 3 persons, 1 potted plant, 1 clock, 3015.6ms\n",
            "video 1/1 (frame 274/592) /content/people-counting.mp4: 384x640 3 persons, 1 potted plant, 1 clock, 2566.6ms\n",
            "video 1/1 (frame 275/592) /content/people-counting.mp4: 384x640 3 persons, 1 potted plant, 1 clock, 2336.2ms\n",
            "video 1/1 (frame 276/592) /content/people-counting.mp4: 384x640 3 persons, 1 potted plant, 1 clock, 2358.3ms\n",
            "video 1/1 (frame 277/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 potted plant, 1 clock, 2348.1ms\n",
            "video 1/1 (frame 278/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 potted plant, 1 clock, 3371.7ms\n",
            "video 1/1 (frame 279/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 potted plant, 1 clock, 2342.8ms\n",
            "video 1/1 (frame 280/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 1 clock, 2346.5ms\n",
            "video 1/1 (frame 281/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 2365.8ms\n",
            "video 1/1 (frame 282/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 1 clock, 2369.2ms\n",
            "video 1/1 (frame 283/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 1 clock, 3305.5ms\n",
            "video 1/1 (frame 284/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 1 clock, 2358.1ms\n",
            "video 1/1 (frame 285/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 1 clock, 2376.0ms\n",
            "video 1/1 (frame 286/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 potted plant, 1 clock, 2334.2ms\n",
            "video 1/1 (frame 287/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 potted plant, 2683.1ms\n",
            "video 1/1 (frame 288/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 2924.1ms\n",
            "video 1/1 (frame 289/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 2351.4ms\n",
            "video 1/1 (frame 290/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 2353.2ms\n",
            "video 1/1 (frame 291/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2337.6ms\n",
            "video 1/1 (frame 292/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3047.3ms\n",
            "video 1/1 (frame 293/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2590.4ms\n",
            "video 1/1 (frame 294/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2345.0ms\n",
            "video 1/1 (frame 295/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2356.6ms\n",
            "video 1/1 (frame 296/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2358.6ms\n",
            "video 1/1 (frame 297/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3338.8ms\n",
            "video 1/1 (frame 298/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2370.5ms\n",
            "video 1/1 (frame 299/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2364.8ms\n",
            "video 1/1 (frame 300/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2341.7ms\n",
            "video 1/1 (frame 301/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 2374.9ms\n",
            "video 1/1 (frame 302/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 potted plant, 3281.3ms\n",
            "video 1/1 (frame 303/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 potted plant, 2338.1ms\n",
            "video 1/1 (frame 304/592) /content/people-counting.mp4: 384x640 3 persons, 1 car, 1 potted plant, 2390.4ms\n",
            "video 1/1 (frame 305/592) /content/people-counting.mp4: 384x640 3 persons, 2 cars, 1 potted plant, 2352.6ms\n",
            "video 1/1 (frame 306/592) /content/people-counting.mp4: 384x640 3 persons, 2 cars, 1 potted plant, 2747.7ms\n",
            "video 1/1 (frame 307/592) /content/people-counting.mp4: 384x640 3 persons, 2 cars, 1 potted plant, 2857.9ms\n",
            "video 1/1 (frame 308/592) /content/people-counting.mp4: 384x640 3 persons, 2 cars, 1 potted plant, 2360.3ms\n",
            "video 1/1 (frame 309/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 potted plant, 2377.6ms\n",
            "video 1/1 (frame 310/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2349.0ms\n",
            "video 1/1 (frame 311/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 3169.7ms\n",
            "video 1/1 (frame 312/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2481.8ms\n",
            "video 1/1 (frame 313/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2362.9ms\n",
            "video 1/1 (frame 314/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2352.5ms\n",
            "video 1/1 (frame 315/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2361.0ms\n",
            "video 1/1 (frame 316/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 3357.6ms\n",
            "video 1/1 (frame 317/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2368.9ms\n",
            "video 1/1 (frame 318/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2370.4ms\n",
            "video 1/1 (frame 319/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 handbag, 1 potted plant, 2350.4ms\n",
            "video 1/1 (frame 320/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 handbag, 1 potted plant, 2518.7ms\n",
            "video 1/1 (frame 321/592) /content/people-counting.mp4: 384x640 1 person, 1 car, 1 handbag, 1 potted plant, 3102.3ms\n",
            "video 1/1 (frame 322/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2351.6ms\n",
            "video 1/1 (frame 323/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2357.1ms\n",
            "video 1/1 (frame 324/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2354.6ms\n",
            "video 1/1 (frame 325/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2895.4ms\n",
            "video 1/1 (frame 326/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2731.6ms\n",
            "video 1/1 (frame 327/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2382.2ms\n",
            "video 1/1 (frame 328/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2349.3ms\n",
            "video 1/1 (frame 329/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2363.0ms\n",
            "video 1/1 (frame 330/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 3345.6ms\n",
            "video 1/1 (frame 331/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 2335.2ms\n",
            "video 1/1 (frame 332/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 2350.7ms\n",
            "video 1/1 (frame 333/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 2337.5ms\n",
            "video 1/1 (frame 334/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 2366.2ms\n",
            "video 1/1 (frame 335/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 3304.7ms\n",
            "video 1/1 (frame 336/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 2334.4ms\n",
            "video 1/1 (frame 337/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 2341.0ms\n",
            "video 1/1 (frame 338/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 2375.3ms\n",
            "video 1/1 (frame 339/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 2579.2ms\n",
            "video 1/1 (frame 340/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 3010.6ms\n",
            "video 1/1 (frame 341/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 2344.3ms\n",
            "video 1/1 (frame 342/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 2352.5ms\n",
            "video 1/1 (frame 343/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 1 potted plant, 2360.9ms\n",
            "video 1/1 (frame 344/592) /content/people-counting.mp4: 384x640 2 persons, 2 cars, 1 handbag, 2933.6ms\n",
            "video 1/1 (frame 345/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2655.1ms\n",
            "video 1/1 (frame 346/592) /content/people-counting.mp4: 384x640 2 persons, 1 car, 1 handbag, 1 potted plant, 2395.8ms\n",
            "video 1/1 (frame 347/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 2357.3ms\n",
            "video 1/1 (frame 348/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 2341.0ms\n",
            "video 1/1 (frame 349/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 3393.4ms\n",
            "video 1/1 (frame 350/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 2504.5ms\n",
            "video 1/1 (frame 351/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 3127.4ms\n",
            "video 1/1 (frame 352/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 2340.0ms\n",
            "video 1/1 (frame 353/592) /content/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 2876.5ms\n",
            "video 1/1 (frame 354/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 2726.8ms\n",
            "video 1/1 (frame 355/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 2370.1ms\n",
            "video 1/1 (frame 356/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 1 clock, 2328.5ms\n",
            "video 1/1 (frame 357/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 1 clock, 2360.1ms\n",
            "video 1/1 (frame 358/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 1 clock, 3411.8ms\n",
            "video 1/1 (frame 359/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 1 clock, 2338.9ms\n",
            "video 1/1 (frame 360/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 1 clock, 2379.7ms\n",
            "video 1/1 (frame 361/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 2341.6ms\n",
            "video 1/1 (frame 362/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 2350.3ms\n",
            "video 1/1 (frame 363/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 3347.1ms\n",
            "video 1/1 (frame 364/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 2341.0ms\n",
            "video 1/1 (frame 365/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 2353.5ms\n",
            "video 1/1 (frame 366/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 2351.6ms\n",
            "video 1/1 (frame 367/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 2618.6ms\n",
            "video 1/1 (frame 368/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 3035.8ms\n",
            "video 1/1 (frame 369/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 2381.7ms\n",
            "video 1/1 (frame 370/592) /content/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 1 potted plant, 2342.4ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Action: gender: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 53ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "video 1/1 (frame 371/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 1 clock, 2637.3ms\n",
            "video 1/1 (frame 372/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 1 clock, 3027.7ms\n",
            "video 1/1 (frame 373/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 1 clock, 2363.4ms\n",
            "video 1/1 (frame 374/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 1 clock, 2345.5ms\n",
            "video 1/1 (frame 375/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 2406.5ms\n",
            "video 1/1 (frame 376/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 3051.9ms\n",
            "video 1/1 (frame 377/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 2585.9ms\n",
            "video 1/1 (frame 378/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 2356.6ms\n",
            "video 1/1 (frame 379/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 2353.6ms\n",
            "video 1/1 (frame 380/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 2355.5ms\n",
            "video 1/1 (frame 381/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 3343.5ms\n",
            "video 1/1 (frame 382/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 2365.5ms\n",
            "video 1/1 (frame 383/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 2331.7ms\n",
            "video 1/1 (frame 384/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 2386.9ms\n",
            "video 1/1 (frame 385/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 2381.7ms\n",
            "video 1/1 (frame 386/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 3223.6ms\n",
            "video 1/1 (frame 387/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2354.0ms\n",
            "video 1/1 (frame 388/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2336.9ms\n",
            "video 1/1 (frame 389/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2329.5ms\n",
            "video 1/1 (frame 390/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2775.5ms\n",
            "video 1/1 (frame 391/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2829.8ms\n",
            "video 1/1 (frame 392/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2361.7ms\n",
            "video 1/1 (frame 393/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2350.3ms\n",
            "video 1/1 (frame 394/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2394.6ms\n",
            "video 1/1 (frame 395/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 3236.4ms\n",
            "video 1/1 (frame 396/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 1 potted plant, 2436.0ms\n",
            "video 1/1 (frame 397/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2352.6ms\n",
            "video 1/1 (frame 398/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2360.7ms\n",
            "video 1/1 (frame 399/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2353.6ms\n",
            "video 1/1 (frame 400/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 3361.8ms\n",
            "video 1/1 (frame 401/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2417.1ms\n",
            "video 1/1 (frame 402/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2336.2ms\n",
            "video 1/1 (frame 403/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2356.4ms\n",
            "video 1/1 (frame 404/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2565.6ms\n",
            "video 1/1 (frame 405/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 3124.2ms\n",
            "video 1/1 (frame 406/592) /content/people-counting.mp4: 384x640 2 persons, 1 handbag, 2334.9ms\n",
            "video 1/1 (frame 407/592) /content/people-counting.mp4: 384x640 1 person, 1 handbag, 2344.9ms\n",
            "video 1/1 (frame 408/592) /content/people-counting.mp4: 384x640 1 person, 1 handbag, 2367.1ms\n",
            "video 1/1 (frame 409/592) /content/people-counting.mp4: 384x640 1 person, 1 handbag, 2914.9ms\n",
            "video 1/1 (frame 410/592) /content/people-counting.mp4: 384x640 1 person, 1 handbag, 2694.2ms\n",
            "video 1/1 (frame 411/592) /content/people-counting.mp4: 384x640 1 person, 1 handbag, 2328.9ms\n",
            "video 1/1 (frame 412/592) /content/people-counting.mp4: 384x640 1 person, 1 handbag, 2373.8ms\n",
            "video 1/1 (frame 413/592) /content/people-counting.mp4: 384x640 1 person, 1 handbag, 1 potted plant, 2360.1ms\n",
            "video 1/1 (frame 414/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3289.3ms\n",
            "video 1/1 (frame 415/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2334.9ms\n",
            "video 1/1 (frame 416/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2387.7ms\n",
            "video 1/1 (frame 417/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2367.2ms\n",
            "video 1/1 (frame 418/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2356.4ms\n",
            "video 1/1 (frame 419/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3338.0ms\n",
            "video 1/1 (frame 420/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2343.2ms\n",
            "video 1/1 (frame 421/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2365.2ms\n",
            "video 1/1 (frame 422/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2355.4ms\n",
            "video 1/1 (frame 423/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2670.7ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Action: gender: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 52ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "video 1/1 (frame 424/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2349.8ms\n",
            "video 1/1 (frame 425/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2376.7ms\n",
            "video 1/1 (frame 426/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2368.0ms\n",
            "video 1/1 (frame 427/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2513.9ms\n",
            "video 1/1 (frame 428/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3174.9ms\n",
            "video 1/1 (frame 429/592) /content/people-counting.mp4: 384x640 1 person, 2 potted plants, 2365.0ms\n",
            "video 1/1 (frame 430/592) /content/people-counting.mp4: 384x640 1 person, 2 potted plants, 2398.1ms\n",
            "video 1/1 (frame 431/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2341.7ms\n",
            "video 1/1 (frame 432/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2860.4ms\n",
            "video 1/1 (frame 433/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2759.0ms\n",
            "video 1/1 (frame 434/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2363.1ms\n",
            "video 1/1 (frame 435/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2335.3ms\n",
            "video 1/1 (frame 436/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2355.2ms\n",
            "video 1/1 (frame 437/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3307.5ms\n",
            "video 1/1 (frame 438/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2388.0ms\n",
            "video 1/1 (frame 439/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2356.9ms\n",
            "video 1/1 (frame 440/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2353.8ms\n",
            "video 1/1 (frame 441/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2327.3ms\n",
            "video 1/1 (frame 442/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3322.0ms\n",
            "video 1/1 (frame 443/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2343.7ms\n",
            "video 1/1 (frame 444/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2341.0ms\n",
            "video 1/1 (frame 445/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2351.5ms\n",
            "video 1/1 (frame 446/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2711.9ms\n",
            "video 1/1 (frame 447/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2925.0ms\n",
            "video 1/1 (frame 448/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2397.8ms\n",
            "video 1/1 (frame 449/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2332.1ms\n",
            "video 1/1 (frame 450/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2382.5ms\n",
            "video 1/1 (frame 451/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3092.4ms\n",
            "video 1/1 (frame 452/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2492.8ms\n",
            "video 1/1 (frame 453/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2376.7ms\n",
            "video 1/1 (frame 454/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2336.9ms\n",
            "video 1/1 (frame 455/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2353.8ms\n",
            "video 1/1 (frame 456/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3334.7ms\n",
            "video 1/1 (frame 457/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2372.2ms\n",
            "video 1/1 (frame 458/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2328.0ms\n",
            "video 1/1 (frame 459/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2340.1ms\n",
            "video 1/1 (frame 460/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2393.3ms\n",
            "video 1/1 (frame 461/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 4338.5ms\n",
            "video 1/1 (frame 462/592) /content/people-counting.mp4: 384x640 1 potted plant, 2384.2ms\n",
            "video 1/1 (frame 463/592) /content/people-counting.mp4: 384x640 1 potted plant, 2340.2ms\n",
            "video 1/1 (frame 464/592) /content/people-counting.mp4: 384x640 1 potted plant, 2357.6ms\n",
            "video 1/1 (frame 465/592) /content/people-counting.mp4: 384x640 1 potted plant, 2359.7ms\n",
            "video 1/1 (frame 466/592) /content/people-counting.mp4: 384x640 1 potted plant, 3296.7ms\n",
            "video 1/1 (frame 467/592) /content/people-counting.mp4: 384x640 1 potted plant, 2349.0ms\n",
            "video 1/1 (frame 468/592) /content/people-counting.mp4: 384x640 1 potted plant, 2374.6ms\n",
            "video 1/1 (frame 469/592) /content/people-counting.mp4: 384x640 1 potted plant, 2362.0ms\n",
            "video 1/1 (frame 470/592) /content/people-counting.mp4: 384x640 1 potted plant, 2566.2ms\n",
            "video 1/1 (frame 471/592) /content/people-counting.mp4: 384x640 1 potted plant, 3034.9ms\n",
            "video 1/1 (frame 472/592) /content/people-counting.mp4: 384x640 1 potted plant, 2393.4ms\n",
            "video 1/1 (frame 473/592) /content/people-counting.mp4: 384x640 1 potted plant, 2356.9ms\n",
            "video 1/1 (frame 474/592) /content/people-counting.mp4: 384x640 1 potted plant, 2353.9ms\n",
            "video 1/1 (frame 475/592) /content/people-counting.mp4: 384x640 1 potted plant, 2997.5ms\n",
            "video 1/1 (frame 476/592) /content/people-counting.mp4: 384x640 1 potted plant, 2647.9ms\n",
            "video 1/1 (frame 477/592) /content/people-counting.mp4: 384x640 1 potted plant, 2360.8ms\n",
            "video 1/1 (frame 478/592) /content/people-counting.mp4: 384x640 1 potted plant, 2355.1ms\n",
            "video 1/1 (frame 479/592) /content/people-counting.mp4: 384x640 1 potted plant, 2385.2ms\n",
            "video 1/1 (frame 480/592) /content/people-counting.mp4: 384x640 1 potted plant, 3322.2ms\n",
            "video 1/1 (frame 481/592) /content/people-counting.mp4: 384x640 1 potted plant, 2357.4ms\n",
            "video 1/1 (frame 482/592) /content/people-counting.mp4: 384x640 1 potted plant, 2359.7ms\n",
            "video 1/1 (frame 483/592) /content/people-counting.mp4: 384x640 1 potted plant, 2369.8ms\n",
            "video 1/1 (frame 484/592) /content/people-counting.mp4: 384x640 1 potted plant, 2389.0ms\n",
            "video 1/1 (frame 485/592) /content/people-counting.mp4: 384x640 1 potted plant, 3272.3ms\n",
            "video 1/1 (frame 486/592) /content/people-counting.mp4: 384x640 1 potted plant, 2356.5ms\n",
            "video 1/1 (frame 487/592) /content/people-counting.mp4: 384x640 1 potted plant, 2380.6ms\n",
            "video 1/1 (frame 488/592) /content/people-counting.mp4: 384x640 1 potted plant, 2348.5ms\n",
            "video 1/1 (frame 489/592) /content/people-counting.mp4: 384x640 1 potted plant, 2756.8ms\n",
            "video 1/1 (frame 490/592) /content/people-counting.mp4: 384x640 1 potted plant, 2924.3ms\n",
            "video 1/1 (frame 491/592) /content/people-counting.mp4: 384x640 1 potted plant, 2344.1ms\n",
            "video 1/1 (frame 492/592) /content/people-counting.mp4: 384x640 1 potted plant, 2355.6ms\n",
            "video 1/1 (frame 493/592) /content/people-counting.mp4: 384x640 1 potted plant, 2362.1ms\n",
            "video 1/1 (frame 494/592) /content/people-counting.mp4: 384x640 1 potted plant, 3217.1ms\n",
            "video 1/1 (frame 495/592) /content/people-counting.mp4: 384x640 1 potted plant, 2456.6ms\n",
            "video 1/1 (frame 496/592) /content/people-counting.mp4: 384x640 1 potted plant, 2367.3ms\n",
            "video 1/1 (frame 497/592) /content/people-counting.mp4: 384x640 1 potted plant, 2363.3ms\n",
            "video 1/1 (frame 498/592) /content/people-counting.mp4: 384x640 1 potted plant, 2356.5ms\n",
            "video 1/1 (frame 499/592) /content/people-counting.mp4: 384x640 1 potted plant, 3325.1ms\n",
            "video 1/1 (frame 500/592) /content/people-counting.mp4: 384x640 1 potted plant, 2360.0ms\n",
            "video 1/1 (frame 501/592) /content/people-counting.mp4: 384x640 1 potted plant, 2358.5ms\n",
            "video 1/1 (frame 502/592) /content/people-counting.mp4: 384x640 1 potted plant, 2361.1ms\n",
            "video 1/1 (frame 503/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2567.0ms\n",
            "video 1/1 (frame 504/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3053.9ms\n",
            "video 1/1 (frame 505/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2354.8ms\n",
            "video 1/1 (frame 506/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2391.3ms\n",
            "video 1/1 (frame 507/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2384.5ms\n",
            "video 1/1 (frame 508/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3051.2ms\n",
            "video 1/1 (frame 509/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2551.2ms\n",
            "video 1/1 (frame 510/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2367.5ms\n",
            "video 1/1 (frame 511/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2363.3ms\n",
            "video 1/1 (frame 512/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2373.2ms\n",
            "video 1/1 (frame 513/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3344.2ms\n",
            "video 1/1 (frame 514/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2357.6ms\n",
            "video 1/1 (frame 515/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2348.8ms\n",
            "video 1/1 (frame 516/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2369.7ms\n",
            "video 1/1 (frame 517/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2439.2ms\n",
            "video 1/1 (frame 518/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3234.6ms\n",
            "video 1/1 (frame 519/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2344.9ms\n",
            "video 1/1 (frame 520/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2356.1ms\n",
            "video 1/1 (frame 521/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2369.7ms\n",
            "video 1/1 (frame 522/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2807.5ms\n",
            "video 1/1 (frame 523/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2814.1ms\n",
            "video 1/1 (frame 524/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2369.4ms\n",
            "video 1/1 (frame 525/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2356.6ms\n",
            "video 1/1 (frame 526/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2348.7ms\n",
            "video 1/1 (frame 527/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 1 clock, 3181.9ms\n",
            "video 1/1 (frame 528/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 1 clock, 2435.6ms\n",
            "video 1/1 (frame 529/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 1 clock, 2383.4ms\n",
            "video 1/1 (frame 530/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2356.1ms\n",
            "video 1/1 (frame 531/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2349.2ms\n",
            "video 1/1 (frame 532/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3337.5ms\n",
            "video 1/1 (frame 533/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2371.8ms\n",
            "video 1/1 (frame 534/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2350.0ms\n",
            "video 1/1 (frame 535/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2369.4ms\n",
            "video 1/1 (frame 536/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2554.6ms\n",
            "video 1/1 (frame 537/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3103.6ms\n",
            "video 1/1 (frame 538/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2416.5ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Action: gender: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 53ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "video 1/1 (frame 539/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2384.4ms\n",
            "video 1/1 (frame 540/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2533.2ms\n",
            "video 1/1 (frame 541/592) /content/people-counting.mp4: 384x640 1 person, 3164.9ms\n",
            "video 1/1 (frame 542/592) /content/people-counting.mp4: 384x640 1 person, 2371.7ms\n",
            "video 1/1 (frame 543/592) /content/people-counting.mp4: 384x640 1 person, 2341.0ms\n",
            "video 1/1 (frame 544/592) /content/people-counting.mp4: 384x640 1 person, 2367.9ms\n",
            "video 1/1 (frame 545/592) /content/people-counting.mp4: 384x640 1 person, 2898.6ms\n",
            "video 1/1 (frame 546/592) /content/people-counting.mp4: 384x640 1 person, 2727.6ms\n",
            "video 1/1 (frame 547/592) /content/people-counting.mp4: 384x640 1 person, 2399.7ms\n",
            "video 1/1 (frame 548/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2370.6ms\n",
            "video 1/1 (frame 549/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2366.9ms\n",
            "video 1/1 (frame 550/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3335.5ms\n",
            "video 1/1 (frame 551/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2410.3ms\n",
            "video 1/1 (frame 552/592) /content/people-counting.mp4: 384x640 1 person, 2337.1ms\n",
            "video 1/1 (frame 553/592) /content/people-counting.mp4: 384x640 1 person, 2360.3ms\n",
            "video 1/1 (frame 554/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2348.9ms\n",
            "video 1/1 (frame 555/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3299.3ms\n",
            "video 1/1 (frame 556/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2316.8ms\n",
            "video 1/1 (frame 557/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2347.3ms\n",
            "video 1/1 (frame 558/592) /content/people-counting.mp4: 384x640 1 person, 2 potted plants, 2354.7ms\n",
            "video 1/1 (frame 559/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2592.6ms\n",
            "video 1/1 (frame 560/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3027.2ms\n",
            "video 1/1 (frame 561/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2342.3ms\n",
            "video 1/1 (frame 562/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2371.6ms\n",
            "video 1/1 (frame 563/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2349.3ms\n",
            "video 1/1 (frame 564/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2999.4ms\n",
            "video 1/1 (frame 565/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2630.7ms\n",
            "video 1/1 (frame 566/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2367.7ms\n",
            "video 1/1 (frame 567/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2351.8ms\n",
            "video 1/1 (frame 568/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2348.1ms\n",
            "video 1/1 (frame 569/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3337.8ms\n",
            "video 1/1 (frame 570/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2354.9ms\n",
            "video 1/1 (frame 571/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3318.4ms\n",
            "video 1/1 (frame 572/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2352.7ms\n",
            "video 1/1 (frame 573/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2884.8ms\n",
            "video 1/1 (frame 574/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2768.6ms\n",
            "video 1/1 (frame 575/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2354.7ms\n",
            "video 1/1 (frame 576/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2368.4ms\n",
            "video 1/1 (frame 577/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2393.9ms\n",
            "video 1/1 (frame 578/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3361.8ms\n",
            "video 1/1 (frame 579/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2349.9ms\n",
            "video 1/1 (frame 580/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2382.4ms\n",
            "video 1/1 (frame 581/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2353.8ms\n",
            "video 1/1 (frame 582/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2383.3ms\n",
            "video 1/1 (frame 583/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 3310.7ms\n",
            "video 1/1 (frame 584/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2362.1ms\n",
            "video 1/1 (frame 585/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2358.4ms\n",
            "video 1/1 (frame 586/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2350.5ms\n",
            "video 1/1 (frame 587/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2704.0ms\n",
            "video 1/1 (frame 588/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2903.2ms\n",
            "video 1/1 (frame 589/592) /content/people-counting.mp4: 384x640 2 persons, 1 potted plant, 2328.1ms\n",
            "video 1/1 (frame 590/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 2321.2ms\n",
            "video 1/1 (frame 591/592) /content/people-counting.mp4: 384x640 1 potted plant, 2324.8ms\n",
            "video 1/1 (frame 592/592) /content/people-counting.mp4: 384x640 1 person, 1 potted plant, 3003.8ms\n",
            "Speed: 4.5ms preprocess, 2597.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing complete. Results saved to output_video_final_trackingID_based.mp4 and detection_data_final_trackingID_based.json\n",
            "Total: 5, Entering: 4, Exiting: 1\n",
            "Restricted area entries: 0\n"
          ]
        }
      ],
      "source": [
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "from deepface import DeepFace\n",
        "import ffmpeg\n",
        "from datetime import timezone\n",
        "import math\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# ===== Configuration =====\n",
        "TARGET_VIDEO_PATH = \"output_video_final_trackingID_based.mp4\"\n",
        "JSON_OUTPUT_PATH = \"detection_data_final_trackingID_based.json\"\n",
        "\n",
        "# Define polygonal areas for counting\n",
        "area1 = np.array([(1169, 1678+50), (1942, 2025+50), (1816, 2102+50), (1085, 1703+50)], np.int32)\n",
        "area2 = np.array([(1040, 1710+50), (1771, 2117+50), (1673, 2142+50), (981, 1713+50)], np.int32)\n",
        "\n",
        "# Define restricted area (example coordinates - adjust as needed)\n",
        "restricted_area = np.array([(500, 500), (800, 500), (800, 800), (500, 800)], np.int32)\n",
        "\n",
        "# Object classes (COCO dataset)\n",
        "BAG_CLASSES = [24, 26, 28]  # backpack, handbag, suitcase\n",
        "CAT_CLASS = 15\n",
        "DOG_CLASS = 16\n",
        "\n",
        "# Mask detection labels\n",
        "MASK_LABELS = [\"mask\", \"no_mask\", \"improper\"]\n",
        "\n",
        "# ===== Initialize =====\n",
        "total_count = 0\n",
        "entering_count = 0\n",
        "exiting_count = 0\n",
        "restricted_area_count = 0  # New counter for restricted area\n",
        "tracker_states = {}  # Tracks area crossings\n",
        "detection_data = {}  # Stores entry/exit information\n",
        "restricted_people = set()  # Track people who entered restricted area\n",
        "\n",
        "# ===== Helper Functions =====\n",
        "def extract_video_metadata(video_path):\n",
        "    \"\"\"Extract all available metadata from a video file using ffmpeg-python.\"\"\"\n",
        "    try:\n",
        "        probe = ffmpeg.probe(video_path)\n",
        "        metadata = {}\n",
        "\n",
        "        # ===== 1. General Video Information =====\n",
        "        if \"format\" in probe:\n",
        "            format_info = probe[\"format\"]\n",
        "            metadata.update({\n",
        "                \"filename\": format_info.get(\"filename\"),\n",
        "                \"format_name\": format_info.get(\"format_name\"),\n",
        "                \"format_long_name\": format_info.get(\"format_long_name\"),\n",
        "                \"duration_seconds\": float(format_info.get(\"duration\", 0)),\n",
        "                \"size_bytes\": int(format_info.get(\"size\", 0)),\n",
        "                \"bitrate\": int(format_info.get(\"bit_rate\", 0)),\n",
        "            })\n",
        "\n",
        "            # Extract creation_time (if available)\n",
        "            if \"tags\" in format_info:\n",
        "                metadata.update({\n",
        "                    \"creation_time\": format_info[\"tags\"].get(\"creation_time\"),\n",
        "                    \"encoder\": format_info[\"tags\"].get(\"encoder\"),\n",
        "                })\n",
        "\n",
        "        # ===== 2. Video Stream Metadata =====\n",
        "        video_streams = [s for s in probe[\"streams\"] if s[\"codec_type\"] == \"video\"]\n",
        "        if video_streams:\n",
        "            video_info = video_streams[0]\n",
        "            metadata.update({\n",
        "                \"video_codec\": video_info.get(\"codec_name\"),\n",
        "                \"width\": int(video_info.get(\"width\", 0)),\n",
        "                \"height\": int(video_info.get(\"height\", 0)),\n",
        "                \"fps\": eval(video_info.get(\"avg_frame_rate\", \"0/1\")),  # e.g., \"30/1\" â†’ 30.0\n",
        "            })\n",
        "\n",
        "            # Extract device-specific metadata (iPhone, Android, etc.)\n",
        "            if \"tags\" in video_info:\n",
        "                metadata.update({\n",
        "                    \"device_model\": video_info[\"tags\"].get(\"com.apple.quicktime.model\"),\n",
        "                    \"software\": video_info[\"tags\"].get(\"software\"),\n",
        "                })\n",
        "\n",
        "        # ===== 3. Audio Stream Metadata =====\n",
        "        audio_streams = [s for s in probe[\"streams\"] if s[\"codec_type\"] == \"audio\"]\n",
        "        if audio_streams:\n",
        "            audio_info = audio_streams[0]\n",
        "            metadata.update({\n",
        "                \"audio_codec\": audio_info.get(\"codec_name\"),\n",
        "                \"sample_rate\": int(audio_info.get(\"sample_rate\", 0)),\n",
        "                \"channels\": int(audio_info.get(\"channels\", 0)),\n",
        "            })\n",
        "\n",
        "        # ===== 4. GPS Coordinates (if recorded) =====\n",
        "        if \"format\" in probe and \"tags\" in probe[\"format\"]:\n",
        "            tags = probe[\"format\"][\"tags\"]\n",
        "            if \"location\" in tags:  # Some Android devices store GPS here\n",
        "                metadata[\"gps_coordinates\"] = tags[\"location\"]\n",
        "            elif \"com.apple.quicktime.location.ISO6709\" in tags:  # iPhone GPS\n",
        "                metadata[\"gps_coordinates\"] = tags[\"com.apple.quicktime.location.ISO6709\"]\n",
        "\n",
        "        # ===== 5. Convert ISO Timestamp to Readable Format =====\n",
        "        if \"creation_time\" in metadata:\n",
        "            try:\n",
        "                dt = datetime.strptime(metadata[\"creation_time\"].split(\".\")[0], \"%Y-%m-%dT%H:%M:%S\")\n",
        "                dt = dt.replace(tzinfo=timezone.utc)\n",
        "                metadata[\"creation_time_utc\"] = dt.strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
        "                metadata[\"creation_time_local\"] = dt.astimezone().strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
        "                metadata[\"recording_time\"] = metadata[\"creation_time_local\"]  # For backward compatibility\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        return metadata\n",
        "\n",
        "    except ffmpeg.Error as e:\n",
        "        print(f\"FFmpeg error: {e.stderr.decode('utf-8')}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def detect_mask(face_img):\n",
        "    \"\"\"Detect if person is wearing a mask\"\"\"\n",
        "    try:\n",
        "        face = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
        "        face = cv2.resize(face, (224, 224))\n",
        "        face = img_to_array(face)\n",
        "        face = preprocess_input(face)\n",
        "        face = np.expand_dims(face, axis=0)\n",
        "\n",
        "        preds = mask_model.predict(face)[0]\n",
        "        max_idx = np.argmax(preds)\n",
        "        return MASK_LABELS[max_idx], float(preds[max_idx])\n",
        "    except Exception as e:\n",
        "        print(f\"Mask detection error: {str(e)}\")\n",
        "        return \"unknown\", 0.0\n",
        "\n",
        "def is_carried(obj_bbox, person_bbox):\n",
        "    \"\"\"Check if an object is being carried by a person\"\"\"\n",
        "    px1, py1, px2, py2 = person_bbox\n",
        "    ox1, oy1, ox2, oy2 = obj_bbox\n",
        "    obj_center_y = (oy1 + oy2) / 2\n",
        "    lower_half_threshold = py1 + (py2 - py1) * 0.6\n",
        "    overlap = (ox1 > px1) and (ox2 < px2) and (oy1 > py1) and (oy2 < py2)\n",
        "    in_carry_position = obj_center_y > lower_half_threshold\n",
        "    return overlap and in_carry_position\n",
        "\n",
        "def analyze_person(frame, bbox, objects):\n",
        "    \"\"\"Analyze a person's attributes at entry/exit points\"\"\"\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    face_roi = frame[y1:y2, x1:x2]\n",
        "\n",
        "    # Age/gender detection\n",
        "    try:\n",
        "        analysis = DeepFace.analyze(face_roi, actions=['age', 'gender'], enforce_detection=False)\n",
        "        gender = analysis[0]['dominant_gender']\n",
        "        age = analysis[0]['age']\n",
        "    except:\n",
        "        gender, age = \"Unknown\", \"Unknown\"\n",
        "\n",
        "    # Mask detection\n",
        "    mask_status, mask_conf = detect_mask(face_roi)\n",
        "\n",
        "    # Check for carried items\n",
        "    carried_items = []\n",
        "    for obj_bbox, _, class_id in objects:\n",
        "        if is_carried(obj_bbox, bbox):\n",
        "            if class_id in BAG_CLASSES:\n",
        "                carried_items.append(\"bag\")\n",
        "            elif class_id == CAT_CLASS:\n",
        "                carried_items.append(\"cat\")\n",
        "            elif class_id == DOG_CLASS:\n",
        "                carried_items.append(\"dog\")\n",
        "\n",
        "    return gender, age, mask_status, mask_conf, carried_items if carried_items else \"no objects\"\n",
        "\n",
        "# ===== Main Processing =====\n",
        "video_metadata = extract_video_metadata(SOURCE_VIDEO_PATH)\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# Get recording time from metadata or use current time as fallback\n",
        "try:\n",
        "    recording_time = datetime.strptime(video_metadata[\"creation_time\"].split(\".\")[0], \"%Y-%m-%dT%H:%M:%S\")\n",
        "    recording_time = recording_time.replace(tzinfo=timezone.utc)\n",
        "except (KeyError, ValueError):\n",
        "    print(\"Warning: Using current time as recording time fallback\")\n",
        "    recording_time = datetime.now(timezone.utc)\n",
        "\n",
        "with sv.VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
        "    for frame_number, result in enumerate(\n",
        "        model.track(source=SOURCE_VIDEO_PATH, tracker=\"bytetrack.yaml\", show=False, stream=True, persist=True)\n",
        "    ):\n",
        "        frame = result.orig_img\n",
        "        detections = sv.Detections.from_yolov8(result)\n",
        "\n",
        "        # Separate detections\n",
        "        people = []\n",
        "        objects = []\n",
        "        if result.boxes.id is not None:\n",
        "            tracker_ids = result.boxes.id.cpu().numpy().astype(int)\n",
        "            for i, (bbox, conf, class_id) in enumerate(zip(detections.xyxy, detections.confidence, detections.class_id)):\n",
        "                if class_id == 0:  # Person\n",
        "                    tracker_id = tracker_ids[i] if i < len(tracker_ids) else None\n",
        "                    people.append((bbox, conf, tracker_id))\n",
        "                elif class_id in BAG_CLASSES + [CAT_CLASS, DOG_CLASS]:\n",
        "                    objects.append((bbox, conf, class_id))\n",
        "\n",
        "        # Process each person's area crossings\n",
        "        for bbox, conf, tracker_id in people:\n",
        "            x1, y1, x2, y2 = bbox\n",
        "            bottom_center = (int((x1+x2)/2), int(y2))\n",
        "\n",
        "            # Check area crossings\n",
        "            in_area1 = cv2.pointPolygonTest(area1, bottom_center, False) >= 0\n",
        "            in_area2 = cv2.pointPolygonTest(area2, bottom_center, False) >= 0\n",
        "            in_restricted = cv2.pointPolygonTest(restricted_area, bottom_center, False) >= 0\n",
        "\n",
        "            current_area = None\n",
        "            if in_area1: current_area = \"area1\"\n",
        "            elif in_area2: current_area = \"area2\"\n",
        "\n",
        "            # Initialize tracker only when entering monitored areas\n",
        "            if tracker_id not in tracker_states and current_area:\n",
        "                tracker_states[tracker_id] = {\n",
        "                    'current_area': current_area,\n",
        "                    'last_area': None,\n",
        "                    'entry_time': None,\n",
        "                    'entered_restricted': False\n",
        "                }\n",
        "                detection_data[tracker_id] = {\n",
        "                    \"tracker_id\": int(tracker_id),\n",
        "                    \"gender\": \"Unknown\",\n",
        "                    \"age\": \"Unknown\",\n",
        "                    \"carrying\": \"none\",\n",
        "                    \"mask_status\": \"unknown\",\n",
        "                    \"mask_confidence\": 0.0,\n",
        "                    \"confidence\": float(conf),\n",
        "                    \"entry_time\": None,\n",
        "                    \"exit_time\": None,\n",
        "                    \"entry_frame\": None,\n",
        "                    \"exit_frame\": None,\n",
        "                    \"entry_mask_status\": None,\n",
        "                    \"exit_mask_status\": None,\n",
        "                    \"entered_restricted\": False,\n",
        "                    \"restricted_entry_time\": None,\n",
        "                    \"restricted_exit_time\": None\n",
        "                }\n",
        "\n",
        "            # Only process if person is in our tracking system (entered monitored area)\n",
        "            if tracker_id in tracker_states:\n",
        "                # Check restricted area entry\n",
        "                if in_restricted and not tracker_states[tracker_id]['entered_restricted']:\n",
        "                    tracker_states[tracker_id]['entered_restricted'] = True\n",
        "                    detection_data[tracker_id]['entered_restricted'] = True\n",
        "                    detection_data[tracker_id]['restricted_entry_time'] = (\n",
        "                        recording_time + timedelta(seconds=frame_number / video_info.fps)\n",
        "                    ).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                    restricted_area_count += 1\n",
        "                    restricted_people.add(tracker_id)\n",
        "\n",
        "                    # Draw alert for restricted area entry\n",
        "                    cv2.putText(frame, \"RESTRICTED AREA ENTRY!\", (int(x1), int(y1)-30),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "                # Check restricted area exit\n",
        "                elif not in_restricted and tracker_states[tracker_id]['entered_restricted']:\n",
        "                    detection_data[tracker_id]['restricted_exit_time'] = (\n",
        "                        recording_time + timedelta(seconds=frame_number / video_info.fps)\n",
        "                    ).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "                # Handle area transitions\n",
        "                if current_area != tracker_states[tracker_id]['current_area']:\n",
        "                    # Entry event (area2)\n",
        "                    if current_area == \"area1\" and tracker_states[tracker_id]['last_area'] == \"area2\":\n",
        "                        # Analyze person attributes\n",
        "                        gender, age, mask_status, mask_conf, carrying = analyze_person(frame, bbox, objects)\n",
        "\n",
        "                        # Update detection data\n",
        "                        entry_time = recording_time + timedelta(seconds=frame_number / video_info.fps)\n",
        "                        detection_data[tracker_id].update({\n",
        "                            \"tracker_id\": int(tracker_id),\n",
        "                            \"gender\": gender,\n",
        "                            \"age\": age,\n",
        "                            \"carrying\": carrying,\n",
        "                            \"mask_status\": mask_status,\n",
        "                            \"mask_confidence\": mask_conf,\n",
        "                            \"entry_time\": entry_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                            \"entry_frame\": frame_number,\n",
        "                            \"entry_mask_status\": mask_status,\n",
        "                            \"entry_mask_confidence\": mask_conf\n",
        "                        })\n",
        "                        entering_count += 1\n",
        "                        total_count += 1\n",
        "\n",
        "                    # Exit event (area1 after area2)\n",
        "                    elif current_area == \"area2\" and tracker_states[tracker_id]['last_area'] == \"area1\":\n",
        "                        # Analyze person attributes again at exit\n",
        "                        gender, age, mask_status, mask_conf, carrying = analyze_person(frame, bbox, objects)\n",
        "\n",
        "                        # Update detection data\n",
        "                        exit_time = recording_time + timedelta(seconds=frame_number / video_info.fps)\n",
        "                        detection_data[tracker_id].update({\n",
        "                            \"tracker_id\": int(tracker_id),\n",
        "                            \"gender\": gender,\n",
        "                            \"age\": age,\n",
        "                            \"carrying\": carrying,\n",
        "                            \"mask_status\": mask_status,\n",
        "                            \"mask_confidence\": mask_conf,\n",
        "                            \"exit_time\": exit_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                            \"exit_frame\": frame_number,\n",
        "                            \"exit_mask_status\": mask_status,\n",
        "                            \"exit_mask_confidence\": mask_conf\n",
        "                        })\n",
        "                        exiting_count += 1\n",
        "                        total_count += 1\n",
        "\n",
        "                    # Update tracker state\n",
        "                    tracker_states[tracker_id]['last_area'] = tracker_states[tracker_id]['current_area']\n",
        "                    tracker_states[tracker_id]['current_area'] = current_area\n",
        "\n",
        "                # Draw bounding box if person is being tracked\n",
        "                if detection_data[tracker_id]['entry_time']:\n",
        "                    person = detection_data[tracker_id]\n",
        "                    label = f\"ID: {tracker_id} | {person['gender']}, {person['age']} | Mask: {person['mask_status']}\"\n",
        "                    if person['entered_restricted']:\n",
        "                        # Highlight people who entered restricted area\n",
        "                        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 3)\n",
        "                        label += \" | RESTRICTED\"\n",
        "                    else:\n",
        "                        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "                    cv2.putText(frame, label, (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
        "\n",
        "        # Draw counters and areas\n",
        "        cv2.polylines(frame, [area1], isClosed=True, color=(255, 0, 0), thickness=2)\n",
        "        cv2.polylines(frame, [area2], isClosed=True, color=(0, 255, 0), thickness=2)\n",
        "        cv2.polylines(frame, [restricted_area], isClosed=True, color=(0, 0, 255), thickness=2)\n",
        "        cv2.putText(frame, \"RESTRICTED AREA\", (restricted_area[0][0], restricted_area[0][1]-10),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "        cv2.putText(frame, f\"Total: {total_count}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "        cv2.putText(frame, f\"Entering: {entering_count}\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Exiting: {exiting_count}\", (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, f\"Restricted Area: {restricted_area_count}\", (50, 200),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "        sink.write_frame(frame)\n",
        "\n",
        "# ===== Save Results =====\n",
        "json_output = {\n",
        "    \"video_metadata\": video_metadata,\n",
        "    \"processing_time\": datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S %Z\"),\n",
        "    \"summary\": {\n",
        "        \"total_people\": int(total_count),\n",
        "        \"total_entering\": int(entering_count),\n",
        "        \"total_exiting\": int(exiting_count),\n",
        "        \"restricted_area_entries\": int(restricted_area_count),\n",
        "        \"restricted_people_ids\": [int(id) for id in restricted_people],\n",
        "        \"fps\": float(video_info.fps),\n",
        "        \"duration_seconds\": float(video_info.total_frames / video_info.fps)\n",
        "    },\n",
        "    \"detections\": {\n",
        "        int(tracker_id): data for tracker_id, data in detection_data.items()\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(JSON_OUTPUT_PATH, \"w\") as f:\n",
        "    json.dump(json_output, f, indent=4)\n",
        "\n",
        "print(f\"Processing complete. Results saved to {TARGET_VIDEO_PATH} and {JSON_OUTPUT_PATH}\")\n",
        "print(f\"Total: {total_count}, Entering: {entering_count}, Exiting: {exiting_count}\")\n",
        "print(f\"Restricted area entries: {restricted_area_count}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Nu9nl9GiyeS-",
        "U_AKZ0YNN78S",
        "MFbLBUMvT1Yq",
        "v4u6RIc6tGXu",
        "Vw6o1DPYGIBG",
        "VoHUsdYmGQi7",
        "vojQ-6o4fE_D",
        "sx-jioI8ZGCf",
        "pvIFBzSlxlqE",
        "FwqaxgwWth_d",
        "kWlzS4jKBXj0",
        "cRQnPs4PBY33",
        "9b27zyP9BmmA",
        "R0mTEISgauwx"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 6929079,
          "sourceId": 11113447,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
