{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:59:11.102943Z","iopub.execute_input":"2025-03-13T03:59:11.103141Z","iopub.status.idle":"2025-03-13T03:59:11.270076Z","shell.execute_reply.started":"2025-03-13T03:59:11.103121Z","shell.execute_reply":"2025-03-13T03:59:11.269064Z"}},"outputs":[{"name":"stdout","text":"Thu Mar 13 03:59:11 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:59:11.271453Z","iopub.execute_input":"2025-03-13T03:59:11.271783Z","iopub.status.idle":"2025-03-13T03:59:15.404822Z","shell.execute_reply.started":"2025-03-13T03:59:11.271750Z","shell.execute_reply":"2025-03-13T03:59:15.403760Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.17.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2025.1.31)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"! rm -rf video.mp4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:59:15.406767Z","iopub.execute_input":"2025-03-13T03:59:15.407086Z","iopub.status.idle":"2025-03-13T03:59:15.524182Z","shell.execute_reply.started":"2025-03-13T03:59:15.407052Z","shell.execute_reply":"2025-03-13T03:59:15.523317Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import gdown\n\n# Update with your file's specific ID\nfile_id = \"1Xf3sROm-sbl9GN33jBOJJdqCxEafrQ4J\"\nurl = f\"https://drive.google.com/uc?id={file_id}\"\n\noutput = \"people-counting.mp4\"\ngdown.download(url, output, quiet=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:59:15.525663Z","iopub.execute_input":"2025-03-13T03:59:15.525894Z","iopub.status.idle":"2025-03-13T03:59:19.675428Z","shell.execute_reply.started":"2025-03-13T03:59:15.525872Z","shell.execute_reply":"2025-03-13T03:59:19.674783Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1Xf3sROm-sbl9GN33jBOJJdqCxEafrQ4J\nTo: /kaggle/working/people-counting.mp4\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.55M/2.55M [00:00<00:00, 173MB/s]\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'people-counting.mp4'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\nprint(HOME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:59:19.676219Z","iopub.execute_input":"2025-03-13T03:59:19.676631Z","iopub.status.idle":"2025-03-13T03:59:19.681008Z","shell.execute_reply.started":"2025-03-13T03:59:19.676608Z","shell.execute_reply":"2025-03-13T03:59:19.680300Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"SOURCE_VIDEO_PATH = \"/kaggle/working/people-counting.mp4\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:59:19.682053Z","iopub.execute_input":"2025-03-13T03:59:19.682339Z","iopub.status.idle":"2025-03-13T03:59:19.696995Z","shell.execute_reply.started":"2025-03-13T03:59:19.682310Z","shell.execute_reply":"2025-03-13T03:59:19.696347Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Pip install method (recommended)\n\n!pip install \"ultralytics<=8.3.40\"\n\nfrom IPython import display\ndisplay.clear_output()\n\nimport ultralytics\nultralytics.checks()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:59:19.697842Z","iopub.execute_input":"2025-03-13T03:59:19.698201Z","iopub.status.idle":"2025-03-13T03:59:27.991434Z","shell.execute_reply.started":"2025-03-13T03:59:19.698173Z","shell.execute_reply":"2025-03-13T03:59:27.990820Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.40 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nSetup complete âœ… (4 CPUs, 31.4 GB RAM, 6170.1/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install supervision==0.3.0\n\nfrom IPython import display\ndisplay.clear_output()\n\nimport supervision\nprint(\"supervision.__version__:\", supervision.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:59:27.992377Z","iopub.execute_input":"2025-03-13T03:59:27.992785Z","iopub.status.idle":"2025-03-13T03:59:31.542287Z","shell.execute_reply.started":"2025-03-13T03:59:27.992761Z","shell.execute_reply":"2025-03-13T03:59:31.541228Z"}},"outputs":[{"name":"stdout","text":"supervision.__version__: 0.3.0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# settings\nMODEL = \"yolov8x.pt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:59:31.544446Z","iopub.execute_input":"2025-03-13T03:59:31.544721Z","iopub.status.idle":"2025-03-13T03:59:31.548341Z","shell.execute_reply.started":"2025-03-13T03:59:31.544696Z","shell.execute_reply":"2025-03-13T03:59:31.547438Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO(MODEL)\nmodel.fuse()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:59:31.549382Z","iopub.execute_input":"2025-03-13T03:59:31.549627Z","iopub.status.idle":"2025-03-13T03:59:34.010534Z","shell.execute_reply.started":"2025-03-13T03:59:31.549606Z","shell.execute_reply":"2025-03-13T03:59:34.009735Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131M/131M [00:00<00:00, 383MB/s] \n","output_type":"stream"},{"name":"stdout","text":"YOLOv8x summary (fused): 268 layers, 68,200,608 parameters, 0 gradients, 257.8 GFLOPs\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load YOLO model\nmodel = YOLO('yolov8s.pt')\n\n# Get class names from the model\nclass_names = model.names  # Dictionary {class_id: class_name}\n\n# Print all class IDs and names\nfor class_id, class_name in class_names.items():\n    print(f\"Class ID: {class_id}, Class Name: {class_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:59:34.011320Z","iopub.execute_input":"2025-03-13T03:59:34.011653Z","iopub.status.idle":"2025-03-13T03:59:34.767439Z","shell.execute_reply.started":"2025-03-13T03:59:34.011617Z","shell.execute_reply":"2025-03-13T03:59:34.766487Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:00<00:00, 195MB/s]","output_type":"stream"},{"name":"stdout","text":"Class ID: 0, Class Name: person\nClass ID: 1, Class Name: bicycle\nClass ID: 2, Class Name: car\nClass ID: 3, Class Name: motorcycle\nClass ID: 4, Class Name: airplane\nClass ID: 5, Class Name: bus\nClass ID: 6, Class Name: train\nClass ID: 7, Class Name: truck\nClass ID: 8, Class Name: boat\nClass ID: 9, Class Name: traffic light\nClass ID: 10, Class Name: fire hydrant\nClass ID: 11, Class Name: stop sign\nClass ID: 12, Class Name: parking meter\nClass ID: 13, Class Name: bench\nClass ID: 14, Class Name: bird\nClass ID: 15, Class Name: cat\nClass ID: 16, Class Name: dog\nClass ID: 17, Class Name: horse\nClass ID: 18, Class Name: sheep\nClass ID: 19, Class Name: cow\nClass ID: 20, Class Name: elephant\nClass ID: 21, Class Name: bear\nClass ID: 22, Class Name: zebra\nClass ID: 23, Class Name: giraffe\nClass ID: 24, Class Name: backpack\nClass ID: 25, Class Name: umbrella\nClass ID: 26, Class Name: handbag\nClass ID: 27, Class Name: tie\nClass ID: 28, Class Name: suitcase\nClass ID: 29, Class Name: frisbee\nClass ID: 30, Class Name: skis\nClass ID: 31, Class Name: snowboard\nClass ID: 32, Class Name: sports ball\nClass ID: 33, Class Name: kite\nClass ID: 34, Class Name: baseball bat\nClass ID: 35, Class Name: baseball glove\nClass ID: 36, Class Name: skateboard\nClass ID: 37, Class Name: surfboard\nClass ID: 38, Class Name: tennis racket\nClass ID: 39, Class Name: bottle\nClass ID: 40, Class Name: wine glass\nClass ID: 41, Class Name: cup\nClass ID: 42, Class Name: fork\nClass ID: 43, Class Name: knife\nClass ID: 44, Class Name: spoon\nClass ID: 45, Class Name: bowl\nClass ID: 46, Class Name: banana\nClass ID: 47, Class Name: apple\nClass ID: 48, Class Name: sandwich\nClass ID: 49, Class Name: orange\nClass ID: 50, Class Name: broccoli\nClass ID: 51, Class Name: carrot\nClass ID: 52, Class Name: hot dog\nClass ID: 53, Class Name: pizza\nClass ID: 54, Class Name: donut\nClass ID: 55, Class Name: cake\nClass ID: 56, Class Name: chair\nClass ID: 57, Class Name: couch\nClass ID: 58, Class Name: potted plant\nClass ID: 59, Class Name: bed\nClass ID: 60, Class Name: dining table\nClass ID: 61, Class Name: toilet\nClass ID: 62, Class Name: tv\nClass ID: 63, Class Name: laptop\nClass ID: 64, Class Name: mouse\nClass ID: 65, Class Name: remote\nClass ID: 66, Class Name: keyboard\nClass ID: 67, Class Name: cell phone\nClass ID: 68, Class Name: microwave\nClass ID: 69, Class Name: oven\nClass ID: 70, Class Name: toaster\nClass ID: 71, Class Name: sink\nClass ID: 72, Class Name: refrigerator\nClass ID: 73, Class Name: book\nClass ID: 74, Class Name: clock\nClass ID: 75, Class Name: vase\nClass ID: 76, Class Name: scissors\nClass ID: 77, Class Name: teddy bear\nClass ID: 78, Class Name: hair drier\nClass ID: 79, Class Name: toothbrush\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import supervision as sv\nfrom ultralytics import YOLO\nimport os\nimport json\nimport cv2  # OpenCV for image processing\nimport numpy as np\n\n\nTARGET_VIDEO_PATH = 'output_video.mp4'\nFRAME_SAVE_DIR = 'frames/'  # Directory to save frames\nFRAME_DATA_PATH = 'frame_data.json'  # JSON file to save frame data\n\n# Define polygon zone (adjust coordinates as needed)\npolygon_zone = np.array([(250, 100), (300, 100), (300, 400), (250, 400)], np.int32)\n\n# Initialize box annotator for drawing bounding boxes\nbox_annotator = sv.BoxAnnotator(\n    thickness=4,\n    text_thickness=4,\n    text_scale=2\n)\n\n# Open video info and frame generator\nvideo_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\ngenerator = sv.video.get_video_frames_generator(SOURCE_VIDEO_PATH)\n\n# Initialize sequential ID mapping\nid_counter = 1\nid_map = {}  # Maps tracker_id to a sequential ID\nframe_data_list = []  # To store frame data\n\n# Create directory for saving frames\nos.makedirs(FRAME_SAVE_DIR, exist_ok=True)\n\n# Function to check if a bounding box center is inside the polygon\ndef is_inside_polygon(polygon, bbox):\n    \"\"\"Check if the center of a bounding box is inside the polygon.\"\"\"\n    x, y, w, h = bbox  # Extract bounding box coordinates\n    center_x, center_y = x + w // 2, y + h // 2  # Calculate center point\n\n    result = cv2.pointPolygonTest(polygon, (center_x, center_y), False)\n    return result >= 0  # Returns True if inside, False if outside\n\n\n# Open output video stream\nwith sv.VideoSink(TARGET_VIDEO_PATH, video_info) as sink:  \n    # Iterate through each frame in the video and track objects\n    for frame_number, result in enumerate(\n        YOLO('yolov8s.pt').track(\n            source=SOURCE_VIDEO_PATH, \n            tracker='bytetrack.yaml', \n            show=False, \n            stream=True, \n            agnostic_nms=True, \n            persist=True\n        )\n    ):\n        # Extract frame and detections\n        frame = result.orig_img\n        detections = sv.Detections.from_yolov8(result)\n\n        # Filter detections to only include people (class_id = 0 in COCO) and inside polygon\n        PEOPLE_CLASS_ID = 0\n        filtered_detections = [\n            (bbox, confidence, class_id, tracker_id)\n            for bbox, confidence, class_id, tracker_id in detections\n            if class_id == PEOPLE_CLASS_ID and is_inside_polygon(polygon_zone, bbox)\n        ]\n        \n        if filtered_detections:\n            people_detections = sv.Detections(\n                xyxy=np.array([bbox for bbox, _, _, _ in filtered_detections]),\n                confidence=np.array([confidence for _, confidence, _, _ in filtered_detections]),\n                class_id=np.array([class_id for _, _, class_id, _ in filtered_detections]),\n                tracker_id=np.array([tracker_id for _, _, _, tracker_id in filtered_detections]) if detections.tracker_id is not None else None\n            )\n        else:\n            # Create empty detections if no people found\n            people_detections = sv.Detections(\n                xyxy=np.empty((0, 4)),\n                confidence=np.empty((0,)),\n                class_id=np.empty((0,), dtype=int),\n                tracker_id=None\n            )\n        \n        # Use people_detections instead of detections\n        detections = people_detections\n\n        # Handle object IDs (tracker IDs)\n        if result.boxes.id is not None:\n            new_tracker_ids = []\n            detected_ids = result.boxes.id.cpu().numpy().astype(int)  # Get detected tracker IDs\n        \n            for tracker_id in detected_ids:\n                if tracker_id not in id_map:\n                    id_map[tracker_id] = len(id_map) + 1  # Ensure continuous numbering (1,2,3,4...)\n                new_tracker_ids.append(id_map[tracker_id])\n        \n            # Update detections with mapped sequential IDs\n            detections.tracker_id = np.array(new_tracker_ids)\n\n        # Define labels for each detection\n        labels = [\n            f\"ID: {tracker_id} | {model.model.names[class_id]} {confidence:0.2f}\"\n            for bbox, confidence, class_id, tracker_id in detections\n        ]\n\n        # Draw polygon on the frame\n        cv2.polylines(frame, [polygon_zone], isClosed=True, color=(0, 255, 0), thickness=2)\n\n        # Annotate the frame\n        frame = box_annotator.annotate(scene=frame, detections=detections, labels=labels)\n\n        # Save current frame to disk\n        frame_path = os.path.join(FRAME_SAVE_DIR, f\"frame_{frame_number:04d}.jpg\")\n        cv2.imwrite(frame_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))  # Convert RGB to BGR for OpenCV\n\n        # Collect frame data for JSON\n        frame_data = {\n            \"frame_number\": frame_number,\n            \"detections\": [\n                {\n                    \"tracker_id\": int(tracker_id) if tracker_id is not None else None,  # Handle None tracker_id\n                    \"class_id\": int(class_id),\n                    \"confidence\": float(confidence),\n                    \"bbox\": [float(coord) for coord in bbox]\n                }\n                for bbox, confidence, class_id, tracker_id in detections\n            ]\n        }\n        frame_data_list.append(frame_data)\n        print(\"Frame data : \" + str(frame_data))\n\n        # Write annotated frame to the output video\n        sink.write_frame(frame)\n\n    print(\"Vehicle tracking completed and output video saved.\")\n\n# Save frame data to a JSON file\nwith open(FRAME_DATA_PATH, 'w') as json_file:\n    json.dump(frame_data_list, json_file, indent=4)\n\nprint(f\"Frames saved to '{FRAME_SAVE_DIR}' and frame data saved to '{FRAME_DATA_PATH}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T04:43:29.194079Z","iopub.execute_input":"2025-03-13T04:43:29.194391Z","iopub.status.idle":"2025-03-13T04:43:37.220117Z","shell.execute_reply.started":"2025-03-13T04:43:29.194366Z","shell.execute_reply":"2025-03-13T04:43:37.219225Z"}},"outputs":[{"name":"stdout","text":"\nvideo 1/1 (frame 1/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 8.7ms\nFrame data : {'frame_number': 0, 'detections': []}\nvideo 1/1 (frame 2/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.9ms\nFrame data : {'frame_number': 1, 'detections': []}\nvideo 1/1 (frame 3/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.9ms\nFrame data : {'frame_number': 2, 'detections': []}\nvideo 1/1 (frame 4/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.9ms\nFrame data : {'frame_number': 3, 'detections': []}\nvideo 1/1 (frame 5/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.8ms\nFrame data : {'frame_number': 4, 'detections': []}\nvideo 1/1 (frame 6/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.9ms\nFrame data : {'frame_number': 5, 'detections': []}\nvideo 1/1 (frame 7/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.9ms\nFrame data : {'frame_number': 6, 'detections': []}\nvideo 1/1 (frame 8/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 8.1ms\nFrame data : {'frame_number': 7, 'detections': []}\nvideo 1/1 (frame 9/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.9ms\nFrame data : {'frame_number': 8, 'detections': []}\nvideo 1/1 (frame 10/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.9ms\nFrame data : {'frame_number': 9, 'detections': []}\nvideo 1/1 (frame 11/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.9ms\nFrame data : {'frame_number': 10, 'detections': []}\nvideo 1/1 (frame 12/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.6ms\nFrame data : {'frame_number': 11, 'detections': []}\nvideo 1/1 (frame 13/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.4ms\nFrame data : {'frame_number': 12, 'detections': []}\nvideo 1/1 (frame 14/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.4ms\nFrame data : {'frame_number': 13, 'detections': []}\nvideo 1/1 (frame 15/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.4ms\nFrame data : {'frame_number': 14, 'detections': []}\nvideo 1/1 (frame 16/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.4ms\nFrame data : {'frame_number': 15, 'detections': []}\nvideo 1/1 (frame 17/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.4ms\nFrame data : {'frame_number': 16, 'detections': []}\nvideo 1/1 (frame 18/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.3ms\nFrame data : {'frame_number': 17, 'detections': []}\nvideo 1/1 (frame 19/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.3ms\nFrame data : {'frame_number': 18, 'detections': []}\nvideo 1/1 (frame 20/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.3ms\nFrame data : {'frame_number': 19, 'detections': []}\nvideo 1/1 (frame 21/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 9.0ms\nFrame data : {'frame_number': 20, 'detections': []}\nvideo 1/1 (frame 22/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.3ms\nFrame data : {'frame_number': 21, 'detections': []}\nvideo 1/1 (frame 23/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 11.0ms\nFrame data : {'frame_number': 22, 'detections': []}\nvideo 1/1 (frame 24/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 9.7ms\nFrame data : {'frame_number': 23, 'detections': []}\nvideo 1/1 (frame 25/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.3ms\nFrame data : {'frame_number': 24, 'detections': []}\nvideo 1/1 (frame 26/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 25, 'detections': []}\nvideo 1/1 (frame 27/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.1ms\nFrame data : {'frame_number': 26, 'detections': []}\nvideo 1/1 (frame 28/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 27, 'detections': []}\nvideo 1/1 (frame 29/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 8.2ms\nFrame data : {'frame_number': 28, 'detections': []}\nvideo 1/1 (frame 30/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 29, 'detections': []}\nvideo 1/1 (frame 31/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.6ms\nFrame data : {'frame_number': 30, 'detections': []}\nvideo 1/1 (frame 32/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 31, 'detections': []}\nvideo 1/1 (frame 33/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 32, 'detections': []}\nvideo 1/1 (frame 34/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 33, 'detections': []}\nvideo 1/1 (frame 35/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 8.4ms\nFrame data : {'frame_number': 34, 'detections': []}\nvideo 1/1 (frame 36/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 8.1ms\nFrame data : {'frame_number': 35, 'detections': []}\nvideo 1/1 (frame 37/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.4ms\nFrame data : {'frame_number': 36, 'detections': []}\nvideo 1/1 (frame 38/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 8.9ms\nFrame data : {'frame_number': 37, 'detections': []}\nvideo 1/1 (frame 39/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.3ms\nFrame data : {'frame_number': 38, 'detections': []}\nvideo 1/1 (frame 40/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 8.2ms\nFrame data : {'frame_number': 39, 'detections': []}\nvideo 1/1 (frame 41/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.8ms\nFrame data : {'frame_number': 40, 'detections': []}\nvideo 1/1 (frame 42/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.3ms\nFrame data : {'frame_number': 41, 'detections': []}\nvideo 1/1 (frame 43/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.1ms\nFrame data : {'frame_number': 42, 'detections': []}\nvideo 1/1 (frame 44/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.8ms\nFrame data : {'frame_number': 43, 'detections': []}\nvideo 1/1 (frame 45/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 9.1ms\nFrame data : {'frame_number': 44, 'detections': []}\nvideo 1/1 (frame 46/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.9ms\nFrame data : {'frame_number': 45, 'detections': []}\nvideo 1/1 (frame 47/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.8ms\nFrame data : {'frame_number': 46, 'detections': []}\nvideo 1/1 (frame 48/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 47, 'detections': []}\nvideo 1/1 (frame 49/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.1ms\nFrame data : {'frame_number': 48, 'detections': []}\nvideo 1/1 (frame 50/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.1ms\nFrame data : {'frame_number': 49, 'detections': []}\nvideo 1/1 (frame 51/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.6ms\nFrame data : {'frame_number': 50, 'detections': []}\nvideo 1/1 (frame 52/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.2ms\nFrame data : {'frame_number': 51, 'detections': []}\nvideo 1/1 (frame 53/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 8.7ms\nFrame data : {'frame_number': 52, 'detections': []}\nvideo 1/1 (frame 54/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 8.9ms\nFrame data : {'frame_number': 53, 'detections': []}\nvideo 1/1 (frame 55/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.8ms\nFrame data : {'frame_number': 54, 'detections': []}\nvideo 1/1 (frame 56/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.0ms\nFrame data : {'frame_number': 55, 'detections': []}\nvideo 1/1 (frame 57/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 8.8ms\nFrame data : {'frame_number': 56, 'detections': []}\nvideo 1/1 (frame 58/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.3ms\nFrame data : {'frame_number': 57, 'detections': []}\nvideo 1/1 (frame 59/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.1ms\nFrame data : {'frame_number': 58, 'detections': []}\nvideo 1/1 (frame 60/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.9ms\nFrame data : {'frame_number': 59, 'detections': []}\nvideo 1/1 (frame 61/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 8.5ms\nFrame data : {'frame_number': 60, 'detections': []}\nvideo 1/1 (frame 62/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.7ms\nFrame data : {'frame_number': 61, 'detections': []}\nvideo 1/1 (frame 63/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.7ms\nFrame data : {'frame_number': 62, 'detections': []}\nvideo 1/1 (frame 64/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 8.8ms\nFrame data : {'frame_number': 63, 'detections': []}\nvideo 1/1 (frame 65/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.2ms\nFrame data : {'frame_number': 64, 'detections': []}\nvideo 1/1 (frame 66/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.1ms\nFrame data : {'frame_number': 65, 'detections': []}\nvideo 1/1 (frame 67/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 8.3ms\nFrame data : {'frame_number': 66, 'detections': []}\nvideo 1/1 (frame 68/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 9.3ms\nFrame data : {'frame_number': 67, 'detections': []}\nvideo 1/1 (frame 69/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.7ms\nFrame data : {'frame_number': 68, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.9152506589889526, 'bbox': [104.66204071044922, 122.58035278320312, 296.9873962402344, 368.22845458984375]}]}\nvideo 1/1 (frame 70/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 69, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.9171215295791626, 'bbox': [106.01235961914062, 119.74946594238281, 299.9071350097656, 367.0630187988281]}]}\nvideo 1/1 (frame 71/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 70, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.9170835018157959, 'bbox': [107.6460189819336, 116.55817413330078, 302.862548828125, 365.8704833984375]}]}\nvideo 1/1 (frame 72/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 71, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.9053826928138733, 'bbox': [108.39733123779297, 112.98110961914062, 304.7708740234375, 365.07757568359375]}]}\nvideo 1/1 (frame 73/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 72, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.9113336205482483, 'bbox': [106.41969299316406, 108.64494323730469, 304.7198181152344, 363.6955871582031]}]}\nvideo 1/1 (frame 74/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 73, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.9012073874473572, 'bbox': [107.01240539550781, 104.28496551513672, 306.78466796875, 362.5382385253906]}]}\nvideo 1/1 (frame 75/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 74, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.9088661074638367, 'bbox': [105.04430389404297, 100.62530517578125, 306.69769287109375, 362.2074279785156]}]}\nvideo 1/1 (frame 76/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 75, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8876563310623169, 'bbox': [104.4321517944336, 97.08861541748047, 307.5423889160156, 362.0378112792969]}]}\nvideo 1/1 (frame 77/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 76, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8945045471191406, 'bbox': [102.69986724853516, 94.1263427734375, 306.95306396484375, 362.25115966796875]}]}\nvideo 1/1 (frame 78/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 77, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8889952301979065, 'bbox': [101.7319564819336, 91.94615936279297, 305.90716552734375, 362.1512145996094]}]}\nvideo 1/1 (frame 79/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.5ms\nFrame data : {'frame_number': 78, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8966483473777771, 'bbox': [100.8045425415039, 90.12004852294922, 305.6976318359375, 362.7166442871094]}]}\nvideo 1/1 (frame 80/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 79, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8995398879051208, 'bbox': [99.71012115478516, 88.37928009033203, 305.125244140625, 363.4241943359375]}]}\nvideo 1/1 (frame 81/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 80, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8947303295135498, 'bbox': [99.29948425292969, 87.20789337158203, 304.7799377441406, 363.98419189453125]}]}\nvideo 1/1 (frame 82/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 81, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.874716579914093, 'bbox': [102.67866516113281, 86.76853942871094, 306.32025146484375, 364.06610107421875]}]}\nvideo 1/1 (frame 83/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 82, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.870373547077179, 'bbox': [102.16483306884766, 86.35429382324219, 304.6379699707031, 364.2758483886719]}]}\nvideo 1/1 (frame 84/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 83, 'detections': []}\nvideo 1/1 (frame 85/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.9ms\nFrame data : {'frame_number': 84, 'detections': []}\nvideo 1/1 (frame 86/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.5ms\nFrame data : {'frame_number': 85, 'detections': []}\nvideo 1/1 (frame 87/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 8.1ms\nFrame data : {'frame_number': 86, 'detections': []}\nvideo 1/1 (frame 88/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.2ms\nFrame data : {'frame_number': 87, 'detections': []}\nvideo 1/1 (frame 89/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.8ms\nFrame data : {'frame_number': 88, 'detections': []}\nvideo 1/1 (frame 90/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.1ms\nFrame data : {'frame_number': 89, 'detections': []}\nvideo 1/1 (frame 91/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.2ms\nFrame data : {'frame_number': 90, 'detections': []}\nvideo 1/1 (frame 92/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.2ms\nFrame data : {'frame_number': 91, 'detections': []}\nvideo 1/1 (frame 93/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.1ms\nFrame data : {'frame_number': 92, 'detections': []}\nvideo 1/1 (frame 94/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.5ms\nFrame data : {'frame_number': 93, 'detections': []}\nvideo 1/1 (frame 95/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.2ms\nFrame data : {'frame_number': 94, 'detections': []}\nvideo 1/1 (frame 96/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.2ms\nFrame data : {'frame_number': 95, 'detections': []}\nvideo 1/1 (frame 97/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.1ms\nFrame data : {'frame_number': 96, 'detections': []}\nvideo 1/1 (frame 98/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.1ms\nFrame data : {'frame_number': 97, 'detections': []}\nvideo 1/1 (frame 99/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.2ms\nFrame data : {'frame_number': 98, 'detections': []}\nvideo 1/1 (frame 100/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.2ms\nFrame data : {'frame_number': 99, 'detections': []}\nvideo 1/1 (frame 101/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 2 benchs, 7.2ms\nFrame data : {'frame_number': 100, 'detections': []}\nvideo 1/1 (frame 102/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 101, 'detections': []}\nvideo 1/1 (frame 103/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 102, 'detections': []}\nvideo 1/1 (frame 104/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 103, 'detections': []}\nvideo 1/1 (frame 105/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 104, 'detections': []}\nvideo 1/1 (frame 106/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 105, 'detections': []}\nvideo 1/1 (frame 107/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 106, 'detections': []}\nvideo 1/1 (frame 108/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 107, 'detections': []}\nvideo 1/1 (frame 109/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 108, 'detections': []}\nvideo 1/1 (frame 110/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 109, 'detections': []}\nvideo 1/1 (frame 111/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 110, 'detections': []}\nvideo 1/1 (frame 112/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 111, 'detections': []}\nvideo 1/1 (frame 113/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 112, 'detections': []}\nvideo 1/1 (frame 114/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 113, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.849361002445221, 'bbox': [168.80133056640625, 168.07351684570312, 261.5657958984375, 368.2428894042969]}]}\nvideo 1/1 (frame 115/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 114, 'detections': []}\nvideo 1/1 (frame 116/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 115, 'detections': []}\nvideo 1/1 (frame 117/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 116, 'detections': []}\nvideo 1/1 (frame 118/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 117, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.9145165681838989, 'bbox': [164.055908203125, 142.71359252929688, 271.8150939941406, 360.4246826171875]}]}\nvideo 1/1 (frame 119/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.7ms\nFrame data : {'frame_number': 118, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.9052713513374329, 'bbox': [160.70181274414062, 142.56011962890625, 268.9681396484375, 357.8442077636719]}]}\nvideo 1/1 (frame 120/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.7ms\nFrame data : {'frame_number': 119, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.899385392665863, 'bbox': [157.01390075683594, 145.66921997070312, 266.2344055175781, 359.155029296875]}]}\nvideo 1/1 (frame 121/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.5ms\nFrame data : {'frame_number': 120, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8819535970687866, 'bbox': [154.147216796875, 151.7487030029297, 262.8710632324219, 361.55609130859375]}]}\nvideo 1/1 (frame 122/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 121, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8322345614433289, 'bbox': [153.378173828125, 158.51593017578125, 257.68914794921875, 362.193359375]}]}\nvideo 1/1 (frame 123/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 122, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8018715977668762, 'bbox': [158.7013702392578, 163.5428009033203, 257.86236572265625, 362.5051574707031]}]}\nvideo 1/1 (frame 124/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.5ms\nFrame data : {'frame_number': 123, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7835827469825745, 'bbox': [161.7538604736328, 163.99740600585938, 258.15008544921875, 361.9092712402344]}]}\nvideo 1/1 (frame 125/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 124, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8019490838050842, 'bbox': [160.40333557128906, 161.06382751464844, 255.47105407714844, 361.7382507324219]}]}\nvideo 1/1 (frame 126/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 125, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.840133786201477, 'bbox': [154.5977783203125, 154.6629638671875, 249.94320678710938, 359.7264404296875]}]}\nvideo 1/1 (frame 127/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.7ms\nFrame data : {'frame_number': 126, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8603547215461731, 'bbox': [151.27333068847656, 146.96693420410156, 248.5625, 358.9494934082031]}]}\nvideo 1/1 (frame 128/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 1 handbag, 7.3ms\nFrame data : {'frame_number': 127, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8683066368103027, 'bbox': [146.16246032714844, 139.6923065185547, 245.37562561035156, 356.7002258300781]}]}\nvideo 1/1 (frame 129/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 128, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8987738490104675, 'bbox': [146.96531677246094, 134.10659790039062, 248.2064971923828, 354.3108825683594]}]}\nvideo 1/1 (frame 130/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 129, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8606075048446655, 'bbox': [146.1912841796875, 129.2267608642578, 249.8932647705078, 353.37603759765625]}]}\nvideo 1/1 (frame 131/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 1 handbag, 7.6ms\nFrame data : {'frame_number': 130, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8135184049606323, 'bbox': [149.90682983398438, 127.66998291015625, 253.04623413085938, 353.7117004394531]}]}\nvideo 1/1 (frame 132/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 1 handbag, 7.1ms\nFrame data : {'frame_number': 131, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8511695861816406, 'bbox': [144.8061065673828, 129.43157958984375, 244.90184020996094, 352.91204833984375]}]}\nvideo 1/1 (frame 133/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 132, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8124703168869019, 'bbox': [150.03147888183594, 132.60311889648438, 244.54183959960938, 351.4519348144531]}]}\nvideo 1/1 (frame 134/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 133, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8303114771842957, 'bbox': [152.26329040527344, 137.71084594726562, 241.9502410888672, 352.8948059082031]}]}\nvideo 1/1 (frame 135/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 1 handbag, 7.9ms\nFrame data : {'frame_number': 134, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8116962313652039, 'bbox': [155.05177307128906, 141.38563537597656, 239.9600830078125, 351.62579345703125]}]}\nvideo 1/1 (frame 136/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 135, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.9159455895423889, 'bbox': [118.1175537109375, 45.76530075073242, 269.5240173339844, 347.34759521484375]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.7606560587882996, 'bbox': [157.08792114257812, 141.8724822998047, 239.82830810546875, 351.3951416015625]}]}\nvideo 1/1 (frame 137/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 136, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.9032977223396301, 'bbox': [120.33653259277344, 46.02565002441406, 273.73486328125, 347.0048522949219]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.8033114671707153, 'bbox': [155.13514709472656, 140.8880615234375, 237.4458465576172, 350.7228088378906]}]}\nvideo 1/1 (frame 138/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 137, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8732451796531677, 'bbox': [123.40855407714844, 46.92623519897461, 277.5373229980469, 345.14251708984375]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.8545324206352234, 'bbox': [152.22012329101562, 137.99317932128906, 235.88926696777344, 350.4781799316406]}]}\nvideo 1/1 (frame 139/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 138, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8498494625091553, 'bbox': [125.66181182861328, 49.24633026123047, 280.21551513671875, 344.2357482910156]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.7232140898704529, 'bbox': [153.6678466796875, 134.93185424804688, 237.96302795410156, 349.54302978515625]}]}\nvideo 1/1 (frame 140/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 139, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8711647391319275, 'bbox': [125.76854705810547, 51.354007720947266, 281.79443359375, 344.8775634765625]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.7675636410713196, 'bbox': [150.18930053710938, 133.2701873779297, 235.35792541503906, 348.8233642578125]}]}\nvideo 1/1 (frame 141/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 140, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8035191893577576, 'bbox': [127.369140625, 53.7746467590332, 283.8812255859375, 344.4864501953125]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.6105325818061829, 'bbox': [146.29873657226562, 130.9862823486328, 232.4904327392578, 348.4021301269531]}, {'tracker_id': 3, 'class_id': 0, 'confidence': 0.42541220784187317, 'bbox': [150.1984405517578, 130.95913696289062, 277.3189392089844, 349.16534423828125]}]}\nvideo 1/1 (frame 142/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 141, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8246104717254639, 'bbox': [129.09274291992188, 55.93095397949219, 286.61651611328125, 345.9317626953125]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.47839757800102234, 'bbox': [142.52381896972656, 129.4369354248047, 229.6644744873047, 348.6135559082031]}, {'tracker_id': 3, 'class_id': 0, 'confidence': 0.27161097526550293, 'bbox': [155.14219665527344, 129.39907836914062, 283.1522521972656, 349.164306640625]}]}\nvideo 1/1 (frame 143/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.6ms\nFrame data : {'frame_number': 142, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7492495775222778, 'bbox': [130.85064697265625, 57.240604400634766, 288.74078369140625, 346.0663757324219]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.22914114594459534, 'bbox': [144.0282745361328, 129.1053009033203, 231.6749725341797, 348.31036376953125]}, {'tracker_id': 3, 'class_id': 0, 'confidence': 0.5831051468849182, 'bbox': [154.54922485351562, 127.05371856689453, 284.2316589355469, 348.9129638671875]}]}\nvideo 1/1 (frame 144/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 143, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7907073497772217, 'bbox': [132.0675048828125, 59.52303695678711, 289.60260009765625, 345.2740783691406]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.5073909163475037, 'bbox': [144.98471069335938, 130.5569305419922, 233.064208984375, 347.68511962890625]}, {'tracker_id': 3, 'class_id': 0, 'confidence': 0.4044756293296814, 'bbox': [153.5389404296875, 129.0411376953125, 282.2868347167969, 348.2633361816406]}]}\nvideo 1/1 (frame 145/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 144, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8423072099685669, 'bbox': [132.44276428222656, 61.17274856567383, 289.9288330078125, 344.6792297363281]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.6556234359741211, 'bbox': [144.8636932373047, 131.1968536376953, 233.9652862548828, 347.5284118652344]}]}\nvideo 1/1 (frame 146/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 145, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7807245254516602, 'bbox': [133.23883056640625, 62.608314514160156, 291.49163818359375, 345.25054931640625]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.7364887595176697, 'bbox': [144.49391174316406, 133.89312744140625, 233.68458557128906, 347.76123046875]}]}\nvideo 1/1 (frame 147/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.4ms\nFrame data : {'frame_number': 146, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7475606203079224, 'bbox': [133.796142578125, 66.10902404785156, 291.0079650878906, 344.2044982910156]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.7411651015281677, 'bbox': [149.5518798828125, 136.58718872070312, 237.64682006835938, 347.7741394042969]}]}\nvideo 1/1 (frame 148/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 147, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7777844667434692, 'bbox': [134.01052856445312, 69.46391296386719, 289.3030700683594, 341.0943603515625]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.754647433757782, 'bbox': [154.3036651611328, 140.34938049316406, 239.62371826171875, 347.8804626464844]}]}\nvideo 1/1 (frame 149/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 148, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7134708166122437, 'bbox': [134.51004028320312, 73.03284454345703, 288.3415832519531, 338.90350341796875]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.7684106230735779, 'bbox': [156.10189819335938, 139.88198852539062, 240.17623901367188, 347.59478759765625]}]}\nvideo 1/1 (frame 150/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 149, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7564231157302856, 'bbox': [135.0203857421875, 75.55674743652344, 288.91552734375, 339.1697692871094]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.7584619522094727, 'bbox': [157.5062255859375, 138.14718627929688, 241.32086181640625, 346.57373046875]}]}\nvideo 1/1 (frame 151/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 150, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7005628347396851, 'bbox': [133.79441833496094, 77.75944519042969, 287.5985107421875, 339.21966552734375]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.8141207098960876, 'bbox': [159.37258911132812, 134.1824188232422, 244.22683715820312, 346.5186462402344]}]}\nvideo 1/1 (frame 152/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 151, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.5254307985305786, 'bbox': [133.5126953125, 80.166015625, 286.28179931640625, 338.959716796875]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.8123272657394409, 'bbox': [159.50164794921875, 131.88858032226562, 244.76048278808594, 345.2116394042969]}]}\nvideo 1/1 (frame 153/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 152, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.4937332570552826, 'bbox': [131.73252868652344, 80.99620056152344, 283.80303955078125, 338.077880859375]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.8120296597480774, 'bbox': [157.59317016601562, 130.2036895751953, 244.21026611328125, 345.03302001953125]}]}\nvideo 1/1 (frame 154/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 153, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.24977977573871613, 'bbox': [131.51687622070312, 80.40251922607422, 282.66680908203125, 337.9732971191406]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.7558411955833435, 'bbox': [155.3004150390625, 129.1044158935547, 243.29345703125, 344.33648681640625]}]}\nvideo 1/1 (frame 155/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 154, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.6654275059700012, 'bbox': [121.58783721923828, 78.85171508789062, 271.05670166015625, 338.334228515625]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.6215597987174988, 'bbox': [158.41165161132812, 129.0283660888672, 248.6391143798828, 344.60125732421875]}]}\nvideo 1/1 (frame 156/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.1ms\nFrame data : {'frame_number': 155, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7168821096420288, 'bbox': [158.8867950439453, 128.41290283203125, 250.96400451660156, 343.6572265625]}]}\nvideo 1/1 (frame 157/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 156, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7079764008522034, 'bbox': [158.0934600830078, 128.05601501464844, 251.18605041503906, 342.7859802246094]}]}\nvideo 1/1 (frame 158/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 handbag, 7.1ms\nFrame data : {'frame_number': 157, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7575134634971619, 'bbox': [154.66790771484375, 126.98689270019531, 248.0254669189453, 340.7696533203125]}]}\nvideo 1/1 (frame 159/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 158, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7920926213264465, 'bbox': [150.64273071289062, 127.27650451660156, 244.7638702392578, 341.3367004394531]}]}\nvideo 1/1 (frame 160/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 159, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8034698963165283, 'bbox': [147.8836669921875, 127.98880004882812, 242.80316162109375, 341.09820556640625]}]}\nvideo 1/1 (frame 161/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 160, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.803757905960083, 'bbox': [144.744140625, 129.1658477783203, 239.1395721435547, 341.3964538574219]}]}\nvideo 1/1 (frame 162/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 161, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7575652003288269, 'bbox': [145.75149536132812, 129.4849090576172, 239.4276580810547, 341.6928405761719]}]}\nvideo 1/1 (frame 163/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 162, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7429494261741638, 'bbox': [153.91993713378906, 132.5360870361328, 243.1417999267578, 339.5334167480469]}]}\nvideo 1/1 (frame 164/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 163, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7428892850875854, 'bbox': [157.3655242919922, 131.69984436035156, 245.33242797851562, 339.7257995605469]}]}\nvideo 1/1 (frame 165/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 164, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7757388949394226, 'bbox': [160.01475524902344, 131.115234375, 245.83506774902344, 340.06732177734375]}]}\nvideo 1/1 (frame 166/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 165, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7256287336349487, 'bbox': [150.44358825683594, 128.08692932128906, 238.65985107421875, 341.54827880859375]}]}\nvideo 1/1 (frame 167/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 166, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7626650929450989, 'bbox': [153.0849151611328, 126.4517593383789, 239.88473510742188, 340.21051025390625]}]}\nvideo 1/1 (frame 168/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 167, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.813605010509491, 'bbox': [151.28793334960938, 125.6242904663086, 238.13575744628906, 339.7219543457031]}]}\nvideo 1/1 (frame 169/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.7ms\nFrame data : {'frame_number': 168, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8010739684104919, 'bbox': [148.87985229492188, 127.08540344238281, 236.94940185546875, 341.6785888671875]}]}\nvideo 1/1 (frame 170/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 169, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8291796445846558, 'bbox': [144.2695770263672, 128.01226806640625, 234.16348266601562, 343.0846862792969]}]}\nvideo 1/1 (frame 171/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 170, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8441272974014282, 'bbox': [142.8667449951172, 128.41680908203125, 234.0254669189453, 342.6125183105469]}]}\nvideo 1/1 (frame 172/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 171, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8284321427345276, 'bbox': [141.86630249023438, 128.89976501464844, 234.1903076171875, 342.1542663574219]}]}\nvideo 1/1 (frame 173/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 172, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8333024978637695, 'bbox': [141.38320922851562, 129.13058471679688, 234.92831420898438, 341.7029113769531]}]}\nvideo 1/1 (frame 174/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 173, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8219046592712402, 'bbox': [140.6661376953125, 129.0953826904297, 235.45654296875, 342.0967712402344]}]}\nvideo 1/1 (frame 175/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 174, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.837105393409729, 'bbox': [140.70298767089844, 129.05677795410156, 236.49545288085938, 341.47247314453125]}]}\nvideo 1/1 (frame 176/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 175, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8299081921577454, 'bbox': [135.96847534179688, 128.8690185546875, 232.47535705566406, 341.5762634277344]}]}\nvideo 1/1 (frame 177/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 handbag, 7.1ms\nFrame data : {'frame_number': 176, 'detections': []}\nvideo 1/1 (frame 178/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 handbag, 7.3ms\nFrame data : {'frame_number': 177, 'detections': []}\nvideo 1/1 (frame 179/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 handbag, 7.1ms\nFrame data : {'frame_number': 178, 'detections': []}\nvideo 1/1 (frame 180/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 handbag, 7.8ms\nFrame data : {'frame_number': 179, 'detections': []}\nvideo 1/1 (frame 181/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 handbag, 7.3ms\nFrame data : {'frame_number': 180, 'detections': []}\nvideo 1/1 (frame 182/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 handbag, 7.3ms\nFrame data : {'frame_number': 181, 'detections': []}\nvideo 1/1 (frame 183/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 handbag, 7.1ms\nFrame data : {'frame_number': 182, 'detections': []}\nvideo 1/1 (frame 184/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 183, 'detections': []}\nvideo 1/1 (frame 185/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.1ms\nFrame data : {'frame_number': 184, 'detections': []}\nvideo 1/1 (frame 186/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 1 handbag, 1 bottle, 7.2ms\nFrame data : {'frame_number': 185, 'detections': []}\nvideo 1/1 (frame 187/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 handbag, 7.4ms\nFrame data : {'frame_number': 186, 'detections': []}\nvideo 1/1 (frame 188/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 1 handbag, 1 bottle, 7.5ms\nFrame data : {'frame_number': 187, 'detections': []}\nvideo 1/1 (frame 189/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 2 handbags, 1 bottle, 7.2ms\nFrame data : {'frame_number': 188, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.42646095156669617, 'bbox': [123.7264633178711, 63.74803924560547, 263.5633544921875, 348.7525939941406]}]}\nvideo 1/1 (frame 190/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 2 handbags, 7.3ms\nFrame data : {'frame_number': 189, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.3502700626850128, 'bbox': [133.40582275390625, 67.12906646728516, 272.4668884277344, 344.2904968261719]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.5015411376953125, 'bbox': [126.79366302490234, 67.39079284667969, 283.7966613769531, 218.3115234375]}]}\nvideo 1/1 (frame 191/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 2 handbags, 7.2ms\nFrame data : {'frame_number': 190, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7305126786231995, 'bbox': [139.114501953125, 70.27217102050781, 281.7188415527344, 347.8594665527344]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.1085367426276207, 'bbox': [113.74146270751953, 70.3160171508789, 306.5440673828125, 256.4739990234375]}]}\nvideo 1/1 (frame 192/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 2 handbags, 7.2ms\nFrame data : {'frame_number': 191, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.36168649792671204, 'bbox': [141.0605926513672, 72.3835220336914, 286.4513854980469, 350.2022705078125]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.264160692691803, 'bbox': [112.50825500488281, 72.30488586425781, 315.3852844238281, 269.0963134765625]}]}\nvideo 1/1 (frame 193/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 2 handbags, 7.2ms\nFrame data : {'frame_number': 192, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.531528890132904, 'bbox': [140.08673095703125, 74.64530181884766, 289.3924255371094, 352.45013427734375]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.1329495906829834, 'bbox': [119.12791442871094, 74.78814697265625, 316.3037414550781, 266.7506103515625]}]}\nvideo 1/1 (frame 194/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 193, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.28550851345062256, 'bbox': [140.80401611328125, 76.74384307861328, 287.7479553222656, 348.15277099609375]}]}\nvideo 1/1 (frame 195/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 194, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.38575130701065063, 'bbox': [145.72621154785156, 78.38536834716797, 289.10247802734375, 342.64764404296875]}]}\nvideo 1/1 (frame 196/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 195, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.5588407516479492, 'bbox': [148.84423828125, 80.62871551513672, 290.0896301269531, 341.8032531738281]}]}\nvideo 1/1 (frame 197/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 196, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.3977746069431305, 'bbox': [151.05093383789062, 82.3059310913086, 290.6488037109375, 341.1887512207031]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.4202437400817871, 'bbox': [162.930419921875, 171.58114624023438, 212.09906005859375, 345.48065185546875]}]}\nvideo 1/1 (frame 198/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 197, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.6264549493789673, 'bbox': [152.03692626953125, 83.54911041259766, 291.57977294921875, 342.7579345703125]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.3041716516017914, 'bbox': [160.625244140625, 167.59646606445312, 209.94766235351562, 345.582763671875]}]}\nvideo 1/1 (frame 199/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 198, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.5787290334701538, 'bbox': [152.0004425048828, 84.39375305175781, 291.07720947265625, 343.53350830078125]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.31583723425865173, 'bbox': [156.5767822265625, 162.80026245117188, 207.24923706054688, 346.34478759765625]}]}\nvideo 1/1 (frame 200/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.1ms\nFrame data : {'frame_number': 199, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.6991021633148193, 'bbox': [151.9203338623047, 85.01273345947266, 291.1087646484375, 345.37017822265625]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.20121951401233673, 'bbox': [152.5731201171875, 153.61077880859375, 205.52886962890625, 347.3475341796875]}]}\nvideo 1/1 (frame 201/400) /kaggle/working/people-counting.mp4: 384x640 5 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 200, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.6814141273498535, 'bbox': [149.76480102539062, 85.04094696044922, 289.1934814453125, 347.5649108886719]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.2725532054901123, 'bbox': [153.9561767578125, 158.05767822265625, 205.12913513183594, 347.8119812011719]}]}\nvideo 1/1 (frame 202/400) /kaggle/working/people-counting.mp4: 384x640 5 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 201, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.5188359618186951, 'bbox': [135.58523559570312, 84.53152465820312, 270.10247802734375, 347.4002380371094]}, {'tracker_id': 2, 'class_id': 0, 'confidence': 0.3681337833404541, 'bbox': [154.4883270263672, 168.85296630859375, 203.12884521484375, 348.3903503417969]}]}\nvideo 1/1 (frame 203/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 202, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.5944961905479431, 'bbox': [140.14865112304688, 83.87358856201172, 273.0032653808594, 346.70623779296875]}]}\nvideo 1/1 (frame 204/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 203, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.631517767906189, 'bbox': [140.34866333007812, 82.29995727539062, 273.04327392578125, 347.46221923828125]}]}\nvideo 1/1 (frame 205/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 204, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8510403633117676, 'bbox': [140.3257293701172, 80.64569854736328, 273.039794921875, 347.44744873046875]}]}\nvideo 1/1 (frame 206/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 3 benchs, 7.1ms\nFrame data : {'frame_number': 205, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.86799156665802, 'bbox': [139.2677001953125, 78.0296630859375, 272.1410217285156, 346.85565185546875]}]}\nvideo 1/1 (frame 207/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 3 benchs, 7.2ms\nFrame data : {'frame_number': 206, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8732678890228271, 'bbox': [137.28189086914062, 75.61980438232422, 270.7137756347656, 346.788330078125]}]}\nvideo 1/1 (frame 208/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 3 benchs, 7.1ms\nFrame data : {'frame_number': 207, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8775699734687805, 'bbox': [133.8949432373047, 73.66584777832031, 267.0964660644531, 346.2791442871094]}]}\nvideo 1/1 (frame 209/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 208, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.897847592830658, 'bbox': [129.63168334960938, 72.09869384765625, 262.2127380371094, 345.4678649902344]}]}\nvideo 1/1 (frame 210/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 209, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8501668572425842, 'bbox': [126.3212661743164, 70.62864685058594, 258.294677734375, 344.8039855957031]}]}\nvideo 1/1 (frame 211/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 210, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8640275001525879, 'bbox': [123.35798645019531, 69.11709594726562, 255.67868041992188, 345.0387878417969]}]}\nvideo 1/1 (frame 212/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 211, 'detections': []}\nvideo 1/1 (frame 213/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 212, 'detections': []}\nvideo 1/1 (frame 214/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 213, 'detections': []}\nvideo 1/1 (frame 215/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.7ms\nFrame data : {'frame_number': 214, 'detections': []}\nvideo 1/1 (frame 216/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.9ms\nFrame data : {'frame_number': 215, 'detections': []}\nvideo 1/1 (frame 217/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 216, 'detections': []}\nvideo 1/1 (frame 218/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 217, 'detections': []}\nvideo 1/1 (frame 219/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 handbag, 7.6ms\nFrame data : {'frame_number': 218, 'detections': []}\nvideo 1/1 (frame 220/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 219, 'detections': []}\nvideo 1/1 (frame 221/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 220, 'detections': []}\nvideo 1/1 (frame 222/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 221, 'detections': []}\nvideo 1/1 (frame 223/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 222, 'detections': []}\nvideo 1/1 (frame 224/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 223, 'detections': []}\nvideo 1/1 (frame 225/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 224, 'detections': []}\nvideo 1/1 (frame 226/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 backpack, 7.2ms\nFrame data : {'frame_number': 225, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8553745150566101, 'bbox': [165.2876434326172, 149.81564331054688, 260.1324157714844, 344.1238708496094]}]}\nvideo 1/1 (frame 227/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 backpack, 1 handbag, 7.6ms\nFrame data : {'frame_number': 226, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8557674288749695, 'bbox': [162.49876403808594, 150.97006225585938, 258.7093811035156, 344.57611083984375]}]}\nvideo 1/1 (frame 228/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 227, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8355121612548828, 'bbox': [158.8167724609375, 152.7643585205078, 256.0279846191406, 343.78265380859375]}]}\nvideo 1/1 (frame 229/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.2ms\nFrame data : {'frame_number': 228, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8328527808189392, 'bbox': [154.439453125, 150.7637481689453, 254.42343139648438, 343.39703369140625]}]}\nvideo 1/1 (frame 230/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.2ms\nFrame data : {'frame_number': 229, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8421390056610107, 'bbox': [148.6524658203125, 148.46383666992188, 251.23956298828125, 342.6072998046875]}]}\nvideo 1/1 (frame 231/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 230, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.838424563407898, 'bbox': [140.17958068847656, 145.65687561035156, 244.97251892089844, 342.63372802734375]}]}\nvideo 1/1 (frame 232/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.3ms\nFrame data : {'frame_number': 231, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8499422669410706, 'bbox': [132.98081970214844, 143.42454528808594, 238.2959442138672, 342.0571594238281]}]}\nvideo 1/1 (frame 233/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 232, 'detections': []}\nvideo 1/1 (frame 234/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.3ms\nFrame data : {'frame_number': 233, 'detections': []}\nvideo 1/1 (frame 235/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 handbag, 7.3ms\nFrame data : {'frame_number': 234, 'detections': []}\nvideo 1/1 (frame 236/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.2ms\nFrame data : {'frame_number': 235, 'detections': []}\nvideo 1/1 (frame 237/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 handbag, 7.1ms\nFrame data : {'frame_number': 236, 'detections': []}\nvideo 1/1 (frame 238/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 237, 'detections': []}\nvideo 1/1 (frame 239/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 238, 'detections': []}\nvideo 1/1 (frame 240/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 bird, 8.0ms\nFrame data : {'frame_number': 239, 'detections': []}\nvideo 1/1 (frame 241/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 240, 'detections': []}\nvideo 1/1 (frame 242/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 bird, 1 handbag, 7.2ms\nFrame data : {'frame_number': 241, 'detections': []}\nvideo 1/1 (frame 243/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 bird, 1 handbag, 7.1ms\nFrame data : {'frame_number': 242, 'detections': []}\nvideo 1/1 (frame 244/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 bird, 1 backpack, 2 handbags, 8.1ms\nFrame data : {'frame_number': 243, 'detections': []}\nvideo 1/1 (frame 245/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 1 bird, 3 handbags, 7.5ms\nFrame data : {'frame_number': 244, 'detections': []}\nvideo 1/1 (frame 246/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 bird, 2 handbags, 7.3ms\nFrame data : {'frame_number': 245, 'detections': []}\nvideo 1/1 (frame 247/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 bird, 1 handbag, 7.1ms\nFrame data : {'frame_number': 246, 'detections': []}\nvideo 1/1 (frame 248/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 bird, 7.2ms\nFrame data : {'frame_number': 247, 'detections': []}\nvideo 1/1 (frame 249/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 bird, 7.1ms\nFrame data : {'frame_number': 248, 'detections': []}\nvideo 1/1 (frame 250/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 bird, 7.1ms\nFrame data : {'frame_number': 249, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8026597499847412, 'bbox': [170.14173889160156, 127.65519714355469, 256.50872802734375, 346.25506591796875]}]}\nvideo 1/1 (frame 251/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 bird, 7.2ms\nFrame data : {'frame_number': 250, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7991443872451782, 'bbox': [164.8797607421875, 125.25022888183594, 251.17111206054688, 346.9424133300781]}]}\nvideo 1/1 (frame 252/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 bird, 7.2ms\nFrame data : {'frame_number': 251, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.7987933158874512, 'bbox': [163.94818115234375, 124.19049835205078, 249.52737426757812, 346.6243896484375]}]}\nvideo 1/1 (frame 253/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 bird, 7.1ms\nFrame data : {'frame_number': 252, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8001782894134521, 'bbox': [161.48252868652344, 124.72374725341797, 247.15040588378906, 346.525146484375]}]}\nvideo 1/1 (frame 254/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bird, 7.2ms\nFrame data : {'frame_number': 253, 'detections': [{'tracker_id': 1, 'class_id': 0, 'confidence': 0.8384199738502502, 'bbox': [157.53546142578125, 125.08601379394531, 244.16290283203125, 346.4882507324219]}]}\nvideo 1/1 (frame 255/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 1 bird, 1 backpack, 7.1ms\nFrame data : {'frame_number': 254, 'detections': [{'tracker_id': 14, 'class_id': 0, 'confidence': 0.8628392815589905, 'bbox': [150.93173217773438, 126.81906127929688, 237.80239868164062, 346.8146057128906]}]}\nvideo 1/1 (frame 256/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 bird, 1 backpack, 1 handbag, 7.2ms\nFrame data : {'frame_number': 255, 'detections': [{'tracker_id': 14, 'class_id': 0, 'confidence': 0.8533197045326233, 'bbox': [144.12579345703125, 128.35171508789062, 231.4318389892578, 348.24639892578125]}]}\nvideo 1/1 (frame 257/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 bird, 1 backpack, 1 handbag, 7.2ms\nFrame data : {'frame_number': 256, 'detections': [{'tracker_id': 14, 'class_id': 0, 'confidence': 0.8695755004882812, 'bbox': [142.51222229003906, 129.10838317871094, 229.60647583007812, 348.4691467285156]}]}\nvideo 1/1 (frame 258/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 1 bird, 1 backpack, 1 handbag, 7.2ms\nFrame data : {'frame_number': 257, 'detections': [{'tracker_id': 14, 'class_id': 0, 'confidence': 0.8352255821228027, 'bbox': [141.5933074951172, 130.96807861328125, 228.05101013183594, 349.45880126953125]}]}\nvideo 1/1 (frame 259/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 bird, 1 backpack, 1 handbag, 7.1ms\nFrame data : {'frame_number': 258, 'detections': [{'tracker_id': 14, 'class_id': 0, 'confidence': 0.8830297589302063, 'bbox': [139.7517547607422, 127.35908508300781, 226.9739227294922, 350.3326416015625]}]}\nvideo 1/1 (frame 260/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 1 handbag, 9.0ms\nFrame data : {'frame_number': 259, 'detections': []}\nvideo 1/1 (frame 261/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 1 handbag, 7.9ms\nFrame data : {'frame_number': 260, 'detections': []}\nvideo 1/1 (frame 262/400) /kaggle/working/people-counting.mp4: 384x640 5 persons, 1 bench, 1 handbag, 8.2ms\nFrame data : {'frame_number': 261, 'detections': []}\nvideo 1/1 (frame 263/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 8.6ms\nFrame data : {'frame_number': 262, 'detections': []}\nvideo 1/1 (frame 264/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 263, 'detections': []}\nvideo 1/1 (frame 265/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.6ms\nFrame data : {'frame_number': 264, 'detections': []}\nvideo 1/1 (frame 266/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.2ms\nFrame data : {'frame_number': 265, 'detections': []}\nvideo 1/1 (frame 267/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 266, 'detections': []}\nvideo 1/1 (frame 268/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.6ms\nFrame data : {'frame_number': 267, 'detections': []}\nvideo 1/1 (frame 269/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 1 handbag, 7.2ms\nFrame data : {'frame_number': 268, 'detections': []}\nvideo 1/1 (frame 270/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 2 handbags, 7.7ms\nFrame data : {'frame_number': 269, 'detections': []}\nvideo 1/1 (frame 271/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 270, 'detections': []}\nvideo 1/1 (frame 272/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.6ms\nFrame data : {'frame_number': 271, 'detections': []}\nvideo 1/1 (frame 273/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 272, 'detections': []}\nvideo 1/1 (frame 274/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 273, 'detections': []}\nvideo 1/1 (frame 275/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 274, 'detections': []}\nvideo 1/1 (frame 276/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.6ms\nFrame data : {'frame_number': 275, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8547047972679138, 'bbox': [166.8132781982422, 144.0016326904297, 265.41827392578125, 347.7459411621094]}]}\nvideo 1/1 (frame 277/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 276, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8322797417640686, 'bbox': [162.7686767578125, 141.61062622070312, 261.6502380371094, 347.7714538574219]}]}\nvideo 1/1 (frame 278/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 277, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8478748798370361, 'bbox': [162.1402130126953, 139.6620330810547, 260.4129333496094, 348.9666442871094]}]}\nvideo 1/1 (frame 279/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.6ms\nFrame data : {'frame_number': 278, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8787404298782349, 'bbox': [161.76087951660156, 138.888916015625, 259.1820068359375, 350.223876953125]}]}\nvideo 1/1 (frame 280/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 279, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8698634505271912, 'bbox': [160.9918975830078, 139.5426025390625, 256.85791015625, 350.68499755859375]}]}\nvideo 1/1 (frame 281/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.9ms\nFrame data : {'frame_number': 280, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8602533340454102, 'bbox': [160.34780883789062, 141.04718017578125, 254.51278686523438, 351.6175537109375]}]}\nvideo 1/1 (frame 282/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 281, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8608140349388123, 'bbox': [158.99229431152344, 141.79739379882812, 251.65049743652344, 351.75347900390625]}]}\nvideo 1/1 (frame 283/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.3ms\nFrame data : {'frame_number': 282, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8645119667053223, 'bbox': [158.43858337402344, 141.0891876220703, 250.19911193847656, 351.87738037109375]}]}\nvideo 1/1 (frame 284/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 283, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8591097593307495, 'bbox': [158.2241668701172, 139.51589965820312, 249.9906005859375, 352.97271728515625]}]}\nvideo 1/1 (frame 285/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 1 handbag, 7.2ms\nFrame data : {'frame_number': 284, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8774892687797546, 'bbox': [159.28546142578125, 139.99008178710938, 250.15383911132812, 353.1522521972656]}]}\nvideo 1/1 (frame 286/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 285, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8540300130844116, 'bbox': [159.337646484375, 138.8921356201172, 250.70065307617188, 355.1644287109375]}]}\nvideo 1/1 (frame 287/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 286, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8379343748092651, 'bbox': [156.40988159179688, 139.13336181640625, 246.92221069335938, 355.0399475097656]}]}\nvideo 1/1 (frame 288/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 287, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8634968996047974, 'bbox': [153.31272888183594, 140.0853729248047, 242.5454559326172, 354.4045104980469]}]}\nvideo 1/1 (frame 289/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 288, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8643449544906616, 'bbox': [151.74652099609375, 140.16209411621094, 240.4287872314453, 355.160888671875]}]}\nvideo 1/1 (frame 290/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 289, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8449597954750061, 'bbox': [149.2195281982422, 138.118896484375, 237.7771759033203, 354.4777526855469]}]}\nvideo 1/1 (frame 291/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 290, 'detections': [{'tracker_id': 20, 'class_id': 0, 'confidence': 0.8843632340431213, 'bbox': [147.25294494628906, 138.2135772705078, 235.845947265625, 356.3840026855469]}]}\nvideo 1/1 (frame 292/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 291, 'detections': [{'tracker_id': 16, 'class_id': 0, 'confidence': 0.8768230080604553, 'bbox': [143.21189880371094, 138.25213623046875, 232.12350463867188, 358.0111083984375]}]}\nvideo 1/1 (frame 293/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 292, 'detections': [{'tracker_id': 16, 'class_id': 0, 'confidence': 0.8496547937393188, 'bbox': [138.58740234375, 137.93211364746094, 228.34815979003906, 359.43414306640625]}]}\nvideo 1/1 (frame 294/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 293, 'detections': []}\nvideo 1/1 (frame 295/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.3ms\nFrame data : {'frame_number': 294, 'detections': []}\nvideo 1/1 (frame 296/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 295, 'detections': []}\nvideo 1/1 (frame 297/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.7ms\nFrame data : {'frame_number': 296, 'detections': []}\nvideo 1/1 (frame 298/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.3ms\nFrame data : {'frame_number': 297, 'detections': []}\nvideo 1/1 (frame 299/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.2ms\nFrame data : {'frame_number': 298, 'detections': []}\nvideo 1/1 (frame 300/400) /kaggle/working/people-counting.mp4: 384x640 5 persons, 2 benchs, 7.4ms\nFrame data : {'frame_number': 299, 'detections': []}\nvideo 1/1 (frame 301/400) /kaggle/working/people-counting.mp4: 384x640 5 persons, 1 bench, 7.1ms\nFrame data : {'frame_number': 300, 'detections': []}\nvideo 1/1 (frame 302/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.3ms\nFrame data : {'frame_number': 301, 'detections': []}\nvideo 1/1 (frame 303/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 8.0ms\nFrame data : {'frame_number': 302, 'detections': []}\nvideo 1/1 (frame 304/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.9ms\nFrame data : {'frame_number': 303, 'detections': []}\nvideo 1/1 (frame 305/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 8.0ms\nFrame data : {'frame_number': 304, 'detections': [{'tracker_id': 26, 'class_id': 0, 'confidence': 0.7944731116294861, 'bbox': [173.1800994873047, 137.23391723632812, 246.19235229492188, 360.9916687011719]}]}\nvideo 1/1 (frame 306/400) /kaggle/working/people-counting.mp4: 384x640 5 persons, 1 bench, 7.9ms\nFrame data : {'frame_number': 305, 'detections': [{'tracker_id': 26, 'class_id': 0, 'confidence': 0.8587856292724609, 'bbox': [168.33544921875, 136.4624481201172, 244.95423889160156, 363.4713134765625]}]}\nvideo 1/1 (frame 307/400) /kaggle/working/people-counting.mp4: 384x640 5 persons, 1 bench, 7.1ms\nFrame data : {'frame_number': 306, 'detections': [{'tracker_id': 26, 'class_id': 0, 'confidence': 0.8465741872787476, 'bbox': [165.79493713378906, 136.74229431152344, 244.82144165039062, 363.48468017578125]}]}\nvideo 1/1 (frame 308/400) /kaggle/working/people-counting.mp4: 384x640 5 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 307, 'detections': [{'tracker_id': 26, 'class_id': 0, 'confidence': 0.7678220272064209, 'bbox': [160.866455078125, 136.51254272460938, 242.11288452148438, 362.5220642089844]}]}\nvideo 1/1 (frame 309/400) /kaggle/working/people-counting.mp4: 384x640 5 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 308, 'detections': [{'tracker_id': 26, 'class_id': 0, 'confidence': 0.7952679991722107, 'bbox': [156.08856201171875, 135.7462921142578, 239.14096069335938, 361.4323425292969]}]}\nvideo 1/1 (frame 310/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.4ms\nFrame data : {'frame_number': 309, 'detections': [{'tracker_id': 26, 'class_id': 0, 'confidence': 0.8355795741081238, 'bbox': [148.803955078125, 132.9742889404297, 235.3365936279297, 362.79583740234375]}]}\nvideo 1/1 (frame 311/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.1ms\nFrame data : {'frame_number': 310, 'detections': [{'tracker_id': 26, 'class_id': 0, 'confidence': 0.877407968044281, 'bbox': [144.56642150878906, 129.22837829589844, 234.05712890625, 362.4391784667969]}]}\nvideo 1/1 (frame 312/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.2ms\nFrame data : {'frame_number': 311, 'detections': [{'tracker_id': 26, 'class_id': 0, 'confidence': 0.8731315732002258, 'bbox': [139.61561584472656, 126.84644317626953, 231.3778076171875, 361.7903137207031]}]}\nvideo 1/1 (frame 313/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.2ms\nFrame data : {'frame_number': 312, 'detections': [{'tracker_id': 26, 'class_id': 0, 'confidence': 0.8771793246269226, 'bbox': [135.42544555664062, 124.35047912597656, 230.3687744140625, 363.975341796875]}]}\nvideo 1/1 (frame 314/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.3ms\nFrame data : {'frame_number': 313, 'detections': []}\nvideo 1/1 (frame 315/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 1 handbag, 7.1ms\nFrame data : {'frame_number': 314, 'detections': []}\nvideo 1/1 (frame 316/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 315, 'detections': []}\nvideo 1/1 (frame 317/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.3ms\nFrame data : {'frame_number': 316, 'detections': []}\nvideo 1/1 (frame 318/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 7.4ms\nFrame data : {'frame_number': 317, 'detections': []}\nvideo 1/1 (frame 319/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 318, 'detections': []}\nvideo 1/1 (frame 320/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 319, 'detections': []}\nvideo 1/1 (frame 321/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.3ms\nFrame data : {'frame_number': 320, 'detections': []}\nvideo 1/1 (frame 322/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.8ms\nFrame data : {'frame_number': 321, 'detections': []}\nvideo 1/1 (frame 323/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.8ms\nFrame data : {'frame_number': 322, 'detections': []}\nvideo 1/1 (frame 324/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 1 bench, 7.9ms\nFrame data : {'frame_number': 323, 'detections': []}\nvideo 1/1 (frame 325/400) /kaggle/working/people-counting.mp4: 384x640 4 persons, 2 benchs, 7.6ms\nFrame data : {'frame_number': 324, 'detections': []}\nvideo 1/1 (frame 326/400) /kaggle/working/people-counting.mp4: 384x640 3 persons, 2 benchs, 7.6ms\nFrame data : {'frame_number': 325, 'detections': []}\nvideo 1/1 (frame 327/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 8.0ms\nFrame data : {'frame_number': 326, 'detections': []}\nvideo 1/1 (frame 328/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.9ms\nFrame data : {'frame_number': 327, 'detections': []}\nvideo 1/1 (frame 329/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.5ms\nFrame data : {'frame_number': 328, 'detections': []}\nvideo 1/1 (frame 330/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.6ms\nFrame data : {'frame_number': 329, 'detections': []}\nvideo 1/1 (frame 331/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 330, 'detections': []}\nvideo 1/1 (frame 332/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.7ms\nFrame data : {'frame_number': 331, 'detections': []}\nvideo 1/1 (frame 333/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.7ms\nFrame data : {'frame_number': 332, 'detections': [{'tracker_id': 31, 'class_id': 0, 'confidence': 0.9019516110420227, 'bbox': [163.49267578125, 37.46139907836914, 273.286865234375, 380.34674072265625]}]}\nvideo 1/1 (frame 334/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.7ms\nFrame data : {'frame_number': 333, 'detections': [{'tracker_id': 31, 'class_id': 0, 'confidence': 0.8861007690429688, 'bbox': [158.9822235107422, 38.181190490722656, 269.904541015625, 380.9305114746094]}]}\nvideo 1/1 (frame 335/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.9ms\nFrame data : {'frame_number': 334, 'detections': [{'tracker_id': 31, 'class_id': 0, 'confidence': 0.8975691795349121, 'bbox': [152.44100952148438, 39.128013610839844, 265.43359375, 382.86126708984375]}]}\nvideo 1/1 (frame 336/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 8.3ms\nFrame data : {'frame_number': 335, 'detections': [{'tracker_id': 31, 'class_id': 0, 'confidence': 0.8775519132614136, 'bbox': [142.65280151367188, 39.565406799316406, 258.0638122558594, 383.55523681640625]}]}\nvideo 1/1 (frame 337/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 8.0ms\nFrame data : {'frame_number': 336, 'detections': [{'tracker_id': 31, 'class_id': 0, 'confidence': 0.8902198076248169, 'bbox': [129.54725646972656, 39.52587127685547, 248.98956298828125, 385.3505859375]}]}\nvideo 1/1 (frame 338/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 7.7ms\nFrame data : {'frame_number': 337, 'detections': []}\nvideo 1/1 (frame 339/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 7.4ms\nFrame data : {'frame_number': 338, 'detections': []}\nvideo 1/1 (frame 340/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 7.6ms\nFrame data : {'frame_number': 339, 'detections': []}\nvideo 1/1 (frame 341/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 7.7ms\nFrame data : {'frame_number': 340, 'detections': []}\nvideo 1/1 (frame 342/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.1ms\nFrame data : {'frame_number': 341, 'detections': []}\nvideo 1/1 (frame 343/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.6ms\nFrame data : {'frame_number': 342, 'detections': []}\nvideo 1/1 (frame 344/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 7.2ms\nFrame data : {'frame_number': 343, 'detections': []}\nvideo 1/1 (frame 345/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 1 handbag, 7.2ms\nFrame data : {'frame_number': 344, 'detections': []}\nvideo 1/1 (frame 346/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 1 bench, 1 handbag, 7.1ms\nFrame data : {'frame_number': 345, 'detections': []}\nvideo 1/1 (frame 347/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.4ms\nFrame data : {'frame_number': 346, 'detections': []}\nvideo 1/1 (frame 348/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.1ms\nFrame data : {'frame_number': 347, 'detections': []}\nvideo 1/1 (frame 349/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.2ms\nFrame data : {'frame_number': 348, 'detections': []}\nvideo 1/1 (frame 350/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.1ms\nFrame data : {'frame_number': 349, 'detections': []}\nvideo 1/1 (frame 351/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.3ms\nFrame data : {'frame_number': 350, 'detections': []}\nvideo 1/1 (frame 352/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.2ms\nFrame data : {'frame_number': 351, 'detections': []}\nvideo 1/1 (frame 353/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.2ms\nFrame data : {'frame_number': 352, 'detections': []}\nvideo 1/1 (frame 354/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 353, 'detections': []}\nvideo 1/1 (frame 355/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.4ms\nFrame data : {'frame_number': 354, 'detections': []}\nvideo 1/1 (frame 356/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 355, 'detections': []}\nvideo 1/1 (frame 357/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 356, 'detections': []}\nvideo 1/1 (frame 358/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 357, 'detections': []}\nvideo 1/1 (frame 359/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 358, 'detections': []}\nvideo 1/1 (frame 360/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.3ms\nFrame data : {'frame_number': 359, 'detections': []}\nvideo 1/1 (frame 361/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 360, 'detections': []}\nvideo 1/1 (frame 362/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 361, 'detections': []}\nvideo 1/1 (frame 363/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 362, 'detections': []}\nvideo 1/1 (frame 364/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 363, 'detections': []}\nvideo 1/1 (frame 365/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 364, 'detections': []}\nvideo 1/1 (frame 366/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.2ms\nFrame data : {'frame_number': 365, 'detections': []}\nvideo 1/1 (frame 367/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.6ms\nFrame data : {'frame_number': 366, 'detections': []}\nvideo 1/1 (frame 368/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.5ms\nFrame data : {'frame_number': 367, 'detections': []}\nvideo 1/1 (frame 369/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.5ms\nFrame data : {'frame_number': 368, 'detections': []}\nvideo 1/1 (frame 370/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.9ms\nFrame data : {'frame_number': 369, 'detections': []}\nvideo 1/1 (frame 371/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.7ms\nFrame data : {'frame_number': 370, 'detections': []}\nvideo 1/1 (frame 372/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 8.0ms\nFrame data : {'frame_number': 371, 'detections': []}\nvideo 1/1 (frame 373/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.3ms\nFrame data : {'frame_number': 372, 'detections': []}\nvideo 1/1 (frame 374/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.1ms\nFrame data : {'frame_number': 373, 'detections': []}\nvideo 1/1 (frame 375/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.3ms\nFrame data : {'frame_number': 374, 'detections': []}\nvideo 1/1 (frame 376/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.2ms\nFrame data : {'frame_number': 375, 'detections': []}\nvideo 1/1 (frame 377/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 1 bench, 7.3ms\nFrame data : {'frame_number': 376, 'detections': []}\nvideo 1/1 (frame 378/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.1ms\nFrame data : {'frame_number': 377, 'detections': []}\nvideo 1/1 (frame 379/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 7.3ms\nFrame data : {'frame_number': 378, 'detections': []}\nvideo 1/1 (frame 380/400) /kaggle/working/people-counting.mp4: 384x640 2 persons, 7.2ms\nFrame data : {'frame_number': 379, 'detections': []}\nvideo 1/1 (frame 381/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.9ms\nFrame data : {'frame_number': 380, 'detections': []}\nvideo 1/1 (frame 382/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.3ms\nFrame data : {'frame_number': 381, 'detections': []}\nvideo 1/1 (frame 383/400) /kaggle/working/people-counting.mp4: 384x640 1 person, 7.6ms\nFrame data : {'frame_number': 382, 'detections': []}\nvideo 1/1 (frame 384/400) /kaggle/working/people-counting.mp4: 384x640 (no detections), 7.5ms\nFrame data : {'frame_number': 383, 'detections': []}\nvideo 1/1 (frame 385/400) /kaggle/working/people-counting.mp4: 384x640 (no detections), 7.1ms\nFrame data : {'frame_number': 384, 'detections': []}\nvideo 1/1 (frame 386/400) /kaggle/working/people-counting.mp4: 384x640 (no detections), 7.2ms\nFrame data : {'frame_number': 385, 'detections': []}\nvideo 1/1 (frame 387/400) /kaggle/working/people-counting.mp4: 384x640 (no detections), 7.2ms\nFrame data : {'frame_number': 386, 'detections': []}\nvideo 1/1 (frame 388/400) /kaggle/working/people-counting.mp4: 384x640 (no detections), 7.2ms\nFrame data : {'frame_number': 387, 'detections': []}\nvideo 1/1 (frame 389/400) /kaggle/working/people-counting.mp4: 384x640 1 bench, 7.2ms\nFrame data : {'frame_number': 388, 'detections': []}\nvideo 1/1 (frame 390/400) /kaggle/working/people-counting.mp4: 384x640 2 benchs, 1 vase, 7.2ms\nFrame data : {'frame_number': 389, 'detections': []}\nvideo 1/1 (frame 391/400) /kaggle/working/people-counting.mp4: 384x640 2 benchs, 1 vase, 7.2ms\nFrame data : {'frame_number': 390, 'detections': []}\nvideo 1/1 (frame 392/400) /kaggle/working/people-counting.mp4: 384x640 2 benchs, 7.1ms\nFrame data : {'frame_number': 391, 'detections': []}\nvideo 1/1 (frame 393/400) /kaggle/working/people-counting.mp4: 384x640 1 bench, 7.2ms\nFrame data : {'frame_number': 392, 'detections': []}\nvideo 1/1 (frame 394/400) /kaggle/working/people-counting.mp4: 384x640 1 bench, 7.2ms\nFrame data : {'frame_number': 393, 'detections': []}\nvideo 1/1 (frame 395/400) /kaggle/working/people-counting.mp4: 384x640 1 bench, 7.2ms\nFrame data : {'frame_number': 394, 'detections': []}\nvideo 1/1 (frame 396/400) /kaggle/working/people-counting.mp4: 384x640 1 bench, 7.2ms\nFrame data : {'frame_number': 395, 'detections': []}\nvideo 1/1 (frame 397/400) /kaggle/working/people-counting.mp4: 384x640 1 bench, 7.1ms\nFrame data : {'frame_number': 396, 'detections': []}\nvideo 1/1 (frame 398/400) /kaggle/working/people-counting.mp4: 384x640 (no detections), 7.7ms\nFrame data : {'frame_number': 397, 'detections': []}\nvideo 1/1 (frame 399/400) /kaggle/working/people-counting.mp4: 384x640 (no detections), 7.5ms\nFrame data : {'frame_number': 398, 'detections': []}\nvideo 1/1 (frame 400/400) /kaggle/working/people-counting.mp4: 384x640 (no detections), 7.1ms\nFrame data : {'frame_number': 399, 'detections': []}\nSpeed: 1.8ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\nVehicle tracking completed and output video saved.\nFrames saved to 'frames/' and frame data saved to 'frame_data.json'.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'output_video.mp4')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T04:44:10.989542Z","iopub.execute_input":"2025-03-13T04:44:10.989897Z","iopub.status.idle":"2025-03-13T04:44:10.995155Z","shell.execute_reply.started":"2025-03-13T04:44:10.989863Z","shell.execute_reply":"2025-03-13T04:44:10.994405Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/output_video.mp4","text/html":"<a href='output_video.mp4' target='_blank'>output_video.mp4</a><br>"},"metadata":{}}],"execution_count":23}]}